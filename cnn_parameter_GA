import random
import copy
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from g_mlp_pytorch import gMLPVision
import numpy as np

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Dataset & Transform (åŒcnn_mixup.py) ---
train_transform = transforms.Compose([
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
])
test_transform = transforms.Compose([transforms.ToTensor()])

class CIFAR10_dataset(Dataset):
    def __init__(self, partition="train", transform=None):
        self.partition = partition
        self.transform = transform
        if self.partition == "train":
            self.data = torchvision.datasets.CIFAR10(".data/", train=True, download=True)
        else:
            self.data = torchvision.datasets.CIFAR10(".data/", train=False, download=True)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx][0]
        image_tensor = self.transform(image)
        label = torch.tensor(self.data[idx][1])
        label = nn.functional.one_hot(label, num_classes=10).float()
        return {"img": image_tensor, "label": label}

# --- Mixup ---
def mixup_data(x, y, alpha=0.1, device="cpu"):
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.0
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(device)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# --- gMLP Model Factory ---
def create_gmlp_model(params):
    return gMLPVision(
        image_size=32,
        patch_size=params['patch_size'],
        num_classes=10,
        dim=params['dim'],
        depth=params['depth'],
        ff_mult=params['ff_mult'],
        channels=3,
        prob_survival=params['prob_survival'],
    )

# --- Genetic Algorithm ---
PARAM_SPACE = {
    'patch_size': [2, 4, 8],
    'dim': [128, 192, 256, 384],
    'depth': [6, 8, 10, 12, 14],
    'ff_mult': [2, 3, 4, 5],
    'prob_survival': [0.8, 0.85, 0.9, 0.95, 1.0],
}

def random_params():
    return {k: random.choice(v) for k, v in PARAM_SPACE.items()}

def mutate(params):
    new_params = copy.deepcopy(params)
    key = random.choice(list(PARAM_SPACE.keys()))
    new_params[key] = random.choice(PARAM_SPACE[key])
    return new_params

def crossover(p1, p2):
    child = {}
    for k in PARAM_SPACE.keys():
        child[k] = random.choice([p1[k], p2[k]])
    return child

def evaluate_fitness(params, train_loader, test_loader, epochs=3):
    model = create_gmlp_model(params).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4, betas=(0.9, 0.95))
    model.train()
    for epoch in range(epochs):
        for batch in train_loader:
            images = batch["img"].to(device)
            labels = batch["label"].to(device)
            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.1, device=device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
    # Evaluate
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch in test_loader:
            images = batch["img"].to(device)
            labels = batch["label"].to(device)
            outputs = model(images)
            pred = torch.argmax(outputs, dim=1)
            labels_idx = torch.argmax(labels, dim=1)
            correct += pred.eq(labels_idx).sum().item()
            total += labels.size(0)
    accuracy = 100.0 * correct / total
    return accuracy

def genetic_search(generations=5, population_size=6, retain=0.5, mutate_chance=0.3):
    train_dataset = CIFAR10_dataset(partition="train", transform=train_transform)
    test_dataset = CIFAR10_dataset(partition="test", transform=test_transform)
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

    population = [random_params() for _ in range(population_size)]
    best_params = None
    best_acc = -1

    for gen in range(generations):
        print(f"\n=== Generation {gen+1} ===")
        fitness_scores = []
        for i, params in enumerate(population):
            print(f"å€‹é«” {i+1}: {params}")
            acc = evaluate_fitness(params, train_loader, test_loader, epochs=2)
            print(f"  -> æ¸¬è©¦æº–ç¢ºç‡: {acc:.2f}%")
            fitness_scores.append((acc, params))
            if acc > best_acc:
                best_acc = acc
                best_params = params
        # é¸æ“‡
        fitness_scores.sort(reverse=True, key=lambda x: x[0])
        survivors = [x[1] for x in fitness_scores[:int(population_size*retain)]]
        # ç”¢ç”Ÿæ–°ä¸€ä»£
        next_gen = survivors.copy()
        while len(next_gen) < population_size:
            if random.random() < mutate_chance:
                parent = random.choice(survivors)
                child = mutate(parent)
            else:
                p1, p2 = random.sample(survivors, 2)
                child = crossover(p1, p2)
            next_gen.append(child)
        population = next_gen
        print(f"æœ¬ä¸–ä»£æœ€ä½³: {fitness_scores[0][1]}, æº–ç¢ºç‡: {fitness_scores[0][0]:.2f}%")
    print("\n=== æœ€ä½³åƒæ•¸çµ„åˆ ===")
    print(best_params)
    print(f"æœ€ä½³æ¸¬è©¦æº–ç¢ºç‡: {best_acc:.2f}%")
    return best_params, best_acc

if __name__ == "__main__":
    print("ğŸ”¬ ä½¿ç”¨éºå‚³æ¼”ç®—æ³•æœå°‹æœ€ä½³gMLPæ¶æ§‹åƒæ•¸")
    genetic_search(generations=3, population_size=4)
