批次 550/782: 損失=0.8526, 準確率=78.07%
   批次 600/782: 損失=0.8517, 準確率=78.15%
   批次 650/782: 損失=0.8521, 準確率=78.12%
   批次 700/782: 損失=0.8517, 準確率=78.11%
   批次 750/782: 損失=0.8503, 準確率=78.10%
   批次 782/782: 損失=0.8513, 準確率=78.06%
Epoch 28 完成: 訓練=78.06%, 驗證=74.79%, 時間=72.1s

Epoch 29/100, LR: 0.002458
   批次  50/782: 損失=0.8300, 準確率=78.41%
   批次 100/782: 損失=0.8392, 準確率=78.33%
   批次 150/782: 損失=0.8383, 準確率=78.47%
   批次 200/782: 損失=0.8403, 準確率=78.26%
   批次 250/782: 損失=0.8391, 準確率=78.24%
   批次 300/782: 損失=0.8432, 準確率=78.12%
   批次 350/782: 損失=0.8460, 準確率=78.09%
   批次 400/782: 損失=0.8431, 準確率=78.27%
   批次 450/782: 損失=0.8435, 準確率=78.28%
   批次 500/782: 損失=0.8443, 準確率=78.24%
   批次 550/782: 損失=0.8457, 準確率=78.21%
   批次 600/782: 損失=0.8451, 準確率=78.18%
   批次 650/782: 損失=0.8460, 準確率=78.12%
   批次 700/782: 損失=0.8456, 準確率=78.12%
   批次 750/782: 損失=0.8449, 準確率=78.12%
   批次 782/782: 損失=0.8455, 準確率=78.08%
Epoch 29 完成: 訓練=78.08%, 驗證=74.81%, 時間=70.4s

Epoch 30/100, LR: 0.002421
   批次  50/782: 損失=0.8196, 準確率=78.31%
   批次 100/782: 損失=0.8241, 準確率=78.42%
   批次 150/782: 損失=0.8239, 準確率=78.62%
   批次 200/782: 損失=0.8278, 準確率=78.66%
   批次 250/782: 損失=0.8306, 準確率=78.66%
   批次 300/782: 損失=0.8359, 準確率=78.51%
   批次 350/782: 損失=0.8349, 準確率=78.59%
   批次 400/782: 損失=0.8361, 準確率=78.51%
   批次 450/782: 損失=0.8369, 準確率=78.44%
   批次 500/782: 損失=0.8367, 準確率=78.49%
   批次 550/782: 損失=0.8361, 準確率=78.47%
   批次 600/782: 損失=0.8393, 準確率=78.35%
   批次 650/782: 損失=0.8397, 準確率=78.37%
   批次 700/782: 損失=0.8403, 準確率=78.29%
   批次 750/782: 損失=0.8409, 準確率=78.29%
   批次 782/782: 損失=0.8409, 準確率=78.29%
Epoch 30 完成: 訓練=78.29%, 驗證=74.99%, 時間=73.2s
   💾 新最佳模型已保存: 驗證準確率 74.99%

Epoch 31/100, LR: 0.002384
   批次  50/782: 損失=0.8273, 準確率=79.06%
   批次 100/782: 損失=0.8422, 準確率=78.38%
   批次 150/782: 損失=0.8370, 準確率=78.46%
   批次 200/782: 損失=0.8347, 準確率=78.62%
   批次 250/782: 損失=0.8327, 準確率=78.76%
   批次 300/782: 損失=0.8360, 準確率=78.67%
   批次 350/782: 損失=0.8357, 準確率=78.67%
   批次 400/782: 損失=0.8363, 準確率=78.64%
   批次 450/782: 損失=0.8325, 準確率=78.87%
   批次 500/782: 損失=0.8334, 準確率=78.77%
   批次 550/782: 損失=0.8329, 準確率=78.76%
   批次 600/782: 損失=0.8327, 準確率=78.80%
   批次 650/782: 損失=0.8320, 準確率=78.75%
   批次 700/782: 損失=0.8330, 準確率=78.75%
   批次 750/782: 損失=0.8337, 準確率=78.72%
   批次 782/782: 損失=0.8348, 準確率=78.66%
Epoch 31 完成: 訓練=78.66%, 驗證=75.06%, 時間=73.8s
   💾 新最佳模型已保存: 驗證準確率 75.06%

Epoch 32/100, LR: 0.002345
   批次  50/782: 損失=0.8079, 準確率=79.84%
   批次 100/782: 損失=0.8144, 準確率=79.44%
   批次 150/782: 損失=0.8142, 準確率=79.55%
   批次 200/782: 損失=0.8208, 準確率=79.21%
   批次 250/782: 損失=0.8237, 準確率=79.27%
   批次 300/782: 損失=0.8246, 準確率=79.12%
   批次 350/782: 損失=0.8222, 準確率=79.23%
   批次 400/782: 損失=0.8237, 準確率=79.18%
   批次 450/782: 損失=0.8254, 準確率=79.15%
   批次 500/782: 損失=0.8266, 準確率=79.11%
   批次 550/782: 損失=0.8289, 準確率=79.02%
   批次 600/782: 損失=0.8301, 準確率=79.00%
   批次 650/782: 損失=0.8312, 準確率=78.99%
   批次 700/782: 損失=0.8317, 準確率=78.96%
   批次 750/782: 損失=0.8318, 準確率=78.91%
   批次 782/782: 損失=0.8317, 準確率=78.91%
Epoch 32 完成: 訓練=78.91%, 驗證=75.36%, 時間=77.9s
   💾 新最佳模型已保存: 驗證準確率 75.36%

Epoch 33/100, LR: 0.002306
   批次  50/782: 損失=0.8079, 準確率=79.75%
   批次 100/782: 損失=0.8172, 準確率=79.80%
   批次 150/782: 損失=0.8184, 準確率=79.56%
   批次 200/782: 損失=0.8207, 準確率=79.36%
   批次 250/782: 損失=0.8232, 準確率=79.28%
   批次 300/782: 損失=0.8243, 準確率=79.23%
   批次 350/782: 損失=0.8263, 準確率=79.08%
   批次 400/782: 損失=0.8276, 準確率=78.96%
   批次 450/782: 損失=0.8240, 準確率=79.09%
   批次 500/782: 損失=0.8243, 準確率=78.96%
   批次 550/782: 損失=0.8248, 準確率=78.95%
   批次 600/782: 損失=0.8268, 準確率=78.90%
   批次 650/782: 損失=0.8272, 準確率=78.89%
   批次 700/782: 損失=0.8257, 準確率=78.98%
   批次 750/782: 損失=0.8253, 準確率=79.00%
   批次 782/782: 損失=0.8256, 準確率=79.01%
Epoch 33 完成: 訓練=79.01%, 驗證=74.64%, 時間=71.4s

Epoch 34/100, LR: 0.002266
   批次  50/782: 損失=0.8068, 準確率=79.38%
   批次 100/782: 損失=0.8131, 準確率=79.45%
   批次 150/782: 損失=0.8067, 準確率=79.76%
   批次 200/782: 損失=0.8071, 準確率=79.68%
   批次 250/782: 損失=0.8056, 準確率=79.83%
   批次 300/782: 損失=0.8127, 準確率=79.42%
   批次 350/782: 損失=0.8155, 準確率=79.22%
   批次 400/782: 損失=0.8154, 準確率=79.34%
   批次 450/782: 損失=0.8148, 準確率=79.39%
   批次 500/782: 損失=0.8145, 準確率=79.50%
   批次 550/782: 損失=0.8139, 準確率=79.55%
   批次 600/782: 損失=0.8141, 準確率=79.58%
   批次 650/782: 損失=0.8131, 準確率=79.59%
   批次 700/782: 損失=0.8160, 準確率=79.42%
   批次 750/782: 損失=0.8163, 準確率=79.36%
   批次 782/782: 損失=0.8162, 準確率=79.32%
Epoch 34 完成: 訓練=79.32%, 驗證=75.80%, 時間=70.8s
   💾 新最佳模型已保存: 驗證準確率 75.80%

Epoch 35/100, LR: 0.002225
   批次  50/782: 損失=0.8221, 準確率=78.94%
   批次 100/782: 損失=0.8024, 準確率=79.88%
   批次 150/782: 損失=0.8171, 準確率=79.16%
   批次 200/782: 損失=0.8152, 準確率=79.13%
   批次 250/782: 損失=0.8074, 準確率=79.52%
   批次 300/782: 損失=0.8084, 準確率=79.65%
   批次 350/782: 損失=0.8080, 準確率=79.71%
   批次 400/782: 損失=0.8103, 準確率=79.65%
   批次 450/782: 損失=0.8115, 準確率=79.61%
   批次 500/782: 損失=0.8118, 準確率=79.58%
   批次 550/782: 損失=0.8130, 準確率=79.49%
   批次 600/782: 損失=0.8134, 準確率=79.50%
   批次 650/782: 損失=0.8138, 準確率=79.51%
   批次 700/782: 損失=0.8139, 準確率=79.54%
   批次 750/782: 損失=0.8140, 準確率=79.50%
   批次 782/782: 損失=0.8147, 準確率=79.47%
Epoch 35 完成: 訓練=79.47%, 驗證=76.15%, 時間=73.0s
   💾 新最佳模型已保存: 驗證準確率 76.15%

Epoch 36/100, LR: 0.002184
   批次  50/782: 損失=0.8091, 準確率=79.06%
   批次 100/782: 損失=0.8095, 準確率=79.67%
   批次 150/782: 損失=0.8096, 準確率=79.83%
   批次 200/782: 損失=0.8059, 準確率=79.95%
   批次 250/782: 損失=0.8058, 準確率=80.01%
   批次 300/782: 損失=0.8030, 準確率=80.08%
   批次 350/782: 損失=0.8018, 準確率=80.07%
   批次 400/782: 損失=0.8016, 準確率=80.01%
   批次 450/782: 損失=0.8037, 準確率=79.91%
   批次 500/782: 損失=0.8028, 準確率=79.93%
   批次 550/782: 損失=0.8047, 準確率=79.85%
   批次 600/782: 損失=0.8069, 準確率=79.76%
   批次 650/782: 損失=0.8093, 準確率=79.67%
   批次 700/782: 損失=0.8092, 準確率=79.65%
   批次 750/782: 損失=0.8095, 準確率=79.65%
   批次 782/782: 損失=0.8105, 準確率=79.61%
Epoch 36 完成: 訓練=79.61%, 驗證=76.12%, 時間=70.7s

Epoch 37/100, LR: 0.002142
   批次  50/782: 損失=0.7922, 準確率=81.03%
   批次 100/782: 損失=0.8075, 準確率=80.05%
   批次 150/782: 損失=0.8017, 準確率=80.21%
   批次 200/782: 損失=0.7969, 準確率=80.51%
   批次 250/782: 損失=0.7973, 準確率=80.47%
   批次 300/782: 損失=0.7997, 準確率=80.41%
   批次 350/782: 損失=0.8023, 準確率=80.30%
   批次 400/782: 損失=0.8012, 準確率=80.38%
   批次 450/782: 損失=0.8007, 準確率=80.30%
   批次 500/782: 損失=0.8035, 準確率=80.21%
   批次 550/782: 損失=0.8028, 準確率=80.16%
   批次 600/782: 損失=0.8043, 準確率=80.01%
   批次 650/782: 損失=0.8056, 準確率=79.88%
   批次 700/782: 損失=0.8063, 準確率=79.85%
   批次 750/782: 損失=0.8068, 準確率=79.84%
   批次 782/782: 損失=0.8072, 準確率=79.85%
Epoch 37 完成: 訓練=79.85%, 驗證=76.26%, 時間=70.7s
   💾 新最佳模型已保存: 驗證準確率 76.26%

Epoch 38/100, LR: 0.002099
   批次  50/782: 損失=0.7779, 準確率=81.78%
   批次 100/782: 損失=0.7880, 準確率=81.22%
   批次 150/782: 損失=0.7945, 準確率=80.67%
   批次 200/782: 損失=0.7965, 準確率=80.56%
   批次 250/782: 損失=0.7952, 準確率=80.50%
   批次 300/782: 損失=0.7933, 準確率=80.54%
   批次 350/782: 損失=0.7941, 準確率=80.49%
   批次 400/782: 損失=0.7951, 準確率=80.49%
   批次 450/782: 損失=0.7975, 準確率=80.34%
   批次 500/782: 損失=0.7990, 準確率=80.29%
   批次 550/782: 損失=0.7990, 準確率=80.25%
   批次 600/782: 損失=0.8004, 準確率=80.17%
   批次 650/782: 損失=0.8011, 準確率=80.12%
   批次 700/782: 損失=0.8026, 準確率=80.03%
   批次 750/782: 損失=0.8018, 準確率=80.05%
   批次 782/782: 損失=0.8020, 準確率=80.02%
Epoch 38 完成: 訓練=80.02%, 驗證=76.01%, 時間=71.7s

Epoch 39/100, LR: 0.002055
   批次  50/782: 損失=0.8151, 準確率=79.88%
   批次 100/782: 損失=0.7879, 準確率=80.75%
   批次 150/782: 損失=0.7851, 準確率=81.09%
   批次 200/782: 損失=0.7882, 準確率=80.82%
   批次 250/782: 損失=0.7875, 準確率=80.92%
   批次 300/782: 損失=0.7908, 準確率=80.73%
   批次 350/782: 損失=0.7934, 準確率=80.62%
   批次 400/782: 損失=0.7936, 準確率=80.61%
   批次 450/782: 損失=0.7936, 準確率=80.59%
   批次 500/782: 損失=0.7938, 準確率=80.61%
   批次 550/782: 損失=0.7945, 準確率=80.54%
   批次 600/782: 損失=0.7947, 準確率=80.55%
   批次 650/782: 損失=0.7960, 準確率=80.48%
   批次 700/782: 損失=0.7966, 準確率=80.46%
   批次 750/782: 損失=0.7963, 準確率=80.44%
   批次 782/782: 損失=0.7967, 準確率=80.41%
Epoch 39 完成: 訓練=80.41%, 驗證=76.08%, 時間=71.1s

Epoch 40/100, LR: 0.002011
   批次  50/782: 損失=0.7722, 準確率=81.12%
   批次 100/782: 損失=0.7788, 準確率=81.00%
   批次 150/782: 損失=0.7829, 準確率=81.04%
   批次 200/782: 損失=0.7840, 準確率=80.78%
   批次 250/782: 損失=0.7831, 準確率=80.89%
   批次 300/782: 損失=0.7804, 準確率=80.87%
   批次 350/782: 損失=0.7840, 準確率=80.68%
   批次 400/782: 損失=0.7827, 準確率=80.74%
   批次 450/782: 損失=0.7855, 準確率=80.59%
   批次 500/782: 損失=0.7845, 準確率=80.72%
   批次 550/782: 損失=0.7870, 準確率=80.68%
   批次 600/782: 損失=0.7889, 準確率=80.57%
   批次 650/782: 損失=0.7900, 準確率=80.53%
   批次 700/782: 損失=0.7924, 準確率=80.44%
   批次 750/782: 損失=0.7919, 準確率=80.42%
   批次 782/782: 損失=0.7927, 準確率=80.41%
Epoch 40 完成: 訓練=80.41%, 驗證=75.81%, 時間=73.8s

Epoch 41/100, LR: 0.001967
   批次  50/782: 損失=0.8041, 準確率=80.34%
   批次 100/782: 損失=0.7851, 準確率=80.81%
   批次 150/782: 損失=0.7853, 準確率=80.78%
   批次 200/782: 損失=0.7841, 準確率=80.71%
   批次 250/782: 損失=0.7866, 準確率=80.58%
   批次 300/782: 損失=0.7860, 準確率=80.69%
   批次 350/782: 損失=0.7841, 準確率=80.83%
   批次 400/782: 損失=0.7832, 準確率=80.87%
   批次 450/782: 損失=0.7840, 準確率=80.77%
   批次 500/782: 損失=0.7848, 準確率=80.67%
   批次 550/782: 損失=0.7855, 準確率=80.70%
   批次 600/782: 損失=0.7877, 準確率=80.65%
   批次 650/782: 損失=0.7886, 準確率=80.58%
   批次 700/782: 損失=0.7883, 準確率=80.56%
   批次 750/782: 損失=0.7894, 準確率=80.51%
   批次 782/782: 損失=0.7907, 準確率=80.46%
Epoch 41 完成: 訓練=80.46%, 驗證=76.74%, 時間=69.7s
   💾 新最佳模型已保存: 驗證準確率 76.74%

Epoch 42/100, LR: 0.001922
   批次  50/782: 損失=0.7698, 準確率=81.66%
   批次 100/782: 損失=0.7767, 準確率=81.20%
   批次 150/782: 損失=0.7706, 準確率=81.54%
   批次 200/782: 損失=0.7797, 準確率=80.97%
   批次 250/782: 損失=0.7765, 準確率=81.06%
   批次 300/782: 損失=0.7788, 準確率=81.06%
   批次 350/782: 損失=0.7809, 準確率=80.98%
   批次 400/782: 損失=0.7834, 準確率=80.88%
   批次 450/782: 損失=0.7809, 準確率=81.02%
   批次 500/782: 損失=0.7814, 準確率=80.98%
   批次 550/782: 損失=0.7834, 準確率=80.88%
   批次 600/782: 損失=0.7834, 準確率=80.86%
   批次 650/782: 損失=0.7844, 準確率=80.80%
   批次 700/782: 損失=0.7846, 準確率=80.80%
   批次 750/782: 損失=0.7848, 準確率=80.73%
   批次 782/782: 損失=0.7858, 準確率=80.73%
Epoch 42 完成: 訓練=80.73%, 驗證=76.68%, 時間=71.8s

Epoch 43/100, LR: 0.001877
   批次  50/782: 損失=0.7586, 準確率=82.03%
   批次 100/782: 損失=0.7633, 準確率=81.88%
   批次 150/782: 損失=0.7559, 準確率=82.20%
   批次 200/782: 損失=0.7552, 準確率=82.26%
   批次 250/782: 損失=0.7591, 準確率=82.04%
   批次 300/782: 損失=0.7659, 準確率=81.85%
   批次 350/782: 損失=0.7684, 準確率=81.74%
   批次 400/782: 損失=0.7686, 準確率=81.68%
   批次 450/782: 損失=0.7717, 準確率=81.49%
   批次 500/782: 損失=0.7743, 準確率=81.33%
   批次 550/782: 損失=0.7762, 準確率=81.24%
   批次 600/782: 損失=0.7766, 準確率=81.21%
   批次 650/782: 損失=0.7780, 準確率=81.13%
   批次 700/782: 損失=0.7774, 準確率=81.08%
   批次 750/782: 損失=0.7772, 準確率=81.09%
   批次 782/782: 損失=0.7767, 準確率=81.10%
Epoch 43 完成: 訓練=81.10%, 驗證=75.89%, 時間=70.3s
   📊 訓練-驗證差異: 5.21%

Epoch 44/100, LR: 0.001831
   批次  50/782: 損失=0.7595, 準確率=82.31%
   批次 100/782: 損失=0.7574, 準確率=82.11%
   批次 150/782: 損失=0.7515, 準確率=82.23%
   批次 200/782: 損失=0.7569, 準確率=82.07%
   批次 250/782: 損失=0.7637, 準確率=81.72%
   批次 300/782: 損失=0.7630, 準確率=81.65%
   批次 350/782: 損失=0.7647, 準確率=81.59%
   批次 400/782: 損失=0.7697, 準確率=81.46%
   批次 450/782: 損失=0.7712, 準確率=81.40%
   批次 500/782: 損失=0.7726, 準確率=81.29%
   批次 550/782: 損失=0.7724, 準確率=81.32%
   批次 600/782: 損失=0.7728, 準確率=81.34%
   批次 650/782: 損失=0.7751, 準確率=81.22%
   批次 700/782: 損失=0.7758, 準確率=81.16%
   批次 750/782: 損失=0.7772, 準確率=81.12%
   批次 782/782: 損失=0.7775, 準確率=81.11%
Epoch 44 完成: 訓練=81.11%, 驗證=76.57%, 時間=71.3s

Epoch 45/100, LR: 0.001785
   批次  50/782: 損失=0.7475, 準確率=82.56%
   批次 100/782: 損失=0.7625, 準確率=81.67%
   批次 150/782: 損失=0.7609, 準確率=81.78%
   批次 200/782: 損失=0.7617, 準確率=81.70%
   批次 250/782: 損失=0.7605, 準確率=81.74%
   批次 300/782: 損失=0.7593, 準確率=81.78%
   批次 350/782: 損失=0.7622, 準確率=81.64%
   批次 400/782: 損失=0.7650, 準確率=81.48%
   批次 450/782: 損失=0.7654, 準確率=81.50%
   批次 500/782: 損失=0.7661, 準確率=81.49%
   批次 550/782: 損失=0.7674, 準確率=81.44%
   批次 600/782: 損失=0.7677, 準確率=81.45%
   批次 650/782: 損失=0.7694, 準確率=81.38%
   批次 700/782: 損失=0.7707, 準確率=81.28%
   批次 750/782: 損失=0.7723, 準確率=81.24%
   批次 782/782: 損失=0.7719, 準確率=81.23%
Epoch 45 完成: 訓練=81.23%, 驗證=76.99%, 時間=73.5s
   💾 新最佳模型已保存: 驗證準確率 76.99%

Epoch 46/100, LR: 0.001739
   批次  50/782: 損失=0.7548, 準確率=81.72%
   批次 100/782: 損失=0.7593, 準確率=81.62%
   批次 150/782: 損失=0.7575, 準確率=81.92%
   批次 200/782: 損失=0.7590, 準確率=81.94%
   批次 250/782: 損失=0.7620, 準確率=81.74%
   批次 300/782: 損失=0.7620, 準確率=81.73%
   批次 350/782: 損失=0.7637, 準確率=81.69%
   批次 400/782: 損失=0.7639, 準確率=81.70%
   批次 450/782: 損失=0.7646, 準確率=81.66%
   批次 500/782: 損失=0.7657, 準確率=81.63%
   批次 550/782: 損失=0.7650, 準確率=81.60%
   批次 600/782: 損失=0.7637, 準確率=81.65%
   批次 650/782: 損失=0.7648, 準確率=81.59%
   批次 700/782: 損失=0.7644, 準確率=81.61%
   批次 750/782: 損失=0.7649, 準確率=81.57%
   批次 782/782: 損失=0.7662, 準確率=81.51%
Epoch 46 完成: 訓練=81.51%, 驗證=76.72%, 時間=71.2s

Epoch 47/100, LR: 0.001692
   批次  50/782: 損失=0.7482, 準確率=82.59%
   批次 100/782: 損失=0.7550, 準確率=82.25%
   批次 150/782: 損失=0.7563, 準確率=82.09%
   批次 200/782: 損失=0.7572, 準確率=81.98%
   批次 250/782: 損失=0.7610, 準確率=81.86%
   批次 300/782: 損失=0.7608, 準確率=81.78%
   批次 350/782: 損失=0.7606, 準確率=81.79%
   批次 400/782: 損失=0.7593, 準確率=81.87%
   批次 450/782: 損失=0.7595, 準確率=81.85%
   批次 500/782: 損失=0.7615, 準確率=81.72%
   批次 550/782: 損失=0.7629, 準確率=81.69%
   批次 600/782: 損失=0.7642, 準確率=81.65%
   批次 650/782: 損失=0.7642, 準確率=81.73%
   批次 700/782: 損失=0.7636, 準確率=81.75%
   批次 750/782: 損失=0.7631, 準確率=81.77%
   批次 782/782: 損失=0.7634, 準確率=81.76%
Epoch 47 完成: 訓練=81.76%, 驗證=76.68%, 時間=69.9s
   📊 訓練-驗證差異: 5.08%

Epoch 48/100, LR: 0.001646
   批次  50/782: 損失=0.7566, 準確率=82.00%
   批次 100/782: 損失=0.7562, 準確率=82.03%
   批次 150/782: 損失=0.7457, 準確率=82.33%
   批次 200/782: 損失=0.7505, 準確率=82.05%
   批次 250/782: 損失=0.7490, 準確率=82.14%
   批次 300/782: 損失=0.7503, 準確率=82.13%
   批次 350/782: 損失=0.7514, 準確率=82.18%
   批次 400/782: 損失=0.7531, 準確率=82.09%
   批次 450/782: 損失=0.7540, 準確率=82.01%
   批次 500/782: 損失=0.7559, 準確率=81.94%
   批次 550/782: 損失=0.7563, 準確率=81.89%
   批次 600/782: 損失=0.7563, 準確率=81.88%
   批次 650/782: 損失=0.7557, 準確率=81.93%
   批次 700/782: 損失=0.7563, 準確率=81.92%
   批次 750/782: 損失=0.7573, 準確率=81.85%
   批次 782/782: 損失=0.7570, 準確率=81.84%
Epoch 48 完成: 訓練=81.84%, 驗證=76.65%, 時間=73.2s
   📊 訓練-驗證差異: 5.19%

Epoch 49/100, LR: 0.001599
   批次  50/782: 損失=0.7500, 準確率=82.66%
   批次 100/782: 損失=0.7443, 準確率=82.64%
   批次 150/782: 損失=0.7421, 準確率=82.60%
   批次 200/782: 損失=0.7413, 準確率=82.76%
   批次 250/782: 損失=0.7438, 準確率=82.66%
   批次 300/782: 損失=0.7466, 準確率=82.51%
   批次 350/782: 損失=0.7453, 準確率=82.54%
   批次 400/782: 損失=0.7478, 準確率=82.43%
   批次 450/782: 損失=0.7491, 準確率=82.35%
   批次 500/782: 損失=0.7480, 準確率=82.40%
   批次 550/782: 損失=0.7516, 準確率=82.20%
   批次 600/782: 損失=0.7520, 準確率=82.19%
   批次 650/782: 損失=0.7536, 準確率=82.04%
   批次 700/782: 損失=0.7532, 準確率=82.14%
   批次 750/782: 損失=0.7541, 準確率=82.11%
   批次 782/782: 損失=0.7544, 準確率=82.09%
Epoch 49 完成: 訓練=82.09%, 驗證=77.04%, 時間=71.2s
   📊 訓練-驗證差異: 5.05%
   💾 新最佳模型已保存: 驗證準確率 77.04%

Epoch 50/100, LR: 0.001552
   批次  50/782: 損失=0.7321, 準確率=83.00%
   批次 100/782: 損失=0.7434, 準確率=82.36%
   批次 150/782: 損失=0.7446, 準確率=82.39%
   批次 200/782: 損失=0.7430, 準確率=82.46%
   批次 250/782: 損失=0.7401, 準確率=82.67%
   批次 300/782: 損失=0.7389, 準確率=82.72%
   批次 350/782: 損失=0.7382, 準確率=82.66%
   批次 400/782: 損失=0.7401, 準確率=82.63%
   批次 450/782: 損失=0.7411, 準確率=82.56%
   批次 500/782: 損失=0.7421, 準確率=82.53%
   批次 550/782: 損失=0.7431, 準確率=82.56%
   批次 600/782: 損失=0.7451, 準確率=82.43%
   批次 650/782: 損失=0.7449, 準確率=82.46%
   批次 700/782: 損失=0.7442, 準確率=82.51%
   批次 750/782: 損失=0.7441, 準確率=82.49%
   批次 782/782: 損失=0.7456, 準確率=82.45%
Epoch 50 完成: 訓練=82.45%, 驗證=77.30%, 時間=72.6s
   📊 訓練-驗證差異: 5.15%
   💾 新最佳模型已保存: 驗證準確率 77.30%

Epoch 51/100, LR: 0.001505
   批次  50/782: 損失=0.7171, 準確率=83.94%
   批次 100/782: 損失=0.7315, 準確率=83.41%
   批次 150/782: 損失=0.7319, 準確率=83.27%
   批次 200/782: 損失=0.7338, 準確率=83.31%
   批次 250/782: 損失=0.7332, 準確率=83.20%
   批次 300/782: 損失=0.7394, 準確率=82.96%
   批次 350/782: 損失=0.7401, 準確率=82.99%
   批次 400/782: 損失=0.7439, 準確率=82.78%
   批次 450/782: 損失=0.7420, 準確率=82.86%
   批次 500/782: 損失=0.7400, 準確率=82.88%
   批次 550/782: 損失=0.7409, 準確率=82.82%
   批次 600/782: 損失=0.7424, 準確率=82.71%
   批次 650/782: 損失=0.7417, 準確率=82.76%
   批次 700/782: 損失=0.7436, 準確率=82.70%
   批次 750/782: 損失=0.7440, 準確率=82.68%
   批次 782/782: 損失=0.7443, 準確率=82.62%
Epoch 51 完成: 訓練=82.62%, 驗證=76.50%, 時間=71.3s
   📊 訓練-驗證差異: 6.12%

Epoch 52/100, LR: 0.001458
   批次  50/782: 損失=0.7155, 準確率=83.81%
   批次 100/782: 損失=0.7217, 準確率=83.53%
   批次 150/782: 損失=0.7240, 準確率=83.26%
   批次 200/782: 損失=0.7250, 準確率=83.23%
   批次 250/782: 損失=0.7244, 準確率=83.28%
   批次 300/782: 損失=0.7276, 準確率=83.11%
   批次 350/782: 損失=0.7299, 準確率=83.08%
   批次 400/782: 損失=0.7286, 準確率=83.21%
   批次 450/782: 損失=0.7296, 準確率=83.19%
   批次 500/782: 損失=0.7320, 準確率=83.09%
   批次 550/782: 損失=0.7344, 準確率=82.99%
   批次 600/782: 損失=0.7350, 準確率=82.95%
   批次 650/782: 損失=0.7358, 準確率=82.97%
   批次 700/782: 損失=0.7372, 準確率=82.90%
   批次 750/782: 損失=0.7374, 準確率=82.88%
   批次 782/782: 損失=0.7393, 準確率=82.78%
Epoch 52 完成: 訓練=82.78%, 驗證=76.78%, 時間=69.3s
   📊 訓練-驗證差異: 6.00%

Epoch 53/100, LR: 0.001411
   批次  50/782: 損失=0.7348, 準確率=83.44%
   批次 100/782: 損失=0.7298, 準確率=83.66%
   批次 150/782: 損失=0.7256, 準確率=83.77%
   批次 200/782: 損失=0.7258, 準確率=83.63%
   批次 250/782: 損失=0.7278, 準確率=83.44%
   批次 300/782: 損失=0.7283, 準確率=83.38%
   批次 350/782: 損失=0.7278, 準確率=83.39%
   批次 400/782: 損失=0.7279, 準確率=83.38%
   批次 450/782: 損失=0.7313, 準確率=83.19%
   批次 500/782: 損失=0.7323, 準確率=83.19%
   批次 550/782: 損失=0.7332, 準確率=83.09%
   批次 600/782: 損失=0.7339, 準確率=83.03%
   批次 650/782: 損失=0.7343, 準確率=83.00%
   批次 700/782: 損失=0.7344, 準確率=82.99%
   批次 750/782: 損失=0.7356, 準確率=82.98%
   批次 782/782: 損失=0.7356, 準確率=82.99%
Epoch 53 完成: 訓練=82.99%, 驗證=77.09%, 時間=71.9s
   📊 訓練-驗證差異: 5.90%

Epoch 54/100, LR: 0.001364
   批次  50/782: 損失=0.7299, 準確率=84.03%
   批次 100/782: 損失=0.7218, 準確率=84.14%
   批次 150/782: 損失=0.7144, 準確率=84.18%
   批次 200/782: 損失=0.7161, 準確率=84.20%
   批次 250/782: 損失=0.7245, 準確率=83.74%
   批次 300/782: 損失=0.7269, 準確率=83.54%
   批次 350/782: 損失=0.7276, 準確率=83.47%
   批次 400/782: 損失=0.7270, 準確率=83.38%
   批次 450/782: 損失=0.7292, 準確率=83.24%
   批次 500/782: 損失=0.7293, 準確率=83.28%
   批次 550/782: 損失=0.7304, 準確率=83.22%
   批次 600/782: 損失=0.7313, 準確率=83.16%
   批次 650/782: 損失=0.7303, 準確率=83.20%
   批次 700/782: 損失=0.7291, 準確率=83.24%
   批次 750/782: 損失=0.7324, 準確率=83.08%
   批次 782/782: 損失=0.7324, 準確率=83.10%
Epoch 54 完成: 訓練=83.10%, 驗證=76.99%, 時間=69.2s
   📊 訓練-驗證差異: 6.11%

Epoch 55/100, LR: 0.001318
   批次  50/782: 損失=0.7368, 準確率=82.41%
   批次 100/782: 損失=0.7183, 準確率=83.52%
   批次 150/782: 損失=0.7140, 準確率=83.88%
   批次 200/782: 損失=0.7174, 準確率=83.76%
   批次 250/782: 損失=0.7178, 準確率=83.76%
   批次 300/782: 損失=0.7206, 準確率=83.58%
   批次 350/782: 損失=0.7236, 準確率=83.48%
   批次 400/782: 損失=0.7236, 準確率=83.46%
   批次 450/782: 損失=0.7235, 準確率=83.44%
   批次 500/782: 損失=0.7225, 準確率=83.48%
   批次 550/782: 損失=0.7242, 準確率=83.40%
   批次 600/782: 損失=0.7246, 準確率=83.39%
   批次 650/782: 損失=0.7254, 準確率=83.34%
   批次 700/782: 損失=0.7263, 準確率=83.28%
   批次 750/782: 損失=0.7260, 準確率=83.30%
   批次 782/782: 損失=0.7266, 準確率=83.25%
Epoch 55 完成: 訓練=83.25%, 驗證=76.96%, 時間=68.5s
   📊 訓練-驗證差異: 6.29%

Epoch 56/100, LR: 0.001271
   批次  50/782: 損失=0.7140, 準確率=83.53%
   批次 100/782: 損失=0.7143, 準確率=83.75%
   批次 150/782: 損失=0.7105, 準確率=84.11%
   批次 200/782: 損失=0.7090, 準確率=84.16%
   批次 250/782: 損失=0.7124, 準確率=83.88%
   批次 300/782: 損失=0.7114, 準確率=83.95%
   批次 350/782: 損失=0.7151, 準確率=83.71%
   批次 400/782: 損失=0.7179, 準確率=83.64%
   批次 450/782: 損失=0.7176, 準確率=83.65%
   批次 500/782: 損失=0.7178, 準確率=83.62%
   批次 550/782: 損失=0.7195, 準確率=83.49%
   批次 600/782: 損失=0.7208, 準確率=83.43%
   批次 650/782: 損失=0.7213, 準確率=83.43%
   批次 700/782: 損失=0.7217, 準確率=83.34%
   批次 750/782: 損失=0.7218, 準確率=83.40%
   批次 782/782: 損失=0.7224, 準確率=83.39%
Epoch 56 完成: 訓練=83.39%, 驗證=77.28%, 時間=70.1s
   📊 訓練-驗證差異: 6.11%

Epoch 57/100, LR: 0.001225
   批次  50/782: 損失=0.7072, 準確率=84.03%
   批次 100/782: 損失=0.7042, 準確率=84.39%
   批次 150/782: 損失=0.7034, 準確率=84.57%
   批次 200/782: 損失=0.7067, 準確率=84.40%
   批次 250/782: 損失=0.7077, 準確率=84.22%
   批次 300/782: 損失=0.7108, 準確率=84.03%
   批次 350/782: 損失=0.7106, 準確率=84.07%
   批次 400/782: 損失=0.7144, 準確率=83.84%
   批次 450/782: 損失=0.7146, 準確率=83.91%
   批次 500/782: 損失=0.7150, 準確率=83.85%
   批次 550/782: 損失=0.7141, 準確率=83.94%
   批次 600/782: 損失=0.7152, 準確率=83.81%
   批次 650/782: 損失=0.7189, 準確率=83.66%
   批次 700/782: 損失=0.7199, 準確率=83.57%
   批次 750/782: 損失=0.7185, 準確率=83.60%
   批次 782/782: 損失=0.7186, 準確率=83.62%
Epoch 57 完成: 訓練=83.62%, 驗證=77.51%, 時間=71.6s
   📊 訓練-驗證差異: 6.11%
   💾 新最佳模型已保存: 驗證準確率 77.51%

Epoch 58/100, LR: 0.001179
   批次  50/782: 損失=0.7073, 準確率=84.44%
   批次 100/782: 損失=0.7064, 準確率=84.48%
   批次 150/782: 損失=0.7111, 準確率=84.29%
   批次 200/782: 損失=0.7097, 準確率=84.32%
   批次 250/782: 損失=0.7116, 準確率=84.17%
   批次 300/782: 損失=0.7131, 準確率=84.04%
   批次 350/782: 損失=0.7099, 準確率=84.18%
   批次 400/782: 損失=0.7108, 準確率=84.15%
   批次 450/782: 損失=0.7093, 準確率=84.21%
   批次 500/782: 損失=0.7083, 準確率=84.28%
   批次 550/782: 損失=0.7085, 準確率=84.27%
   批次 600/782: 損失=0.7089, 準確率=84.27%
   批次 650/782: 損失=0.7093, 準確率=84.26%
   批次 700/782: 損失=0.7103, 準確率=84.21%
   批次 750/782: 損失=0.7105, 準確率=84.17%
   批次 782/782: 損失=0.7116, 準確率=84.14%
Epoch 58 完成: 訓練=84.14%, 驗證=77.38%, 時間=71.9s
   📊 訓練-驗證差異: 6.76%

Epoch 59/100, LR: 0.001133
   批次  50/782: 損失=0.6976, 準確率=84.28%
   批次 100/782: 損失=0.7075, 準確率=84.19%
   批次 150/782: 損失=0.7114, 準確率=83.89%
   批次 200/782: 損失=0.7098, 準確率=84.06%
   批次 250/782: 損失=0.7103, 準確率=84.03%
   批次 300/782: 損失=0.7096, 準確率=84.03%
   批次 350/782: 損失=0.7085, 準確率=84.06%
   批次 400/782: 損失=0.7072, 準確率=84.01%
   批次 450/782: 損失=0.7089, 準確率=83.98%
   批次 500/782: 損失=0.7067, 準確率=84.11%
   批次 550/782: 損失=0.7074, 準確率=84.10%
   批次 600/782: 損失=0.7084, 準確率=84.03%
   批次 650/782: 損失=0.7103, 準確率=83.93%
   批次 700/782: 損失=0.7112, 準確率=83.88%
   批次 750/782: 損失=0.7110, 準確率=83.92%
   批次 782/782: 損失=0.7115, 準確率=83.93%
Epoch 59 完成: 訓練=83.93%, 驗證=77.47%, 時間=72.2s
   📊 訓練-驗證差異: 6.46%

Epoch 60/100, LR: 0.001088
   批次  50/782: 損失=0.6985, 準確率=84.50%
   批次 100/782: 損失=0.6946, 準確率=84.59%
   批次 150/782: 損失=0.6988, 準確率=84.48%
   批次 200/782: 損失=0.7018, 準確率=84.16%
   批次 250/782: 損失=0.6973, 準確率=84.38%
   批次 300/782: 損失=0.6975, 準確率=84.41%
   批次 350/782: 損失=0.6973, 準確率=84.41%
   批次 400/782: 損失=0.6983, 準確率=84.46%
   批次 450/782: 損失=0.6984, 準確率=84.44%
   批次 500/782: 損失=0.6993, 準確率=84.50%
   批次 550/782: 損失=0.6997, 準確率=84.47%
   批次 600/782: 損失=0.7010, 準確率=84.42%
   批次 650/782: 損失=0.7037, 準確率=84.29%
   批次 700/782: 損失=0.7047, 準確率=84.27%
   批次 750/782: 損失=0.7058, 準確率=84.24%
   批次 782/782: 損失=0.7060, 準確率=84.21%
Epoch 60 完成: 訓練=84.21%, 驗證=77.03%, 時間=72.4s
   📊 訓練-驗證差異: 7.18%

Epoch 61/100, LR: 0.001043
   批次  50/782: 損失=0.7023, 準確率=83.94%
   批次 100/782: 損失=0.6957, 準確率=84.42%
   批次 150/782: 損失=0.6931, 準確率=84.81%
   批次 200/782: 損失=0.6935, 準確率=84.96%
   批次 250/782: 損失=0.7016, 準確率=84.57%
   批次 300/782: 損失=0.7016, 準確率=84.57%
   批次 350/782: 損失=0.7008, 準確率=84.56%
   批次 400/782: 損失=0.7005, 準確率=84.54%
   批次 450/782: 損失=0.7031, 準確率=84.33%
   批次 500/782: 損失=0.7044, 準確率=84.19%
   批次 550/782: 損失=0.7050, 準確率=84.10%
   批次 600/782: 損失=0.7061, 準確率=84.05%
   批次 650/782: 損失=0.7064, 準確率=84.06%
   批次 700/782: 損失=0.7052, 準確率=84.13%
   批次 750/782: 損失=0.7041, 準確率=84.18%
   批次 782/782: 損失=0.7044, 準確率=84.16%
Epoch 61 完成: 訓練=84.16%, 驗證=77.68%, 時間=73.2s
   📊 訓練-驗證差異: 6.48%
   💾 新最佳模型已保存: 驗證準確率 77.68%

Epoch 62/100, LR: 0.000999
   批次  50/782: 損失=0.6768, 準確率=84.97%
   批次 100/782: 損失=0.6823, 準確率=84.86%
   批次 150/782: 損失=0.6890, 準確率=84.52%
   批次 200/782: 損失=0.6873, 準確率=84.73%
   批次 250/782: 損失=0.6874, 準確率=84.89%
   批次 300/782: 損失=0.6907, 準確率=84.81%
   批次 350/782: 損失=0.6946, 準確率=84.63%
   批次 400/782: 損失=0.6957, 準確率=84.67%
   批次 450/782: 損失=0.6955, 準確率=84.68%
   批次 500/782: 損失=0.6962, 準確率=84.68%
   批次 550/782: 損失=0.6980, 準確率=84.58%
   批次 600/782: 損失=0.6968, 準確率=84.62%
   批次 650/782: 損失=0.6957, 準確率=84.66%
   批次 700/782: 損失=0.6973, 準確率=84.54%
   批次 750/782: 損失=0.6982, 準確率=84.51%
   批次 782/782: 損失=0.6982, 準確率=84.51%
Epoch 62 完成: 訓練=84.51%, 驗證=77.57%, 時間=72.4s
   📊 訓練-驗證差異: 6.94%

Epoch 63/100, LR: 0.000955
   批次  50/782: 損失=0.6749, 準確率=85.47%
   批次 100/782: 損失=0.6812, 準確率=85.20%
   批次 150/782: 損失=0.6845, 準確率=85.17%
   批次 200/782: 損失=0.6865, 準確率=85.10%
   批次 250/782: 損失=0.6893, 準確率=85.03%
   批次 300/782: 損失=0.6901, 準確率=84.91%
   批次 350/782: 損失=0.6898, 準確率=84.95%
   批次 400/782: 損失=0.6901, 準確率=84.92%
   批次 450/782: 損失=0.6917, 準確率=84.83%
   批次 500/782: 損失=0.6924, 準確率=84.79%
   批次 550/782: 損失=0.6939, 準確率=84.65%
   批次 600/782: 損失=0.6933, 準確率=84.66%
   批次 650/782: 損失=0.6935, 準確率=84.71%
   批次 700/782: 損失=0.6931, 準確率=84.75%
   批次 750/782: 損失=0.6941, 準確率=84.71%
   批次 782/782: 損失=0.6944, 準確率=84.69%
Epoch 63 完成: 訓練=84.69%, 驗證=77.80%, 時間=72.4s
   📊 訓練-驗證差異: 6.89%
   💾 新最佳模型已保存: 驗證準確率 77.80%

Epoch 64/100, LR: 0.000911
   批次  50/782: 損失=0.6589, 準確率=86.09%
   批次 100/782: 損失=0.6608, 準確率=86.06%
   批次 150/782: 損失=0.6690, 準確率=85.88%
   批次 200/782: 損失=0.6749, 準確率=85.46%
   批次 250/782: 損失=0.6789, 準確率=85.20%
   批次 300/782: 損失=0.6817, 準確率=85.08%
   批次 350/782: 損失=0.6824, 準確率=85.09%
   批次 400/782: 損失=0.6835, 準確率=85.07%
   批次 450/782: 損失=0.6875, 準確率=84.87%
   批次 500/782: 損失=0.6893, 準確率=84.86%
   批次 550/782: 損失=0.6905, 準確率=84.77%
   批次 600/782: 損失=0.6908, 準確率=84.70%
   批次 650/782: 損失=0.6904, 準確率=84.73%
   批次 700/782: 損失=0.6906, 準確率=84.77%
   批次 750/782: 損失=0.6907, 準確率=84.78%
   批次 782/782: 損失=0.6900, 準確率=84.83%
Epoch 64 完成: 訓練=84.83%, 驗證=77.57%, 時間=73.0s
   📊 訓練-驗證差異: 7.26%

Epoch 65/100, LR: 0.000868
   批次  50/782: 損失=0.6862, 準確率=85.59%
   批次 100/782: 損失=0.6764, 準確率=85.33%
   批次 150/782: 損失=0.6763, 準確率=85.34%
   批次 200/782: 損失=0.6829, 準確率=85.09%
   批次 250/782: 損失=0.6845, 準確率=85.11%
   批次 300/782: 損失=0.6834, 準確率=85.18%
   批次 350/782: 損失=0.6839, 準確率=85.08%
   批次 400/782: 損失=0.6843, 準確率=84.98%
   批次 450/782: 損失=0.6863, 準確率=84.91%
   批次 500/782: 損失=0.6859, 準確率=84.94%
   批次 550/782: 損失=0.6842, 準確率=85.01%
   批次 600/782: 損失=0.6869, 準確率=84.90%
   批次 650/782: 損失=0.6870, 準確率=84.93%
   批次 700/782: 損失=0.6877, 準確率=84.96%
   批次 750/782: 損失=0.6873, 準確率=85.00%
   批次 782/782: 損失=0.6877, 準確率=84.97%
Epoch 65 完成: 訓練=84.97%, 驗證=77.54%, 時間=72.3s
   📊 訓練-驗證差異: 7.43%

Epoch 66/100, LR: 0.000826
   批次  50/782: 損失=0.6698, 準確率=86.66%
   批次 100/782: 損失=0.6553, 準確率=87.00%
   批次 150/782: 損失=0.6662, 準確率=86.49%
   批次 200/782: 損失=0.6712, 準確率=86.08%
   批次 250/782: 損失=0.6737, 準確率=85.88%
   批次 300/782: 損失=0.6745, 準確率=85.88%
   批次 350/782: 損失=0.6767, 準確率=85.73%
   批次 400/782: 損失=0.6777, 準確率=85.62%
   批次 450/782: 損失=0.6789, 準確率=85.52%
   批次 500/782: 損失=0.6801, 準確率=85.38%
   批次 550/782: 損失=0.6791, 準確率=85.42%
   批次 600/782: 損失=0.6811, 準確率=85.32%
   批次 650/782: 損失=0.6818, 準確率=85.29%
   批次 700/782: 損失=0.6814, 準確率=85.25%
   批次 750/782: 損失=0.6827, 準確率=85.22%
   批次 782/782: 損失=0.6832, 準確率=85.21%
Epoch 66 完成: 訓練=85.21%, 驗證=77.54%, 時間=71.7s
   📊 訓練-驗證差異: 7.67%

Epoch 67/100, LR: 0.000785
   批次  50/782: 損失=0.6777, 準確率=85.66%
   批次 100/782: 損失=0.6661, 準確率=86.06%
   批次 150/782: 損失=0.6715, 準確率=85.76%
   批次 200/782: 損失=0.6737, 準確率=85.56%
   批次 250/782: 損失=0.6743, 準確率=85.47%
   批次 300/782: 損失=0.6738, 準確率=85.54%
   批次 350/782: 損失=0.6711, 準確率=85.74%
   批次 400/782: 損失=0.6715, 準確率=85.75%
   批次 450/782: 損失=0.6751, 準確率=85.54%
   批次 500/782: 損失=0.6758, 準確率=85.50%
   批次 550/782: 損失=0.6756, 準確率=85.53%
   批次 600/782: 損失=0.6762, 準確率=85.50%
   批次 650/782: 損失=0.6786, 準確率=85.38%
   批次 700/782: 損失=0.6788, 準確率=85.37%
   批次 750/782: 損失=0.6800, 準確率=85.32%
   批次 782/782: 損失=0.6800, 準確率=85.33%
Epoch 67 完成: 訓練=85.33%, 驗證=77.81%, 時間=72.3s
   📊 訓練-驗證差異: 7.52%
   💾 新最佳模型已保存: 驗證準確率 77.81%

Epoch 68/100, LR: 0.000744
   批次  50/782: 損失=0.6778, 準確率=86.00%
   批次 100/782: 損失=0.6741, 準確率=86.16%
   批次 150/782: 損失=0.6668, 準確率=86.34%
   批次 200/782: 損失=0.6727, 準確率=85.91%
   批次 250/782: 損失=0.6772, 準確率=85.79%
   批次 300/782: 損失=0.6718, 準確率=85.97%
   批次 350/782: 損失=0.6713, 準確率=85.97%
   批次 400/782: 損失=0.6734, 準確率=85.80%
   批次 450/782: 損失=0.6746, 準確率=85.74%
   批次 500/782: 損失=0.6744, 準確率=85.74%
   批次 550/782: 損失=0.6746, 準確率=85.73%
   批次 600/782: 損失=0.6747, 準確率=85.68%
   批次 650/782: 損失=0.6757, 準確率=85.69%
   批次 700/782: 損失=0.6772, 準確率=85.56%
   批次 750/782: 損失=0.6771, 準確率=85.59%
   批次 782/782: 損失=0.6773, 準確率=85.55%
Epoch 68 完成: 訓練=85.55%, 驗證=77.86%, 時間=73.7s
   📊 訓練-驗證差異: 7.69%
   💾 新最佳模型已保存: 驗證準確率 77.86%

Epoch 69/100, LR: 0.000704
   批次  50/782: 損失=0.6714, 準確率=86.03%
   批次 100/782: 損失=0.6660, 準確率=85.98%
   批次 150/782: 損失=0.6687, 準確率=85.83%
   批次 200/782: 損失=0.6697, 準確率=85.79%
   批次 250/782: 損失=0.6725, 準確率=85.70%
   批次 300/782: 損失=0.6719, 準確率=85.75%
   批次 350/782: 損失=0.6706, 準確率=85.76%
   批次 400/782: 損失=0.6694, 準確率=85.84%
   批次 450/782: 損失=0.6691, 準確率=85.87%
   批次 500/782: 損失=0.6712, 準確率=85.79%
   批次 550/782: 損失=0.6718, 準確率=85.77%
   批次 600/782: 損失=0.6730, 準確率=85.73%
   批次 650/782: 損失=0.6748, 準確率=85.62%
   批次 700/782: 損失=0.6747, 準確率=85.60%
   批次 750/782: 損失=0.6765, 準確率=85.52%
   批次 782/782: 損失=0.6770, 準確率=85.49%
Epoch 69 完成: 訓練=85.49%, 驗證=77.74%, 時間=72.0s
   📊 訓練-驗證差異: 7.75%

Epoch 70/100, LR: 0.000665
   批次  50/782: 損失=0.6606, 準確率=86.59%
   批次 100/782: 損失=0.6519, 準確率=86.77%
   批次 150/782: 損失=0.6566, 準確率=86.58%
   批次 200/782: 損失=0.6541, 準確率=86.67%
   批次 250/782: 損失=0.6576, 準確率=86.47%
   批次 300/782: 損失=0.6626, 準確率=86.32%
   批次 350/782: 損失=0.6632, 準確率=86.23%
   批次 400/782: 損失=0.6633, 準確率=86.17%
   批次 450/782: 損失=0.6637, 準確率=86.11%
   批次 500/782: 損失=0.6641, 準確率=86.14%
   批次 550/782: 損失=0.6656, 準確率=86.10%
   批次 600/782: 損失=0.6654, 準確率=86.08%
   批次 650/782: 損失=0.6658, 準確率=86.05%
   批次 700/782: 損失=0.6665, 準確率=86.01%
   批次 750/782: 損失=0.6672, 準確率=86.02%
   批次 782/782: 損失=0.6672, 準確率=86.02%
Epoch 70 完成: 訓練=86.02%, 驗證=78.07%, 時間=70.6s
   📊 訓練-驗證差異: 7.95%
   💾 新最佳模型已保存: 驗證準確率 78.07%

Epoch 71/100, LR: 0.000626
   批次  50/782: 損失=0.6585, 準確率=87.00%
   批次 100/782: 損失=0.6668, 準確率=86.38%
   批次 150/782: 損失=0.6619, 準確率=86.27%
   批次 200/782: 損失=0.6614, 準確率=86.34%
   批次 250/782: 損失=0.6584, 準確率=86.34%
   批次 300/782: 損失=0.6588, 準確率=86.34%
   批次 350/782: 損失=0.6597, 準確率=86.29%
   批次 400/782: 損失=0.6607, 準確率=86.21%
   批次 450/782: 損失=0.6609, 準確率=86.22%
   批次 500/782: 損失=0.6604, 準確率=86.19%
   批次 550/782: 損失=0.6633, 準確率=86.05%
   批次 600/782: 損失=0.6651, 準確率=86.02%
   批次 650/782: 損失=0.6654, 準確率=86.02%
   批次 700/782: 損失=0.6655, 準確率=85.96%
   批次 750/782: 損失=0.6658, 準確率=85.91%
   批次 782/782: 損失=0.6670, 準確率=85.85%
Epoch 71 完成: 訓練=85.85%, 驗證=78.01%, 時間=74.6s
   📊 訓練-驗證差異: 7.84%

Epoch 72/100, LR: 0.000589
   批次  50/782: 損失=0.6422, 準確率=86.97%
   批次 100/782: 損失=0.6427, 準確率=87.08%
   批次 150/782: 損失=0.6490, 準確率=86.66%
   批次 200/782: 損失=0.6548, 準確率=86.46%
   批次 250/782: 損失=0.6573, 準確率=86.29%
   批次 300/782: 損失=0.6614, 準確率=86.17%
   批次 350/782: 損失=0.6627, 準確率=86.12%
   批次 400/782: 損失=0.6628, 準確率=86.08%
   批次 450/782: 損失=0.6616, 準確率=86.10%
   批次 500/782: 損失=0.6623, 準確率=86.12%
   批次 550/782: 損失=0.6624, 準確率=86.15%
   批次 600/782: 損失=0.6613, 準確率=86.14%
   批次 650/782: 損失=0.6602, 準確率=86.18%
   批次 700/782: 損失=0.6618, 準確率=86.14%
   批次 750/782: 損失=0.6629, 準確率=86.10%
   批次 782/782: 損失=0.6638, 準確率=86.06%
Epoch 72 完成: 訓練=86.06%, 驗證=77.74%, 時間=73.2s
   ⚠️  過擬合警告: 差異 8.32% > 閾值 8.0% (1/6)
   📊 訓練-驗證差異: 8.32%

Epoch 73/100, LR: 0.000552
   批次  50/782: 損失=0.6436, 準確率=87.19%
   批次 100/782: 損失=0.6449, 準確率=86.91%
   批次 150/782: 損失=0.6491, 準確率=86.80%
   批次 200/782: 損失=0.6521, 準確率=86.54%
   批次 250/782: 損失=0.6547, 準確率=86.48%
   批次 300/782: 損失=0.6563, 準確率=86.46%
   批次 350/782: 損失=0.6555, 準確率=86.62%
   批次 400/782: 損失=0.6555, 準確率=86.66%
   批次 450/782: 損失=0.6559, 準確率=86.62%
   批次 500/782: 損失=0.6557, 準確率=86.63%
   批次 550/782: 損失=0.6552, 準確率=86.59%
   批次 600/782: 損失=0.6571, 準確率=86.50%
   批次 650/782: 損失=0.6581, 準確率=86.48%
   批次 700/782: 損失=0.6585, 準確率=86.44%
   批次 750/782: 損失=0.6606, 準確率=86.34%
   批次 782/782: 損失=0.6614, 準確率=86.30%
Epoch 73 完成: 訓練=86.30%, 驗證=78.15%, 時間=70.8s
   ⚠️  過擬合警告: 差異 8.15% > 閾值 8.0% (2/6)
   📊 訓練-驗證差異: 8.15%
   💾 新最佳模型已保存: 驗證準確率 78.15%

Epoch 74/100, LR: 0.000516
   批次  50/782: 損失=0.6428, 準確率=86.59%
   批次 100/782: 損失=0.6481, 準確率=86.55%
   批次 150/782: 損失=0.6461, 準確率=86.82%
   批次 200/782: 損失=0.6494, 準確率=86.62%
   批次 250/782: 損失=0.6537, 準確率=86.41%
   批次 300/782: 損失=0.6535, 準確率=86.38%
   批次 350/782: 損失=0.6541, 準確率=86.33%
   批次 400/782: 損失=0.6552, 準確率=86.33%
   批次 450/782: 損失=0.6542, 準確率=86.42%
   批次 500/782: 損失=0.6546, 準確率=86.41%
   批次 550/782: 損失=0.6548, 準確率=86.38%
   批次 600/782: 損失=0.6549, 準確率=86.38%
   批次 650/782: 損失=0.6556, 準確率=86.45%
   批次 700/782: 損失=0.6565, 準確率=86.40%
   批次 750/782: 損失=0.6567, 準確率=86.43%
   批次 782/782: 損失=0.6566, 準確率=86.41%
Epoch 74 完成: 訓練=86.41%, 驗證=78.07%, 時間=73.7s
   ⚠️  過擬合警告: 差異 8.34% > 閾值 8.0% (3/6)
   📊 訓練-驗證差異: 8.34%

Epoch 75/100, LR: 0.000482
   批次  50/782: 損失=0.6457, 準確率=87.53%
   批次 100/782: 損失=0.6363, 準確率=87.81%
   批次 150/782: 損失=0.6412, 準確率=87.41%
   批次 200/782: 損失=0.6465, 準確率=87.06%
   批次 250/782: 損失=0.6494, 準確率=86.94%
   批次 300/782: 損失=0.6517, 準確率=86.72%
   批次 350/782: 損失=0.6539, 準確率=86.62%
   批次 400/782: 損失=0.6544, 準確率=86.64%
   批次 450/782: 損失=0.6531, 準確率=86.73%
   批次 500/782: 損失=0.6525, 準確率=86.74%
   批次 550/782: 損失=0.6525, 準確率=86.76%
   批次 600/782: 損失=0.6527, 準確率=86.75%
   批次 650/782: 損失=0.6532, 準確率=86.73%
   批次 700/782: 損失=0.6542, 準確率=86.67%
   批次 750/782: 損失=0.6546, 準確率=86.61%
   批次 782/782: 損失=0.6546, 準確率=86.62%
Epoch 75 完成: 訓練=86.62%, 驗證=77.94%, 時間=69.5s
   ⚠️  過擬合警告: 差異 8.68% > 閾值 8.0% (4/6)
   📊 訓練-驗證差異: 8.68%

Epoch 76/100, LR: 0.000448
   批次  50/782: 損失=0.6571, 準確率=86.78%
   批次 100/782: 損失=0.6564, 準確率=86.78%
   批次 150/782: 損失=0.6564, 準確率=86.66%
   批次 200/782: 損失=0.6541, 準確率=86.72%
   批次 250/782: 損失=0.6509, 準確率=86.79%
   批次 300/782: 損失=0.6494, 準確率=86.82%
   批次 350/782: 損失=0.6480, 準確率=86.86%
   批次 400/782: 損失=0.6490, 準確率=86.78%
   批次 450/782: 損失=0.6504, 準確率=86.76%
   批次 500/782: 損失=0.6509, 準確率=86.75%
   批次 550/782: 損失=0.6514, 準確率=86.71%
   批次 600/782: 損失=0.6512, 準確率=86.72%
   批次 650/782: 損失=0.6510, 準確率=86.76%
   批次 700/782: 損失=0.6518, 準確率=86.70%
   批次 750/782: 損失=0.6521, 準確率=86.66%
   批次 782/782: 損失=0.6525, 準確率=86.68%
Epoch 76 完成: 訓練=86.68%, 驗證=77.84%, 時間=70.8s
   ⚠️  過擬合警告: 差異 8.84% > 閾值 8.0% (5/6)
   📊 訓練-驗證差異: 8.84%

Epoch 77/100, LR: 0.000415
   批次  50/782: 損失=0.6164, 準確率=88.28%
   批次 100/782: 損失=0.6258, 準確率=88.00%
   批次 150/782: 損失=0.6327, 準確率=87.82%
   批次 200/782: 損失=0.6333, 準確率=87.67%
   批次 250/782: 損失=0.6347, 準確率=87.50%
   批次 300/782: 損失=0.6343, 準確率=87.43%
   批次 350/782: 損失=0.6328, 準確率=87.46%
   批次 400/782: 損失=0.6360, 準確率=87.34%
   批次 450/782: 損失=0.6377, 準確率=87.27%
   批次 500/782: 損失=0.6408, 準確率=87.16%
   批次 550/782: 損失=0.6431, 準確率=87.07%
   批次 600/782: 損失=0.6429, 準確率=87.11%
   批次 650/782: 損失=0.6431, 準確率=87.13%
   批次 700/782: 損失=0.6443, 準確率=86.99%
   批次 750/782: 損失=0.6458, 準確率=86.93%
   批次 782/782: 損失=0.6469, 準確率=86.89%
Epoch 77 完成: 訓練=86.89%, 驗證=77.89%, 時間=71.2s
   ⚠️  過擬合警告: 差異 9.00% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 5556.2s (92.6min)
   • 實際訓練epochs: 77 / 100
   • 平均每epoch: 72.2s
   • 最佳驗證準確率: 78.15%
   • 早停原因: 過擬合檢測 (差異: 9.00%)
   • 已載入最佳模型權重

📈 繪製超快速訓練歷史...

📊 評估超縮小版模型...
   ✓ 整體準確率: 78.15%

🎉 超快速訓練完成!
   • 模型大小: Test
   • 最終準確率: 78.15%
   • 總訓練時間: 92.6 分鐘
   • 平均每epoch: 72.2 秒