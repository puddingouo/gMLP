📋 超縮小版 gMLP 模型架構比較:
=====================================================================================
模型       深度     維度       FFN倍數    參數(M)      過擬合風險
-------------------------------------------------------------------------------------
Nano     6      64       2        0.3        很低
XS       8      80       3        0.8        低
S        12     128      3        2.0        中等
M        16     160      4        4.5        較高
L        30     128      6        5.9        很高
-------------------------------------------------------------------------------------
🎯 建議（針對10K訓練樣本）:
   • Nano: 極速原型開發，最低過擬合風險 (<1分鐘訓練)
   • XS: 快速實驗，低過擬合風險 (~2分鐘訓練) ⭐推薦
   • S: 平衡性能與速度，中等過擬合風險 (~5分鐘訓練)
   • M: 較好性能但過擬合風險較高 (~10分鐘訓練)
   • L: 最大模型，很高過擬合風險，不建議用於小數據集
📦 加載超快速 CIFAR-10 數據集...
   🚀 超快速模式：小規模數據集訓練
   ✓ 訓練樣本: 30000
   ✓ 測試樣本: 5000
   ✓ Batch大小: 64

🏗️ 創建超縮小版 gMLP-Nano 模型...
   ⚡ CPU模式：已設置4個線程
   ✓ 超縮小版 gMLP-Nano 模型創建完成
   ✓ 設備: cpu
   ✓ 參數數量: 105,290 (0.11M)
   ✓ 目標參數: 0.3M
   ✓ 模型大小: 0.4 MB
   ✓ 架構: depth=6, dim=64, ff_mult=2

🏋️ 開始超快速訓練 (50 個 epochs)...
   🛡️  啟用過擬合早停保護

Epoch 1/50, LR: 0.003000
   批次 20/469: 損失=2.1481, 準確率=20.86%
   批次 40/469: 損失=2.0601, 準確率=22.66%
   批次 60/469: 損失=2.0064, 準確率=25.83%
   批次 80/469: 損失=1.9555, 準確率=28.26%
   批次 100/469: 損失=1.9167, 準確率=30.30%
   批次 120/469: 損失=1.8827, 準確率=32.03%
   批次 140/469: 損失=1.8555, 準確率=33.40%
   批次 160/469: 損失=1.8416, 準確率=33.96%
   批次 180/469: 損失=1.8231, 準確率=34.61%
   批次 200/469: 損失=1.8040, 準確率=35.45%
   批次 220/469: 損失=1.7887, 準確率=36.24%
   批次 240/469: 損失=1.7699, 準確率=37.10%
   批次 260/469: 損失=1.7532, 準確率=37.79%
   批次 280/469: 損失=1.7424, 準確率=38.33%
   批次 300/469: 損失=1.7319, 準確率=38.86%
   批次 320/469: 損失=1.7216, 準確率=39.43%
   批次 340/469: 損失=1.7118, 準確率=39.92%
   批次 360/469: 損失=1.7048, 準確率=40.21%
   批次 380/469: 損失=1.6962, 準確率=40.59%
   批次 400/469: 損失=1.6902, 準確率=40.93%
   批次 420/469: 損失=1.6805, 準確率=41.33%
   批次 440/469: 損失=1.6724, 準確率=41.69%
   批次 460/469: 損失=1.6656, 準確率=42.05%
Epoch 1 完成: 訓練=42.14%, 驗證=50.16%, 時間=61.1s
   💾 新最佳模型已保存: 驗證準確率 50.16%

Epoch 2/50, LR: 0.002997
   批次 20/469: 損失=1.4984, 準確率=49.30%
   批次 40/469: 損失=1.4877, 準確率=49.45%
   批次 60/469: 損失=1.4818, 準確率=49.61%
   批次 80/469: 損失=1.4883, 準確率=49.28%
   批次 100/469: 損失=1.4793, 準確率=50.03%
   批次 120/469: 損失=1.4767, 準確率=50.07%
   批次 140/469: 損失=1.4755, 準確率=50.16%
   批次 160/469: 損失=1.4712, 準確率=50.50%
   批次 180/469: 損失=1.4692, 準確率=50.76%
   批次 200/469: 損失=1.4705, 準確率=50.84%
   批次 220/469: 損失=1.4693, 準確率=50.97%
   批次 240/469: 損失=1.4653, 準確率=51.03%
   批次 260/469: 損失=1.4623, 準確率=51.07%
   批次 280/469: 損失=1.4559, 準確率=51.49%
   批次 300/469: 損失=1.4533, 準確率=51.60%
   批次 320/469: 損失=1.4504, 準確率=51.67%
   批次 340/469: 損失=1.4454, 準確率=51.83%
   批次 360/469: 損失=1.4419, 準確率=52.03%
   批次 380/469: 損失=1.4382, 準確率=52.18%
   批次 400/469: 損失=1.4364, 準確率=52.34%
   批次 420/469: 損失=1.4320, 準確率=52.53%
   批次 440/469: 損失=1.4274, 準確率=52.72%
   批次 460/469: 損失=1.4248, 準確率=52.90%
Epoch 2 完成: 訓練=52.92%, 驗證=57.72%, 時間=61.9s
   💾 新最佳模型已保存: 驗證準確率 57.72%

Epoch 3/50, LR: 0.002988
   批次 20/469: 損失=1.3578, 準確率=54.92%
   批次 40/469: 損失=1.3445, 準確率=55.31%
   批次 60/469: 損失=1.3458, 準確率=55.68%
   批次 80/469: 損失=1.3424, 準確率=56.25%
   批次 100/469: 損失=1.3341, 準確率=56.48%
   批次 120/469: 損失=1.3302, 準確率=56.74%
   批次 140/469: 損失=1.3328, 準確率=56.73%
   批次 160/469: 損失=1.3359, 準確率=56.67%
   批次 180/469: 損失=1.3346, 準確率=56.69%
   批次 200/469: 損失=1.3338, 準確率=56.64%
   批次 220/469: 損失=1.3370, 準確率=56.63%
   批次 240/469: 損失=1.3337, 準確率=56.88%
   批次 260/469: 損失=1.3342, 準確率=56.79%
   批次 280/469: 損失=1.3313, 準確率=56.97%
   批次 300/469: 損失=1.3289, 準確率=57.09%
   批次 320/469: 損失=1.3302, 準確率=57.04%
   批次 340/469: 損失=1.3275, 準確率=57.18%
   批次 360/469: 損失=1.3257, 準確率=57.23%
   批次 380/469: 損失=1.3249, 準確率=57.24%
   批次 400/469: 損失=1.3224, 準確率=57.36%
   批次 420/469: 損失=1.3203, 準確率=57.43%
   批次 440/469: 損失=1.3157, 準確率=57.67%
   批次 460/469: 損失=1.3122, 準確率=57.83%
Epoch 3 完成: 訓練=57.85%, 驗證=60.34%, 時間=65.4s
   💾 新最佳模型已保存: 驗證準確率 60.34%

Epoch 4/50, LR: 0.002974
   批次 20/469: 損失=1.2327, 準確率=61.25%
   批次 40/469: 損失=1.2313, 準確率=61.45%
   批次 60/469: 損失=1.2379, 準確率=60.86%
   批次 80/469: 損失=1.2460, 準確率=60.84%
   批次 100/469: 損失=1.2529, 準確率=60.47%
   批次 120/469: 損失=1.2477, 準確率=60.65%
   批次 140/469: 損失=1.2481, 準確率=60.67%
   批次 160/469: 損失=1.2474, 準確率=60.58%
   批次 180/469: 損失=1.2449, 準確率=60.48%
   批次 200/469: 損失=1.2496, 準確率=60.34%
   批次 220/469: 損失=1.2522, 準確率=60.20%
   批次 240/469: 損失=1.2494, 準確率=60.41%
   批次 260/469: 損失=1.2490, 準確率=60.49%
   批次 280/469: 損失=1.2469, 準確率=60.49%
   批次 300/469: 損失=1.2414, 準確率=60.75%
   批次 320/469: 損失=1.2409, 準確率=60.79%
   批次 340/469: 損失=1.2377, 準確率=60.95%
   批次 360/469: 損失=1.2377, 準確率=60.95%
   批次 380/469: 損失=1.2359, 準確率=61.04%
   批次 400/469: 損失=1.2362, 準確率=61.05%
   批次 420/469: 損失=1.2342, 準確率=61.19%
   批次 440/469: 損失=1.2341, 準確率=61.14%
   批次 460/469: 損失=1.2353, 準確率=61.10%
Epoch 4 完成: 訓練=61.01%, 驗證=62.58%, 時間=61.3s
   💾 新最佳模型已保存: 驗證準確率 62.58%

Epoch 5/50, LR: 0.002953
   批次 20/469: 損失=1.1821, 準確率=63.28%
   批次 40/469: 損失=1.1859, 準確率=63.28%
   批次 60/469: 損失=1.1831, 準確率=63.78%
   批次 80/469: 損失=1.1823, 準確率=63.59%
   批次 100/469: 損失=1.1797, 準確率=63.50%
   批次 120/469: 損失=1.1817, 準確率=63.28%
   批次 140/469: 損失=1.1788, 準確率=63.50%
   批次 160/469: 損失=1.1806, 準確率=63.52%
   批次 180/469: 損失=1.1797, 準確率=63.71%
   批次 200/469: 損失=1.1805, 準確率=63.80%
   批次 220/469: 損失=1.1804, 準確率=63.77%
   批次 240/469: 損失=1.1812, 準確率=63.67%
   批次 260/469: 損失=1.1846, 準確率=63.53%
   批次 280/469: 損失=1.1850, 準確率=63.49%
   批次 300/469: 損失=1.1843, 準確率=63.43%
   批次 320/469: 損失=1.1840, 準確率=63.36%
   批次 340/469: 損失=1.1835, 準確率=63.40%
   批次 360/469: 損失=1.1820, 準確率=63.42%
   批次 380/469: 損失=1.1822, 準確率=63.37%
   批次 400/469: 損失=1.1841, 準確率=63.30%
   批次 420/469: 損失=1.1853, 準確率=63.33%
   批次 440/469: 損失=1.1848, 準確率=63.40%
   批次 460/469: 損失=1.1834, 準確率=63.47%
Epoch 5 完成: 訓練=63.48%, 驗證=64.34%, 時間=55.9s
   💾 新最佳模型已保存: 驗證準確率 64.34%

Epoch 6/50, LR: 0.002927
   批次 20/469: 損失=1.1444, 準確率=65.23%
   批次 40/469: 損失=1.1565, 準確率=64.69%
   批次 60/469: 損失=1.1358, 準確率=65.49%
   批次 80/469: 損失=1.1383, 準確率=65.10%
   批次 100/469: 損失=1.1353, 準確率=65.23%
   批次 120/469: 損失=1.1373, 準確率=65.08%
   批次 140/469: 損失=1.1397, 準確率=65.25%
   批次 160/469: 損失=1.1361, 準確率=65.42%
   批次 180/469: 損失=1.1372, 準確率=65.41%
   批次 200/469: 損失=1.1307, 準確率=65.69%
   批次 220/469: 損失=1.1295, 準確率=65.68%
   批次 240/469: 損失=1.1305, 準確率=65.59%
   批次 260/469: 損失=1.1320, 準確率=65.56%
   批次 280/469: 損失=1.1304, 準確率=65.53%
   批次 300/469: 損失=1.1359, 準確率=65.30%
   批次 320/469: 損失=1.1353, 準確率=65.30%
   批次 340/469: 損失=1.1363, 準確率=65.34%
   批次 360/469: 損失=1.1354, 準確率=65.33%
   批次 380/469: 損失=1.1385, 準確率=65.21%
   批次 400/469: 損失=1.1367, 準確率=65.29%
   批次 420/469: 損失=1.1344, 準確率=65.40%
   批次 440/469: 損失=1.1340, 準確率=65.42%
   批次 460/469: 損失=1.1345, 準確率=65.38%
Epoch 6 完成: 訓練=65.44%, 驗證=65.68%, 時間=56.0s
   💾 新最佳模型已保存: 驗證準確率 65.68%

Epoch 7/50, LR: 0.002895
   批次 20/469: 損失=1.1248, 準確率=65.47%
   批次 40/469: 損失=1.1180, 準確率=66.33%
   批次 60/469: 損失=1.1294, 準確率=65.99%
   批次 80/469: 損失=1.1253, 準確率=66.29%
   批次 100/469: 損失=1.1225, 準確率=66.45%
   批次 120/469: 損失=1.1236, 準確率=66.30%
   批次 140/469: 損失=1.1149, 準確率=66.57%
   批次 160/469: 損失=1.1148, 準確率=66.60%
   批次 180/469: 損失=1.1181, 準確率=66.47%
   批次 200/469: 損失=1.1128, 準確率=66.62%
   批次 220/469: 損失=1.1129, 準確率=66.61%
   批次 240/469: 損失=1.1145, 準確率=66.51%
   批次 260/469: 損失=1.1142, 準確率=66.66%
   批次 280/469: 損失=1.1120, 準確率=66.80%
   批次 300/469: 損失=1.1095, 準確率=66.86%
   批次 320/469: 損失=1.1076, 準確率=66.89%
   批次 340/469: 損失=1.1081, 準確率=66.82%
   批次 360/469: 損失=1.1061, 準確率=66.97%
   批次 380/469: 損失=1.1050, 準確率=67.04%
   批次 400/469: 損失=1.1028, 準確率=67.16%
   批次 420/469: 損失=1.1046, 準確率=67.05%
   批次 440/469: 損失=1.1059, 準確率=66.94%
   批次 460/469: 損失=1.1058, 準確率=66.94%
Epoch 7 完成: 訓練=66.95%, 驗證=66.84%, 時間=52.2s
   💾 新最佳模型已保存: 驗證準確率 66.84%

Epoch 8/50, LR: 0.002858
   批次 20/469: 損失=1.0429, 準確率=69.69%
   批次 40/469: 損失=1.0390, 準確率=70.16%
   批次 60/469: 損失=1.0496, 準確率=69.22%
   批次 80/469: 損失=1.0621, 準確率=68.55%
   批次 100/469: 損失=1.0667, 準確率=68.34%
   批次 120/469: 損失=1.0639, 準確率=68.55%
   批次 140/469: 損失=1.0642, 準確率=68.53%
   批次 160/469: 損失=1.0621, 準確率=68.76%
   批次 180/469: 損失=1.0620, 準確率=68.74%
   批次 200/469: 損失=1.0654, 準確率=68.64%
   批次 220/469: 損失=1.0672, 準確率=68.66%
   批次 240/469: 損失=1.0686, 準確率=68.49%
   批次 260/469: 損失=1.0704, 準確率=68.48%
   批次 280/469: 損失=1.0699, 準確率=68.35%
   批次 300/469: 損失=1.0677, 準確率=68.43%
   批次 320/469: 損失=1.0684, 準確率=68.31%
   批次 340/469: 損失=1.0708, 準確率=68.24%
   批次 360/469: 損失=1.0712, 準確率=68.18%
   批次 380/469: 損失=1.0709, 準確率=68.18%
   批次 400/469: 損失=1.0740, 準確率=68.05%
   批次 420/469: 損失=1.0726, 準確率=68.12%
   批次 440/469: 損失=1.0713, 準確率=68.21%
   批次 460/469: 損失=1.0702, 準確率=68.29%
Epoch 8 完成: 訓練=68.30%, 驗證=67.48%, 時間=56.1s
   💾 新最佳模型已保存: 驗證準確率 67.48%

Epoch 9/50, LR: 0.002815
   批次 20/469: 損失=1.0569, 準確率=68.75%
   批次 40/469: 損失=1.0515, 準確率=68.98%
   批次 60/469: 損失=1.0709, 準確率=68.46%
   批次 80/469: 損失=1.0654, 準確率=68.79%
   批次 100/469: 損失=1.0519, 準確率=69.09%
   批次 120/469: 損失=1.0425, 準確率=69.86%
   批次 140/469: 損失=1.0458, 準確率=69.75%
   批次 160/469: 損失=1.0436, 準確率=69.86%
   批次 180/469: 損失=1.0410, 準確率=69.90%
   批次 200/469: 損失=1.0388, 準確率=69.99%
   批次 220/469: 損失=1.0420, 準確率=69.88%
   批次 240/469: 損失=1.0440, 準確率=69.58%
   批次 260/469: 損失=1.0451, 準確率=69.49%
   批次 280/469: 損失=1.0434, 準確率=69.56%
   批次 300/469: 損失=1.0419, 準確率=69.70%
   批次 320/469: 損失=1.0441, 準確率=69.60%
   批次 340/469: 損失=1.0443, 準確率=69.56%
   批次 360/469: 損失=1.0433, 準確率=69.60%
   批次 380/469: 損失=1.0418, 準確率=69.69%
   批次 400/469: 損失=1.0429, 準確率=69.65%
   批次 420/469: 損失=1.0423, 準確率=69.73%
   批次 440/469: 損失=1.0432, 準確率=69.66%
   批次 460/469: 損失=1.0449, 準確率=69.60%
Epoch 9 完成: 訓練=69.62%, 驗證=68.04%, 時間=57.9s
   💾 新最佳模型已保存: 驗證準確率 68.04%

Epoch 10/50, LR: 0.002767
   批次 20/469: 損失=0.9995, 準確率=72.81%
   批次 40/469: 損失=0.9894, 準確率=72.97%
   批次 60/469: 損失=1.0026, 準確率=72.32%
   批次 80/469: 損失=1.0110, 準確率=71.39%
   批次 100/469: 損失=1.0096, 準確率=71.34%
   批次 120/469: 損失=1.0165, 準確率=71.24%
   批次 140/469: 損失=1.0153, 準確率=71.21%
   批次 160/469: 損失=1.0152, 準確率=71.31%
   批次 180/469: 損失=1.0119, 準確率=71.41%
   批次 200/469: 損失=1.0130, 準確率=71.33%
   批次 220/469: 損失=1.0109, 準確率=71.29%
   批次 240/469: 損失=1.0144, 準確率=71.09%
   批次 260/469: 損失=1.0156, 準確率=70.93%
   批次 280/469: 損失=1.0170, 準確率=70.80%
   批次 300/469: 損失=1.0196, 準確率=70.60%
   批次 320/469: 損失=1.0181, 準確率=70.68%
   批次 340/469: 損失=1.0196, 準確率=70.68%
   批次 360/469: 損失=1.0202, 準確率=70.69%
   批次 380/469: 損失=1.0192, 準確率=70.68%
   批次 400/469: 損失=1.0186, 準確率=70.75%
   批次 420/469: 損失=1.0184, 準確率=70.73%
   批次 440/469: 損失=1.0192, 準確率=70.68%
   批次 460/469: 損失=1.0212, 準確率=70.63%
Epoch 10 完成: 訓練=70.69%, 驗證=69.82%, 時間=55.0s
   💾 新最佳模型已保存: 驗證準確率 69.82%

Epoch 11/50, LR: 0.002714
   批次 20/469: 損失=0.9383, 準確率=75.23%
   批次 40/469: 損失=0.9740, 準確率=73.32%
   批次 60/469: 損失=0.9943, 準確率=71.69%
   批次 80/469: 損失=0.9967, 準確率=71.82%
   批次 100/469: 損失=0.9947, 準確率=71.91%
   批次 120/469: 損失=0.9949, 準確率=71.91%
   批次 140/469: 損失=1.0011, 準確率=71.54%
   批次 160/469: 損失=0.9978, 準確率=71.70%
   批次 180/469: 損失=1.0010, 準確率=71.41%
   批次 200/469: 損失=1.0000, 準確率=71.53%
   批次 220/469: 損失=1.0000, 準確率=71.53%
   批次 240/469: 損失=0.9998, 準確率=71.61%
   批次 260/469: 損失=0.9963, 準確率=71.73%
   批次 280/469: 損失=0.9965, 準確率=71.77%
   批次 300/469: 損失=0.9957, 準確率=71.76%
   批次 320/469: 損失=0.9967, 準確率=71.71%
   批次 340/469: 損失=0.9954, 準確率=71.80%
   批次 360/469: 損失=0.9955, 準確率=71.81%
   批次 380/469: 損失=0.9953, 準確率=71.76%
   批次 400/469: 損失=0.9970, 準確率=71.71%
   批次 420/469: 損失=0.9959, 準確率=71.80%
   批次 440/469: 損失=0.9971, 準確率=71.82%
   批次 460/469: 損失=0.9978, 準確率=71.75%
Epoch 11 完成: 訓練=71.74%, 驗證=70.04%, 時間=55.3s
   💾 新最佳模型已保存: 驗證準確率 70.04%

Epoch 12/50, LR: 0.002657
   批次 20/469: 損失=0.8824, 準確率=77.27%
   批次 40/469: 損失=0.9232, 準確率=74.96%
   批次 60/469: 損失=0.9398, 準確率=74.09%
   批次 80/469: 損失=0.9530, 準確率=73.26%
   批次 100/469: 損失=0.9543, 準確率=73.28%
   批次 120/469: 損失=0.9555, 準確率=73.26%
   批次 140/469: 損失=0.9614, 準確率=72.79%
   批次 160/469: 損失=0.9651, 準確率=72.54%
   批次 180/469: 損失=0.9617, 準確率=72.60%
   批次 200/469: 損失=0.9633, 準確率=72.62%
   批次 220/469: 損失=0.9658, 準確率=72.57%
   批次 240/469: 損失=0.9672, 準確率=72.43%
   批次 260/469: 損失=0.9665, 準確率=72.48%
   批次 280/469: 損失=0.9685, 準確率=72.39%
   批次 300/469: 損失=0.9697, 準確率=72.39%
   批次 320/469: 損失=0.9715, 準確率=72.30%
   批次 340/469: 損失=0.9725, 準確率=72.26%
   批次 360/469: 損失=0.9751, 準確率=72.17%
   批次 380/469: 損失=0.9745, 準確率=72.16%
   批次 400/469: 損失=0.9749, 準確率=72.20%
   批次 420/469: 損失=0.9755, 準確率=72.20%
   批次 440/469: 損失=0.9760, 準確率=72.16%
   批次 460/469: 損失=0.9768, 準確率=72.14%
Epoch 12 完成: 訓練=72.19%, 驗證=70.22%, 時間=56.5s
   💾 新最佳模型已保存: 驗證準確率 70.22%

Epoch 13/50, LR: 0.002595
   批次 20/469: 損失=0.9370, 準確率=75.08%
   批次 40/469: 損失=0.9439, 準確率=74.73%
   批次 60/469: 損失=0.9406, 準確率=74.17%
   批次 80/469: 損失=0.9445, 準確率=73.95%
   批次 100/469: 損失=0.9406, 準確率=74.44%
   批次 120/469: 損失=0.9540, 準確率=73.80%
   批次 140/469: 損失=0.9554, 準確率=73.64%
   批次 160/469: 損失=0.9633, 準確率=73.30%
   批次 180/469: 損失=0.9636, 準確率=73.19%
   批次 200/469: 損失=0.9616, 準確率=73.30%
   批次 220/469: 損失=0.9597, 準確率=73.27%
   批次 240/469: 損失=0.9605, 準確率=73.27%
   批次 260/469: 損失=0.9601, 準確率=73.20%
   批次 280/469: 損失=0.9615, 準確率=73.17%
   批次 300/469: 損失=0.9595, 準確率=73.29%
   批次 320/469: 損失=0.9567, 準確率=73.45%
   批次 340/469: 損失=0.9567, 準確率=73.44%
   批次 360/469: 損失=0.9558, 準確率=73.46%
   批次 380/469: 損失=0.9543, 準確率=73.54%
   批次 400/469: 損失=0.9539, 準確率=73.47%
   批次 420/469: 損失=0.9553, 準確率=73.41%
   批次 440/469: 損失=0.9562, 準確率=73.42%
   批次 460/469: 損失=0.9557, 準確率=73.39%
Epoch 13 完成: 訓練=73.44%, 驗證=70.32%, 時間=55.0s
   💾 新最佳模型已保存: 驗證準確率 70.32%

Epoch 14/50, LR: 0.002528
   批次 20/469: 損失=0.9076, 準確率=74.53%
   批次 40/469: 損失=0.9231, 準確率=73.83%
   批次 60/469: 損失=0.9272, 準確率=74.06%
   批次 80/469: 損失=0.9308, 準確率=74.06%
   批次 100/469: 損失=0.9189, 準確率=74.45%
   批次 120/469: 損失=0.9279, 準確率=74.24%
   批次 140/469: 損失=0.9278, 準確率=74.12%
   批次 160/469: 損失=0.9306, 準確率=74.00%
   批次 180/469: 損失=0.9314, 準確率=73.89%
   批次 200/469: 損失=0.9342, 準確率=73.86%
   批次 220/469: 損失=0.9361, 準確率=73.88%
   批次 240/469: 損失=0.9372, 準確率=73.86%
   批次 260/469: 損失=0.9367, 準確率=73.89%
   批次 280/469: 損失=0.9368, 準確率=73.92%
   批次 300/469: 損失=0.9373, 準確率=73.92%
   批次 320/469: 損失=0.9364, 準確率=73.87%
   批次 340/469: 損失=0.9368, 準確率=73.92%
   批次 360/469: 損失=0.9366, 準確率=73.95%
   批次 380/469: 損失=0.9378, 準確率=73.92%
   批次 400/469: 損失=0.9396, 準確率=73.79%
   批次 420/469: 損失=0.9417, 準確率=73.72%
   批次 440/469: 損失=0.9410, 準確率=73.73%
   批次 460/469: 損失=0.9423, 準確率=73.67%
Epoch 14 完成: 訓練=73.67%, 驗證=70.22%, 時間=54.7s

Epoch 15/50, LR: 0.002458
   批次 20/469: 損失=0.8897, 準確率=76.02%
   批次 40/469: 損失=0.8959, 準確率=76.17%
   批次 60/469: 損失=0.9033, 準確率=75.44%
   批次 80/469: 損失=0.9027, 準確率=75.18%
   批次 100/469: 損失=0.9100, 準確率=74.80%
   批次 120/469: 損失=0.9122, 準確率=74.53%
   批次 140/469: 損失=0.9096, 準確率=74.83%
   批次 160/469: 損失=0.9099, 準確率=74.93%
   批次 180/469: 損失=0.9132, 準確率=74.73%
   批次 200/469: 損失=0.9159, 準確率=74.71%
   批次 220/469: 損失=0.9151, 準確率=74.63%
   批次 240/469: 損失=0.9181, 準確率=74.54%
   批次 260/469: 損失=0.9204, 準確率=74.43%
   批次 280/469: 損失=0.9204, 準確率=74.44%
   批次 300/469: 損失=0.9177, 準確率=74.57%
   批次 320/469: 損失=0.9173, 準確率=74.58%
   批次 340/469: 損失=0.9186, 準確率=74.49%
   批次 360/469: 損失=0.9199, 準確率=74.44%
   批次 380/469: 損失=0.9202, 準確率=74.49%
   批次 400/469: 損失=0.9204, 準確率=74.54%
   批次 420/469: 損失=0.9197, 準確率=74.60%
   批次 440/469: 損失=0.9195, 準確率=74.67%
   批次 460/469: 損失=0.9200, 準確率=74.62%
Epoch 15 完成: 訓練=74.59%, 驗證=70.98%, 時間=55.2s
   💾 新最佳模型已保存: 驗證準確率 70.98%

Epoch 16/50, LR: 0.002384
   批次 20/469: 損失=0.8463, 準確率=77.42%
   批次 40/469: 損失=0.8693, 準確率=76.56%
   批次 60/469: 損失=0.8665, 準確率=77.08%
   批次 80/469: 損失=0.8700, 準確率=76.91%
   批次 100/469: 損失=0.8771, 準確率=76.52%
   批次 120/469: 損失=0.8808, 準確率=76.33%
   批次 140/469: 損失=0.8798, 準確率=76.40%
   批次 160/469: 損失=0.8804, 準確率=76.51%
   批次 180/469: 損失=0.8824, 準確率=76.49%
   批次 200/469: 損失=0.8846, 準確率=76.41%
   批次 220/469: 損失=0.8860, 準確率=76.42%
   批次 240/469: 損失=0.8918, 準確率=76.07%
   批次 260/469: 損失=0.8928, 準確率=76.00%
   批次 280/469: 損失=0.8950, 準確率=75.98%
   批次 300/469: 損失=0.8951, 準確率=75.91%
   批次 320/469: 損失=0.8943, 準確率=75.93%
   批次 340/469: 損失=0.8967, 準確率=75.85%
   批次 360/469: 損失=0.8982, 準確率=75.83%
   批次 380/469: 損失=0.9003, 準確率=75.71%
   批次 400/469: 損失=0.9009, 準確率=75.63%
   批次 420/469: 損失=0.9000, 準確率=75.64%
   批次 440/469: 損失=0.9006, 準確率=75.58%
   批次 460/469: 損失=0.9014, 準確率=75.55%
Epoch 16 完成: 訓練=75.57%, 驗證=72.78%, 時間=56.5s
   💾 新最佳模型已保存: 驗證準確率 72.78%

Epoch 17/50, LR: 0.002306
   批次 20/469: 損失=0.8613, 準確率=77.03%
   批次 40/469: 損失=0.8785, 準確率=76.60%
   批次 60/469: 損失=0.8867, 準確率=76.43%
   批次 80/469: 損失=0.8883, 準確率=76.17%
   批次 100/469: 損失=0.8938, 準確率=76.02%
   批次 120/469: 損失=0.8895, 準確率=76.15%
   批次 140/469: 損失=0.8829, 準確率=76.40%
   批次 160/469: 損失=0.8806, 準確率=76.67%
   批次 180/469: 損失=0.8834, 準確率=76.50%
   批次 200/469: 損失=0.8798, 準確率=76.64%
   批次 220/469: 損失=0.8779, 準確率=76.69%
   批次 240/469: 損失=0.8806, 準確率=76.57%
   批次 260/469: 損失=0.8798, 準確率=76.49%
   批次 280/469: 損失=0.8801, 準確率=76.42%
   批次 300/469: 損失=0.8793, 準確率=76.43%
   批次 320/469: 損失=0.8806, 準確率=76.32%
   批次 340/469: 損失=0.8828, 準確率=76.24%
   批次 360/469: 損失=0.8848, 準確率=76.15%
   批次 380/469: 損失=0.8864, 準確率=76.06%
   批次 400/469: 損失=0.8851, 準確率=76.11%
   批次 420/469: 損失=0.8843, 準確率=76.13%
   批次 440/469: 損失=0.8858, 準確率=76.05%
   批次 460/469: 損失=0.8870, 準確率=76.02%
Epoch 17 完成: 訓練=76.01%, 驗證=71.80%, 時間=58.3s

Epoch 18/50, LR: 0.002225
   批次 20/469: 損失=0.8483, 準確率=79.06%
   批次 40/469: 損失=0.8709, 準確率=77.19%
   批次 60/469: 損失=0.8693, 準確率=77.03%
   批次 80/469: 損失=0.8688, 準確率=77.17%
   批次 100/469: 損失=0.8578, 準確率=77.78%
   批次 120/469: 損失=0.8606, 準確率=77.55%
   批次 140/469: 損失=0.8594, 準確率=77.65%
   批次 160/469: 損失=0.8581, 準確率=77.67%
   批次 180/469: 損失=0.8577, 準確率=77.61%
   批次 200/469: 損失=0.8596, 準確率=77.52%
   批次 220/469: 損失=0.8592, 準確率=77.46%
   批次 240/469: 損失=0.8617, 準確率=77.38%
   批次 260/469: 損失=0.8629, 準確率=77.35%
   批次 280/469: 損失=0.8627, 準確率=77.30%
   批次 300/469: 損失=0.8639, 準確率=77.26%
   批次 320/469: 損失=0.8649, 準確率=77.20%
   批次 340/469: 損失=0.8631, 準確率=77.24%
   批次 360/469: 損失=0.8672, 準確率=77.02%
   批次 380/469: 損失=0.8682, 準確率=76.99%
   批次 400/469: 損失=0.8695, 準確率=76.94%
   批次 420/469: 損失=0.8697, 準確率=76.96%
   批次 440/469: 損失=0.8704, 準確率=76.92%
   批次 460/469: 損失=0.8716, 準確率=76.87%
Epoch 18 完成: 訓練=76.81%, 驗證=72.64%, 時間=57.7s

Epoch 19/50, LR: 0.002142
   批次 20/469: 損失=0.8278, 準確率=78.05%
   批次 40/469: 損失=0.8352, 準確率=78.09%
   批次 60/469: 損失=0.8397, 準確率=77.99%
   批次 80/469: 損失=0.8383, 準確率=78.22%
   批次 100/469: 損失=0.8465, 準確率=77.89%
   批次 120/469: 損失=0.8521, 準確率=77.59%
   批次 140/469: 損失=0.8437, 準確率=77.95%
   批次 160/469: 損失=0.8482, 準確率=77.80%
   批次 180/469: 損失=0.8465, 準確率=77.93%
   批次 200/469: 損失=0.8502, 準確率=77.70%
   批次 220/469: 損失=0.8512, 準確率=77.55%
   批次 240/469: 損失=0.8508, 準確率=77.61%
   批次 260/469: 損失=0.8518, 準確率=77.66%
   批次 280/469: 損失=0.8549, 準確率=77.54%
   批次 300/469: 損失=0.8533, 準確率=77.60%
   批次 320/469: 損失=0.8553, 準確率=77.53%
   批次 340/469: 損失=0.8560, 準確率=77.49%
   批次 360/469: 損失=0.8542, 準確率=77.60%
   批次 380/469: 損失=0.8544, 準確率=77.59%
   批次 400/469: 損失=0.8540, 準確率=77.64%
   批次 420/469: 損失=0.8533, 準確率=77.70%
   批次 440/469: 損失=0.8546, 準確率=77.68%
   批次 460/469: 損失=0.8550, 準確率=77.66%
Epoch 19 完成: 訓練=77.68%, 驗證=72.34%, 時間=55.9s
   📊 訓練-驗證差異: 5.34%

Epoch 20/50, LR: 0.002055
   批次 20/469: 損失=0.8691, 準確率=77.50%
   批次 40/469: 損失=0.8404, 準確率=78.40%
   批次 60/469: 損失=0.8317, 準確率=78.91%
   批次 80/469: 損失=0.8359, 準確率=78.77%
   批次 100/469: 損失=0.8374, 準確率=78.78%
   批次 120/469: 損失=0.8331, 準確率=78.83%
   批次 140/469: 損失=0.8278, 準確率=79.02%
   批次 160/469: 損失=0.8355, 準確率=78.60%
   批次 180/469: 損失=0.8354, 準確率=78.54%
   批次 200/469: 損失=0.8377, 準確率=78.38%
   批次 220/469: 損失=0.8385, 準確率=78.33%
   批次 240/469: 損失=0.8366, 準確率=78.39%
   批次 260/469: 損失=0.8352, 準確率=78.43%
   批次 280/469: 損失=0.8332, 準確率=78.48%
   批次 300/469: 損失=0.8322, 準確率=78.40%
   批次 320/469: 損失=0.8333, 準確率=78.38%
   批次 340/469: 損失=0.8346, 準確率=78.33%
   批次 360/469: 損失=0.8372, 準確率=78.22%
   批次 380/469: 損失=0.8359, 準確率=78.26%
   批次 400/469: 損失=0.8375, 準確率=78.23%
   批次 420/469: 損失=0.8404, 準確率=78.13%
   批次 440/469: 損失=0.8412, 準確率=78.11%
   批次 460/469: 損失=0.8426, 準確率=78.05%
Epoch 20 完成: 訓練=78.07%, 驗證=72.56%, 時間=66.0s
   📊 訓練-驗證差異: 5.51%

Epoch 21/50, LR: 0.001967
   批次 20/469: 損失=0.8135, 準確率=80.16%
   批次 40/469: 損失=0.7973, 準確率=80.39%
   批次 60/469: 損失=0.8148, 準確率=79.61%
   批次 80/469: 損失=0.8108, 準確率=79.63%
   批次 100/469: 損失=0.8083, 準確率=79.88%
   批次 120/469: 損失=0.8071, 準確率=80.04%
   批次 140/469: 損失=0.8115, 準確率=79.80%
   批次 160/469: 損失=0.8132, 準確率=79.71%
   批次 180/469: 損失=0.8159, 準確率=79.82%
   批次 200/469: 損失=0.8196, 準確率=79.58%
   批次 220/469: 損失=0.8205, 準確率=79.49%
   批次 240/469: 損失=0.8230, 準確率=79.30%
   批次 260/469: 損失=0.8231, 準確率=79.30%
   批次 280/469: 損失=0.8227, 準確率=79.31%
   批次 300/469: 損失=0.8226, 準確率=79.30%
   批次 320/469: 損失=0.8216, 準確率=79.26%
   批次 340/469: 損失=0.8207, 準確率=79.32%
   批次 360/469: 損失=0.8201, 準確率=79.36%
   批次 380/469: 損失=0.8211, 準確率=79.27%
   批次 400/469: 損失=0.8215, 準確率=79.26%
   批次 420/469: 損失=0.8231, 準確率=79.17%
   批次 440/469: 損失=0.8234, 準確率=79.15%
   批次 460/469: 損失=0.8254, 準確率=79.05%
Epoch 21 完成: 訓練=79.10%, 驗證=72.84%, 時間=53.9s
   📊 訓練-驗證差異: 6.26%
   💾 新最佳模型已保存: 驗證準確率 72.84%

Epoch 22/50, LR: 0.001877
   批次 20/469: 損失=0.7726, 準確率=80.70%
   批次 40/469: 損失=0.7869, 準確率=79.77%
   批次 60/469: 損失=0.7941, 準確率=79.35%
   批次 80/469: 損失=0.7931, 準確率=79.77%
   批次 100/469: 損失=0.7889, 準確率=80.06%
   批次 120/469: 損失=0.7939, 準確率=79.93%
   批次 140/469: 損失=0.7929, 準確率=80.12%
   批次 160/469: 損失=0.7938, 準確率=80.13%
   批次 180/469: 損失=0.7977, 準確率=80.04%
   批次 200/469: 損失=0.8013, 準確率=79.93%
   批次 220/469: 損失=0.8050, 準確率=79.72%
   批次 240/469: 損失=0.8036, 準確率=79.69%
   批次 260/469: 損失=0.8045, 準確率=79.69%
   批次 280/469: 損失=0.8053, 準確率=79.69%
   批次 300/469: 損失=0.8058, 準確率=79.67%
   批次 320/469: 損失=0.8075, 準確率=79.60%
   批次 340/469: 損失=0.8084, 準確率=79.56%
   批次 360/469: 損失=0.8098, 準確率=79.51%
   批次 380/469: 損失=0.8109, 準確率=79.48%
   批次 400/469: 損失=0.8111, 準確率=79.42%
   批次 420/469: 損失=0.8125, 準確率=79.36%
   批次 440/469: 損失=0.8141, 準確率=79.27%
   批次 460/469: 損失=0.8139, 準確率=79.27%
Epoch 22 完成: 訓練=79.25%, 驗證=73.04%, 時間=62.6s
   📊 訓練-驗證差異: 6.21%
   💾 新最佳模型已保存: 驗證準確率 73.04%

Epoch 23/50, LR: 0.001785
   批次 20/469: 損失=0.7839, 準確率=81.56%
   批次 40/469: 損失=0.7845, 準確率=80.51%
   批次 60/469: 損失=0.7840, 準確率=80.21%
   批次 80/469: 損失=0.7846, 準確率=79.98%
   批次 100/469: 損失=0.7843, 準確率=80.16%
   批次 120/469: 損失=0.7909, 準確率=79.93%
   批次 140/469: 損失=0.7932, 準確率=79.94%
   批次 160/469: 損失=0.7947, 準確率=79.79%
   批次 180/469: 損失=0.7907, 準確率=79.92%
   批次 200/469: 損失=0.7926, 準確率=79.94%
   批次 220/469: 損失=0.7957, 準確率=79.83%
   批次 240/469: 損失=0.7933, 準確率=79.95%
   批次 260/469: 損失=0.7937, 準確率=79.95%
   批次 280/469: 損失=0.7937, 準確率=79.92%
   批次 300/469: 損失=0.7922, 準確率=80.02%
   批次 320/469: 損失=0.7944, 準確率=79.89%
   批次 340/469: 損失=0.7953, 準確率=79.87%
   批次 360/469: 損失=0.7964, 準確率=79.86%
   批次 380/469: 損失=0.7978, 準確率=79.82%
   批次 400/469: 損失=0.7988, 準確率=79.72%
   批次 420/469: 損失=0.7982, 準確率=79.74%
   批次 440/469: 損失=0.7984, 準確率=79.72%
   批次 460/469: 損失=0.7978, 準確率=79.77%
Epoch 23 完成: 訓練=79.78%, 驗證=73.70%, 時間=57.9s
   📊 訓練-驗證差異: 6.08%
   💾 新最佳模型已保存: 驗證準確率 73.70%

Epoch 24/50, LR: 0.001692
   批次 20/469: 損失=0.7435, 準確率=82.27%
   批次 40/469: 損失=0.7614, 準確率=81.21%
   批次 60/469: 損失=0.7646, 準確率=81.04%
   批次 80/469: 損失=0.7689, 準確率=80.82%
   批次 100/469: 損失=0.7794, 準確率=80.55%
   批次 120/469: 損失=0.7830, 準確率=80.33%
   批次 140/469: 損失=0.7812, 準確率=80.31%
   批次 160/469: 損失=0.7813, 準確率=80.27%
   批次 180/469: 損失=0.7778, 準確率=80.46%
   批次 200/469: 損失=0.7801, 準確率=80.44%
   批次 220/469: 損失=0.7817, 準確率=80.38%
   批次 240/469: 損失=0.7825, 準確率=80.32%
   批次 260/469: 損失=0.7808, 準確率=80.31%
   批次 280/469: 損失=0.7819, 準確率=80.37%
   批次 300/469: 損失=0.7811, 準確率=80.43%
   批次 320/469: 損失=0.7822, 準確率=80.37%
   批次 340/469: 損失=0.7823, 準確率=80.50%
   批次 360/469: 損失=0.7823, 準確率=80.50%
   批次 380/469: 損失=0.7822, 準確率=80.54%
   批次 400/469: 損失=0.7824, 準確率=80.57%
   批次 420/469: 損失=0.7832, 準確率=80.55%
   批次 440/469: 損失=0.7831, 準確率=80.55%
   批次 460/469: 損失=0.7846, 準確率=80.46%
Epoch 24 完成: 訓練=80.48%, 驗證=73.98%, 時間=53.3s
   📊 訓練-驗證差異: 6.50%
   💾 新最佳模型已保存: 驗證準確率 73.98%

Epoch 25/50, LR: 0.001599
   批次 20/469: 損失=0.7435, 準確率=80.94%
   批次 40/469: 損失=0.7336, 準確率=82.42%
   批次 60/469: 損失=0.7438, 準確率=81.98%
   批次 80/469: 損失=0.7315, 準確率=82.40%
   批次 100/469: 損失=0.7302, 準確率=82.36%
   批次 120/469: 損失=0.7423, 準確率=81.81%
   批次 140/469: 損失=0.7435, 準確率=81.93%
   批次 160/469: 損失=0.7442, 準確率=81.97%
   批次 180/469: 損失=0.7448, 準確率=82.02%
   批次 200/469: 損失=0.7467, 準確率=81.94%
   批次 220/469: 損失=0.7538, 準確率=81.58%
   批次 240/469: 損失=0.7557, 準確率=81.58%
   批次 260/469: 損失=0.7564, 準確率=81.65%
   批次 280/469: 損失=0.7569, 準確率=81.67%
   批次 300/469: 損失=0.7586, 準確率=81.64%
   批次 320/469: 損失=0.7594, 準確率=81.58%
   批次 340/469: 損失=0.7608, 準確率=81.55%
   批次 360/469: 損失=0.7605, 準確率=81.57%
   批次 380/469: 損失=0.7642, 準確率=81.37%
   批次 400/469: 損失=0.7642, 準確率=81.39%
   批次 420/469: 損失=0.7650, 準確率=81.34%
   批次 440/469: 損失=0.7663, 準確率=81.26%
   批次 460/469: 損失=0.7671, 準確率=81.19%
Epoch 25 完成: 訓練=81.23%, 驗證=73.52%, 時間=56.9s
   📊 訓練-驗證差異: 7.71%

Epoch 26/50, LR: 0.001505
   批次 20/469: 損失=0.7221, 準確率=83.44%
   批次 40/469: 損失=0.7291, 準確率=83.05%
   批次 60/469: 損失=0.7280, 準確率=82.81%
   批次 80/469: 損失=0.7382, 準確率=82.29%
   批次 100/469: 損失=0.7335, 準確率=82.80%
   批次 120/469: 損失=0.7400, 準確率=82.60%
   批次 140/469: 損失=0.7444, 準確率=82.32%
   批次 160/469: 損失=0.7465, 準確率=82.17%
   批次 180/469: 損失=0.7436, 準確率=82.26%
   批次 200/469: 損失=0.7411, 準確率=82.30%
   批次 220/469: 損失=0.7478, 準確率=82.01%
   批次 240/469: 損失=0.7474, 準確率=82.06%
   批次 260/469: 損失=0.7479, 準確率=82.05%
   批次 280/469: 損失=0.7492, 準確率=81.98%
   批次 300/469: 損失=0.7489, 準確率=81.99%
   批次 320/469: 損失=0.7509, 準確率=81.91%
   批次 340/469: 損失=0.7531, 準確率=81.82%
   批次 360/469: 損失=0.7537, 準確率=81.82%
   批次 380/469: 損失=0.7529, 準確率=81.93%
   批次 400/469: 損失=0.7538, 準確率=81.84%
   批次 420/469: 損失=0.7541, 準確率=81.81%
   批次 440/469: 損失=0.7555, 準確率=81.77%
   批次 460/469: 損失=0.7553, 準確率=81.77%
Epoch 26 完成: 訓練=81.79%, 驗證=73.68%, 時間=55.2s
   ⚠️  過擬合警告: 差異 8.11% > 閾值 8.0% (1/6)
   📊 訓練-驗證差異: 8.11%

Epoch 27/50, LR: 0.001411
   批次 20/469: 損失=0.7386, 準確率=82.50%
   批次 40/469: 損失=0.7294, 準確率=82.97%
   批次 60/469: 損失=0.7330, 準確率=82.73%
   批次 80/469: 損失=0.7369, 準確率=82.42%
   批次 100/469: 損失=0.7423, 準確率=82.23%
   批次 120/469: 損失=0.7433, 準確率=82.42%
   批次 140/469: 損失=0.7391, 準確率=82.58%
   批次 160/469: 損失=0.7414, 準確率=82.49%
   批次 180/469: 損失=0.7406, 準確率=82.63%
   批次 200/469: 損失=0.7410, 準確率=82.59%
   批次 220/469: 損失=0.7437, 準確率=82.46%
   批次 240/469: 損失=0.7442, 準確率=82.39%
   批次 260/469: 損失=0.7425, 準確率=82.43%
   批次 280/469: 損失=0.7441, 準確率=82.40%
   批次 300/469: 損失=0.7436, 準確率=82.43%
   批次 320/469: 損失=0.7424, 準確率=82.50%
   批次 340/469: 損失=0.7414, 準確率=82.55%
   批次 360/469: 損失=0.7426, 準確率=82.51%
   批次 380/469: 損失=0.7430, 準確率=82.54%
   批次 400/469: 損失=0.7458, 準確率=82.39%
   批次 420/469: 損失=0.7462, 準確率=82.44%
   批次 440/469: 損失=0.7470, 準確率=82.41%
   批次 460/469: 損失=0.7472, 準確率=82.38%
Epoch 27 完成: 訓練=82.42%, 驗證=73.76%, 時間=54.1s
   ⚠️  過擬合警告: 差異 8.66% > 閾值 8.0% (2/6)
   📊 訓練-驗證差異: 8.66%

Epoch 28/50, LR: 0.001318
   批次 20/469: 損失=0.7225, 準確率=83.52%
   批次 40/469: 損失=0.7365, 準確率=82.77%
   批次 60/469: 損失=0.7302, 準確率=82.94%
   批次 80/469: 損失=0.7314, 準確率=82.89%
   批次 100/469: 損失=0.7295, 準確率=82.88%
   批次 120/469: 損失=0.7284, 準確率=82.89%
   批次 140/469: 損失=0.7270, 準確率=83.11%
   批次 160/469: 損失=0.7268, 準確率=83.07%
   批次 180/469: 損失=0.7257, 準確率=83.20%
   批次 200/469: 損失=0.7242, 準確率=83.28%
   批次 220/469: 損失=0.7235, 準確率=83.25%
   批次 240/469: 損失=0.7230, 準確率=83.25%
   批次 260/469: 損失=0.7244, 準確率=83.22%
   批次 280/469: 損失=0.7245, 準確率=83.20%
   批次 300/469: 損失=0.7272, 準確率=83.08%
   批次 320/469: 損失=0.7276, 準確率=83.07%
   批次 340/469: 損失=0.7289, 準確率=83.02%
   批次 360/469: 損失=0.7303, 準確率=82.96%
   批次 380/469: 損失=0.7297, 準確率=83.00%
   批次 400/469: 損失=0.7305, 準確率=82.95%
   批次 420/469: 損失=0.7299, 準確率=82.99%
   批次 440/469: 損失=0.7299, 準確率=82.99%
   批次 460/469: 損失=0.7308, 準確率=82.94%
Epoch 28 完成: 訓練=83.00%, 驗證=74.00%, 時間=52.6s
   ⚠️  過擬合警告: 差異 9.00% > 閾值 8.0% (3/6)
   📊 訓練-驗證差異: 9.00%
   💾 新最佳模型已保存: 驗證準確率 74.00%

Epoch 29/50, LR: 0.001225
   批次 20/469: 損失=0.7226, 準確率=83.20%
   批次 40/469: 損失=0.7103, 準確率=83.71%
   批次 60/469: 損失=0.7092, 準確率=83.70%
   批次 80/469: 損失=0.7025, 準確率=83.91%
   批次 100/469: 損失=0.7103, 準確率=83.39%
   批次 120/469: 損失=0.7087, 準確率=83.53%
   批次 140/469: 損失=0.7051, 準確率=83.73%
   批次 160/469: 損失=0.7098, 準確率=83.58%
   批次 180/469: 損失=0.7081, 準確率=83.62%
   批次 200/469: 損失=0.7109, 準確率=83.56%
   批次 220/469: 損失=0.7123, 準確率=83.54%
   批次 240/469: 損失=0.7145, 準確率=83.43%
   批次 260/469: 損失=0.7142, 準確率=83.48%
   批次 280/469: 損失=0.7158, 準確率=83.44%
   批次 300/469: 損失=0.7146, 準確率=83.52%
   批次 320/469: 損失=0.7162, 準確率=83.40%
   批次 340/469: 損失=0.7163, 準確率=83.32%
   批次 360/469: 損失=0.7179, 準確率=83.31%
   批次 380/469: 損失=0.7173, 準確率=83.39%
   批次 400/469: 損失=0.7188, 準確率=83.29%
   批次 420/469: 損失=0.7195, 準確率=83.31%
   批次 440/469: 損失=0.7203, 準確率=83.35%
   批次 460/469: 損失=0.7214, 準確率=83.28%
Epoch 29 完成: 訓練=83.30%, 驗證=74.20%, 時間=53.8s
   ⚠️  過擬合警告: 差異 9.10% > 閾值 8.0% (4/6)
   📊 訓練-驗證差異: 9.10%
   💾 新最佳模型已保存: 驗證準確率 74.20%

Epoch 30/50, LR: 0.001133
   批次 20/469: 損失=0.6715, 準確率=85.94%
   批次 40/469: 損失=0.6771, 準確率=85.78%
   批次 60/469: 損失=0.6728, 準確率=85.78%
   批次 80/469: 損失=0.6784, 準確率=85.64%
   批次 100/469: 損失=0.6796, 準確率=85.59%
   批次 120/469: 損失=0.6816, 準確率=85.57%
   批次 140/469: 損失=0.6850, 準確率=85.25%
   批次 160/469: 損失=0.6874, 準確率=85.09%
   批次 180/469: 損失=0.6875, 準確率=85.02%
   批次 200/469: 損失=0.6896, 準確率=84.93%
   批次 220/469: 損失=0.6920, 準確率=84.82%
   批次 240/469: 損失=0.6895, 準確率=84.97%
   批次 260/469: 損失=0.6911, 準確率=84.93%
   批次 280/469: 損失=0.6925, 準確率=84.79%
   批次 300/469: 損失=0.6930, 準確率=84.78%
   批次 320/469: 損失=0.6945, 準確率=84.77%
   批次 340/469: 損失=0.6958, 準確率=84.76%
   批次 360/469: 損失=0.6989, 準確率=84.54%
   批次 380/469: 損失=0.7004, 準確率=84.47%
   批次 400/469: 損失=0.7023, 準確率=84.33%
   批次 420/469: 損失=0.7038, 準確率=84.25%
   批次 440/469: 損失=0.7053, 準確率=84.21%
   批次 460/469: 損失=0.7062, 準確率=84.15%
Epoch 30 完成: 訓練=84.10%, 驗證=74.02%, 時間=55.2s
   ⚠️  過擬合警告: 差異 10.08% > 閾值 8.0% (5/6)
   📊 訓練-驗證差異: 10.08%

Epoch 31/50, LR: 0.001043
   批次 20/469: 損失=0.6602, 準確率=85.55%
   批次 40/469: 損失=0.6632, 準確率=85.70%
   批次 60/469: 損失=0.6645, 準確率=85.70%
   批次 80/469: 損失=0.6672, 準確率=85.70%
   批次 100/469: 損失=0.6694, 準確率=85.92%
   批次 120/469: 損失=0.6742, 準確率=85.44%
   批次 140/469: 損失=0.6764, 準確率=85.41%
   批次 160/469: 損失=0.6789, 準確率=85.19%
   批次 180/469: 損失=0.6786, 準確率=85.19%
   批次 200/469: 損失=0.6808, 準確率=85.02%
   批次 220/469: 損失=0.6818, 準確率=84.99%
   批次 240/469: 損失=0.6848, 準確率=84.95%
   批次 260/469: 損失=0.6850, 準確率=84.96%
   批次 280/469: 損失=0.6859, 準確率=84.92%
   批次 300/469: 損失=0.6849, 準確率=84.98%
   批次 320/469: 損失=0.6845, 準確率=85.01%
   批次 340/469: 損失=0.6849, 準確率=84.99%
   批次 360/469: 損失=0.6866, 準確率=84.92%
   批次 380/469: 損失=0.6869, 準確率=84.89%
   批次 400/469: 損失=0.6875, 準確率=84.89%
   批次 420/469: 損失=0.6896, 準確率=84.72%
   批次 440/469: 損失=0.6907, 準確率=84.68%
   批次 460/469: 損失=0.6914, 準確率=84.69%
Epoch 31 完成: 訓練=84.66%, 驗證=74.44%, 時間=54.9s
   ⚠️  過擬合警告: 差異 10.22% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 1764.6s (29.4min)
   • 實際訓練epochs: 31 / 50
   • 平均每epoch: 56.9s
   • 最佳驗證準確率: 74.20%
   • 早停原因: 過擬合檢測 (差異: 10.22%)
   • 已載入最佳模型權重

📈 繪製超快速訓練歷史...

📊 評估超縮小版模型...
   ✓ 整體準確率: 74.20%

🎉 超快速訓練完成!
   • 模型大小: Nano
   • 最終準確率: 74.20%
   • 總訓練時間: 29.4 分鐘
   • 平均每epoch: 56.9 秒