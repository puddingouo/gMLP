請選擇要使用的模型:
   輸入編號 (1-6) 或模型名稱 (Test/Nano/XS/S/M/L): Nano

✅ 您選擇了: Nano 模型
   📋 模型詳情:
      • 深度: 6 層
      • 維度: 64
      • FFN倍數: 2
      • 預估參數: 0.20M
      • 預估時間: ~1分鐘
      • 過擬合風險: 很低
      • 描述: 極小快速模型

   確認使用 Nano 模型嗎? (y/n, 預設=y): y

============================================================
⚙️  訓練參數設置
============================================================

📦 數據集模式選擇:
   1. 快速模式 (50K訓練 + 10K測試) - 推薦
   2. 完整模式 (50K訓練 + 10K測試)
   選擇模式 (1/2, 預設=1): 2

🏋️  訓練輪數 (預設=50): 75

🛡️  過擬合保護:
   1. 啟用早停機制 (推薦)
   2. 關閉早停機制
   選擇 (1/2, 預設=1): 1

✅ 訓練參數確認:
   📦 數據模式: 完整模式
   🏋️  訓練輪數: 75
   🛡️  早停機制: 啟用
📦 加載超快速 CIFAR-10 數據集...
   ✓ 訓練樣本: 50000
   ✓ 測試樣本: 10000
   ✓ Batch大小: 128

🏗️ 創建超縮小版 gMLP-Nano 模型...
   ⚡ CPU模式：已設置4個線程

✅ 超縮小版 gMLP-Nano 模型創建完成
   ✓ 設備: cpu
   ✓ 實際參數數量: 105,290 (0.11M)
   ✓ 目標參數預期: 0.2M
   ✓ 架構配置: depth=6, dim=64, ff_mult=2

🎬 開始訓練 Nano 模型...

🏋️ 開始超快速訓練 (75 個 epochs)...
   🛡️  啟用過擬合早停保護

Epoch 1/75, LR: 0.003000
   批次  50/391: 損失=1.9631, 準確率=28.72%
   批次 100/391: 損失=1.8489, 準確率=34.06%
   批次 150/391: 損失=1.7856, 準確率=36.81%
   批次 200/391: 損失=1.7323, 準確率=38.99%
   批次 250/391: 損失=1.6917, 準確率=40.67%
   批次 300/391: 損失=1.6597, 準確率=42.10%
   批次 350/391: 損失=1.6360, 準確率=43.18%
   批次 391/391: 損失=1.6183, 準確率=44.04%
Epoch 1 完成: 訓練=44.04%, 驗證=50.74%, 時間=85.4s
   💾 新最佳模型已保存: 驗證準確率 50.74%

Epoch 2/75, LR: 0.002999
   批次  50/391: 損失=1.4295, 準確率=52.69%
   批次 100/391: 損失=1.4291, 準確率=52.60%
   批次 150/391: 損失=1.4181, 準確率=53.02%
   批次 200/391: 損失=1.4096, 準確率=53.36%
   批次 250/391: 損失=1.4002, 準確率=53.83%
   批次 300/391: 損失=1.3933, 準確率=54.05%
   批次 350/391: 損失=1.3828, 準確率=54.48%
   批次 391/391: 損失=1.3789, 準確率=54.62%
Epoch 2 完成: 訓練=54.62%, 驗證=57.94%, 時間=84.8s
   💾 新最佳模型已保存: 驗證準確率 57.94%

Epoch 3/75, LR: 0.002995
   批次  50/391: 損失=1.3005, 準確率=57.97%
   批次 100/391: 損失=1.2814, 準確率=58.95%
   批次 150/391: 損失=1.2801, 準確率=59.14%
   批次 200/391: 損失=1.2798, 準確率=59.29%
   批次 250/391: 損失=1.2741, 準確率=59.37%
   批次 300/391: 損失=1.2704, 準確率=59.71%
   批次 350/391: 損失=1.2656, 準確率=59.93%
   批次 391/391: 損失=1.2600, 準確率=60.15%
Epoch 3 完成: 訓練=60.15%, 驗證=61.55%, 時間=84.7s
   💾 新最佳模型已保存: 驗證準確率 61.55%

Epoch 4/75, LR: 0.002988
   批次  50/391: 損失=1.1966, 準確率=63.33%
   批次 100/391: 損失=1.1911, 準確率=63.21%
   批次 150/391: 損失=1.1924, 準確率=63.12%
   批次 200/391: 損失=1.1870, 準確率=63.45%
   批次 250/391: 損失=1.1869, 準確率=63.42%
   批次 300/391: 損失=1.1866, 準確率=63.41%
   批次 350/391: 損失=1.1816, 準確率=63.56%
   批次 391/391: 損失=1.1801, 準確率=63.68%
Epoch 4 完成: 訓練=63.68%, 驗證=64.63%, 時間=85.7s
   💾 新最佳模型已保存: 驗證準確率 64.63%

Epoch 5/75, LR: 0.002979
   批次  50/391: 損失=1.1310, 準確率=65.72%
   批次 100/391: 損失=1.1338, 準確率=65.50%
   批次 150/391: 損失=1.1381, 準確率=65.25%
   批次 200/391: 損失=1.1333, 準確率=65.50%
   批次 250/391: 損失=1.1344, 準確率=65.47%
   批次 300/391: 損失=1.1298, 準確率=65.63%
   批次 350/391: 損失=1.1274, 準確率=65.79%
   批次 391/391: 損失=1.1253, 準確率=65.93%
Epoch 5 完成: 訓練=65.93%, 驗證=66.79%, 時間=85.1s
   💾 新最佳模型已保存: 驗證準確率 66.79%

Epoch 6/75, LR: 0.002967
   批次  50/391: 損失=1.0829, 準確率=67.69%
   批次 100/391: 損失=1.0896, 準確率=67.69%
   批次 150/391: 損失=1.0799, 準確率=68.18%
   批次 200/391: 損失=1.0813, 準確率=68.04%
   批次 250/391: 損失=1.0793, 準確率=68.11%
   批次 300/391: 損失=1.0803, 準確率=68.04%
   批次 350/391: 損失=1.0766, 準確率=68.25%
   批次 391/391: 損失=1.0785, 準確率=68.13%
Epoch 6 完成: 訓練=68.13%, 驗證=67.90%, 時間=82.2s
   💾 新最佳模型已保存: 驗證準確率 67.90%

Epoch 7/75, LR: 0.002953
   批次  50/391: 損失=1.0379, 準確率=69.69%
   批次 100/391: 損失=1.0458, 準確率=69.30%
   批次 150/391: 損失=1.0417, 準確率=69.61%
   批次 200/391: 損失=1.0372, 準確率=69.68%
   批次 250/391: 損失=1.0399, 準確率=69.57%
   批次 300/391: 損失=1.0376, 準確率=69.65%
   批次 350/391: 損失=1.0402, 準確率=69.64%
   批次 391/391: 損失=1.0386, 準確率=69.66%
Epoch 7 完成: 訓練=69.66%, 驗證=68.99%, 時間=82.7s
   💾 新最佳模型已保存: 驗證準確率 68.99%

Epoch 8/75, LR: 0.002936
   批次  50/391: 損失=1.0021, 準確率=70.91%
   批次 100/391: 損失=1.0023, 準確率=71.08%
   批次 150/391: 損失=1.0035, 準確率=70.94%
   批次 200/391: 損失=1.0072, 準確率=70.92%
   批次 250/391: 損失=1.0074, 準確率=70.91%
   批次 300/391: 損失=1.0108, 準確率=70.78%
   批次 350/391: 損失=1.0125, 準確率=70.74%
   批次 391/391: 損失=1.0135, 準確率=70.70%
Epoch 8 完成: 訓練=70.70%, 驗證=70.98%, 時間=84.1s
   💾 新最佳模型已保存: 驗證準確率 70.98%

Epoch 9/75, LR: 0.002917
   批次  50/391: 損失=0.9709, 準確率=72.14%
   批次 100/391: 損失=0.9693, 準確率=71.85%
   批次 150/391: 損失=0.9741, 準確率=71.80%
   批次 200/391: 損失=0.9798, 準確率=71.80%
   批次 250/391: 損失=0.9782, 準確率=72.02%
   批次 300/391: 損失=0.9792, 準確率=72.03%
   批次 350/391: 損失=0.9827, 準確率=71.92%
   批次 391/391: 損失=0.9835, 準確率=71.90%
Epoch 9 完成: 訓練=71.90%, 驗證=71.99%, 時間=83.3s
   💾 新最佳模型已保存: 驗證準確率 71.99%

Epoch 10/75, LR: 0.002895
   批次  50/391: 損失=0.9676, 準確率=72.27%
   批次 100/391: 損失=0.9620, 準確率=72.74%
   批次 150/391: 損失=0.9601, 準確率=72.86%
   批次 200/391: 損失=0.9593, 準確率=72.87%
   批次 250/391: 損失=0.9605, 準確率=72.83%
   批次 300/391: 損失=0.9613, 準確率=72.88%
   批次 350/391: 損失=0.9608, 準確率=72.94%
   批次 391/391: 損失=0.9612, 準確率=72.92%
Epoch 10 完成: 訓練=72.92%, 驗證=71.73%, 時間=83.4s

Epoch 11/75, LR: 0.002871
   批次  50/391: 損失=0.9283, 準確率=74.39%
   批次 100/391: 損失=0.9388, 準確率=74.00%
   批次 150/391: 損失=0.9370, 準確率=74.06%
   批次 200/391: 損失=0.9372, 準確率=74.05%
   批次 250/391: 損失=0.9380, 準確率=74.14%
   批次 300/391: 損失=0.9385, 準確率=74.11%
   批次 350/391: 損失=0.9404, 準確率=73.98%
   批次 391/391: 損失=0.9403, 準確率=73.96%
Epoch 11 完成: 訓練=73.96%, 驗證=72.63%, 時間=82.4s
   💾 新最佳模型已保存: 驗證準確率 72.63%

Epoch 12/75, LR: 0.002844
   批次  50/391: 損失=0.9113, 準確率=75.38%
   批次 100/391: 損失=0.9112, 準確率=75.11%
   批次 150/391: 損失=0.9153, 準確率=75.03%
   批次 200/391: 損失=0.9156, 準確率=75.02%
   批次 250/391: 損失=0.9119, 準確率=75.13%
   批次 300/391: 損失=0.9159, 準確率=74.98%
   批次 350/391: 損失=0.9156, 準確率=75.02%
   批次 391/391: 損失=0.9171, 準確率=75.01%
Epoch 12 完成: 訓練=75.01%, 驗證=73.50%, 時間=82.1s
   💾 新最佳模型已保存: 驗證準確率 73.50%

Epoch 13/75, LR: 0.002815
   批次  50/391: 損失=0.8963, 準確率=75.28%
   批次 100/391: 損失=0.8936, 準確率=75.93%
   批次 150/391: 損失=0.8914, 準確率=75.80%
   批次 200/391: 損失=0.8944, 準確率=75.62%
   批次 250/391: 損失=0.8965, 準確率=75.64%
   批次 300/391: 損失=0.9005, 準確率=75.41%
   批次 350/391: 損失=0.9019, 準確率=75.41%
   批次 391/391: 損失=0.9024, 準確率=75.40%
Epoch 13 完成: 訓練=75.40%, 驗證=73.26%, 時間=86.6s

Epoch 14/75, LR: 0.002784
   批次  50/391: 損失=0.8610, 準確率=77.00%
   批次 100/391: 損失=0.8698, 準確率=76.52%
   批次 150/391: 損失=0.8809, 準確率=76.10%
   批次 200/391: 損失=0.8846, 準確率=76.00%
   批次 250/391: 損失=0.8854, 準確率=76.04%
   批次 300/391: 損失=0.8831, 準確率=76.03%
   批次 350/391: 損失=0.8845, 準確率=75.96%
   批次 391/391: 損失=0.8834, 準確率=76.00%
Epoch 14 完成: 訓練=76.00%, 驗證=73.71%, 時間=81.7s
   💾 新最佳模型已保存: 驗證準確率 73.71%

Epoch 15/75, LR: 0.002750
   批次  50/391: 損失=0.8568, 準確率=77.30%
   批次 100/391: 損失=0.8651, 準確率=76.94%
   批次 150/391: 損失=0.8672, 準確率=76.78%
   批次 200/391: 損失=0.8629, 準確率=77.05%
   批次 250/391: 損失=0.8666, 準確率=76.85%
   批次 300/391: 損失=0.8694, 準確率=76.74%
   批次 350/391: 損失=0.8704, 準確率=76.71%
   批次 391/391: 損失=0.8726, 準確率=76.57%
Epoch 15 完成: 訓練=76.57%, 驗證=74.08%, 時間=85.8s
   💾 新最佳模型已保存: 驗證準確率 74.08%

Epoch 16/75, LR: 0.002714
   批次  50/391: 損失=0.8525, 準確率=76.42%
   批次 100/391: 損失=0.8602, 準確率=76.64%
   批次 150/391: 損失=0.8591, 準確率=76.74%
   批次 200/391: 損失=0.8601, 準確率=76.84%
   批次 250/391: 損失=0.8550, 準確率=77.00%
   批次 300/391: 損失=0.8566, 準確率=76.98%
   批次 350/391: 損失=0.8548, 準確率=77.04%
   批次 391/391: 損失=0.8558, 準確率=77.05%
Epoch 16 完成: 訓練=77.05%, 驗證=74.39%, 時間=87.8s
   💾 新最佳模型已保存: 驗證準確率 74.39%

Epoch 17/75, LR: 0.002677
   批次  50/391: 損失=0.8316, 準確率=78.45%
   批次 100/391: 損失=0.8285, 準確率=78.45%
   批次 150/391: 損失=0.8283, 準確率=78.45%
   批次 200/391: 損失=0.8276, 準確率=78.43%
   批次 250/391: 損失=0.8315, 準確率=78.31%
   批次 300/391: 損失=0.8348, 準確率=78.17%
   批次 350/391: 損失=0.8379, 準確率=78.10%
   批次 391/391: 損失=0.8386, 準確率=78.00%
Epoch 17 完成: 訓練=78.00%, 驗證=74.45%, 時間=84.2s
   💾 新最佳模型已保存: 驗證準確率 74.45%

Epoch 18/75, LR: 0.002637
   批次  50/391: 損失=0.8204, 準確率=78.45%
   批次 100/391: 損失=0.8243, 準確率=78.55%
   批次 150/391: 損失=0.8257, 準確率=78.48%
   批次 200/391: 損失=0.8251, 準確率=78.50%
   批次 250/391: 損失=0.8313, 準確率=78.15%
   批次 300/391: 損失=0.8304, 準確率=78.20%
   批次 350/391: 損失=0.8301, 準確率=78.24%
   批次 391/391: 損失=0.8311, 準確率=78.21%
Epoch 18 完成: 訓練=78.21%, 驗證=75.31%, 時間=85.4s
   💾 新最佳模型已保存: 驗證準確率 75.31%

Epoch 19/75, LR: 0.002595
   批次  50/391: 損失=0.7985, 準確率=79.92%
   批次 100/391: 損失=0.8099, 準確率=79.22%
   批次 150/391: 損失=0.8108, 準確率=79.08%
   批次 200/391: 損失=0.8154, 準確率=78.80%
   批次 250/391: 損失=0.8173, 準確率=78.75%
   批次 300/391: 損失=0.8178, 準確率=78.73%
   批次 350/391: 損失=0.8199, 準確率=78.72%
   批次 391/391: 損失=0.8186, 準確率=78.81%
Epoch 19 完成: 訓練=78.81%, 驗證=75.54%, 時間=83.2s
   💾 新最佳模型已保存: 驗證準確率 75.54%

Epoch 20/75, LR: 0.002551
   批次  50/391: 損失=0.8034, 準確率=80.19%
   批次 100/391: 損失=0.8120, 準確率=79.44%
   批次 150/391: 損失=0.8098, 準確率=79.54%
   批次 200/391: 損失=0.8079, 準確率=79.46%
   批次 250/391: 損失=0.8050, 準確率=79.48%
   批次 300/391: 損失=0.8055, 準確率=79.35%
   批次 350/391: 損失=0.8070, 準確率=79.40%
   批次 391/391: 損失=0.8077, 準確率=79.35%
Epoch 20 完成: 訓練=79.35%, 驗證=76.21%, 時間=84.6s
   💾 新最佳模型已保存: 驗證準確率 76.21%

Epoch 21/75, LR: 0.002505
   批次  50/391: 損失=0.7880, 準確率=80.19%
   批次 100/391: 損失=0.7946, 準確率=79.75%
   批次 150/391: 損失=0.7912, 準確率=79.85%
   批次 200/391: 損失=0.7966, 準確率=79.53%
   批次 250/391: 損失=0.7983, 準確率=79.42%
   批次 300/391: 損失=0.7964, 準確率=79.50%
   批次 350/391: 損失=0.7965, 準確率=79.54%
   批次 391/391: 損失=0.7981, 準確率=79.50%
Epoch 21 完成: 訓練=79.50%, 驗證=75.95%, 時間=83.0s

Epoch 22/75, LR: 0.002458
   批次  50/391: 損失=0.7598, 準確率=81.92%
   批次 100/391: 損失=0.7659, 準確率=81.13%
   批次 150/391: 損失=0.7703, 準確率=80.80%
   批次 200/391: 損失=0.7736, 準確率=80.61%
   批次 250/391: 損失=0.7795, 準確率=80.42%
   批次 300/391: 損失=0.7821, 準確率=80.32%
   批次 350/391: 損失=0.7822, 準確率=80.40%
   批次 391/391: 損失=0.7822, 準確率=80.37%
Epoch 22 完成: 訓練=80.37%, 驗證=75.89%, 時間=82.5s

Epoch 23/75, LR: 0.002409
   批次  50/391: 損失=0.7647, 準確率=81.20%
   批次 100/391: 損失=0.7540, 準確率=81.55%
   批次 150/391: 損失=0.7585, 準確率=81.38%
   批次 200/391: 損失=0.7626, 準確率=81.24%
   批次 250/391: 損失=0.7664, 準確率=81.10%
   批次 300/391: 損失=0.7697, 準確率=80.93%
   批次 350/391: 損失=0.7730, 準確率=80.78%
   批次 391/391: 損失=0.7739, 準確率=80.72%
Epoch 23 完成: 訓練=80.72%, 驗證=75.94%, 時間=84.1s

Epoch 24/75, LR: 0.002358
   批次  50/391: 損失=0.7603, 準確率=81.73%
   批次 100/391: 損失=0.7627, 準確率=81.52%
   批次 150/391: 損失=0.7582, 準確率=81.52%
   批次 200/391: 損失=0.7584, 準確率=81.45%
   批次 250/391: 損失=0.7617, 準確率=81.25%
   批次 300/391: 損失=0.7640, 準確率=81.08%
   批次 350/391: 損失=0.7666, 準確率=80.94%
   批次 391/391: 損失=0.7694, 準確率=80.82%
Epoch 24 完成: 訓練=80.82%, 驗證=76.77%, 時間=83.6s
   💾 新最佳模型已保存: 驗證準確率 76.77%

Epoch 25/75, LR: 0.002306
   批次  50/391: 損失=0.7496, 準確率=81.78%
   批次 100/391: 損失=0.7509, 準確率=81.65%
   批次 150/391: 損失=0.7505, 準確率=81.52%
   批次 200/391: 損失=0.7501, 準確率=81.53%
   批次 250/391: 損失=0.7517, 準確率=81.43%
   批次 300/391: 損失=0.7564, 準確率=81.24%
   批次 350/391: 損失=0.7589, 準確率=81.10%
   批次 391/391: 損失=0.7585, 準確率=81.18%
Epoch 25 完成: 訓練=81.18%, 驗證=77.33%, 時間=84.0s
   💾 新最佳模型已保存: 驗證準確率 77.33%

Epoch 26/75, LR: 0.002253
   批次  50/391: 損失=0.7146, 準確率=82.72%
   批次 100/391: 損失=0.7326, 準確率=81.95%
   批次 150/391: 損失=0.7374, 準確率=82.14%
   批次 200/391: 損失=0.7371, 準確率=82.19%
   批次 250/391: 損失=0.7389, 準確率=82.12%
   批次 300/391: 損失=0.7400, 準確率=82.01%
   批次 350/391: 損失=0.7438, 準確率=81.86%
   批次 391/391: 損失=0.7462, 準確率=81.76%
Epoch 26 完成: 訓練=81.76%, 驗證=77.33%, 時間=82.7s

Epoch 27/75, LR: 0.002198
   批次  50/391: 損失=0.7269, 準確率=83.16%
   批次 100/391: 損失=0.7243, 準確率=82.76%
   批次 150/391: 損失=0.7268, 準確率=82.67%
   批次 200/391: 損失=0.7366, 準確率=82.25%
   批次 250/391: 損失=0.7374, 準確率=82.21%
   批次 300/391: 損失=0.7396, 準確率=82.16%
   批次 350/391: 損失=0.7401, 準確率=82.13%
   批次 391/391: 損失=0.7393, 準確率=82.15%
Epoch 27 完成: 訓練=82.15%, 驗證=77.41%, 時間=81.7s
   💾 新最佳模型已保存: 驗證準確率 77.41%

Epoch 28/75, LR: 0.002142
   批次  50/391: 損失=0.7125, 準確率=83.23%
   批次 100/391: 損失=0.7120, 準確率=83.32%
   批次 150/391: 損失=0.7218, 準確率=82.99%
   批次 200/391: 損失=0.7254, 準確率=82.77%
   批次 250/391: 損失=0.7256, 準確率=82.67%
   批次 300/391: 損失=0.7270, 準確率=82.64%
   批次 350/391: 損失=0.7299, 準確率=82.48%
   批次 391/391: 損失=0.7318, 準確率=82.41%
Epoch 28 完成: 訓練=82.41%, 驗證=77.65%, 時間=83.2s
   💾 新最佳模型已保存: 驗證準確率 77.65%

Epoch 29/75, LR: 0.002084
   批次  50/391: 損失=0.7216, 準確率=82.78%
   批次 100/391: 損失=0.7198, 準確率=82.75%
   批次 150/391: 損失=0.7165, 準確率=82.87%
   批次 200/391: 損失=0.7181, 準確率=82.92%
   批次 250/391: 損失=0.7215, 準確率=82.74%
   批次 300/391: 損失=0.7205, 準確率=82.79%
   批次 350/391: 損失=0.7202, 準確率=82.80%
   批次 391/391: 損失=0.7199, 準確率=82.77%
Epoch 29 完成: 訓練=82.77%, 驗證=77.85%, 時間=85.2s
   💾 新最佳模型已保存: 驗證準確率 77.85%

Epoch 30/75, LR: 0.002026
   批次  50/391: 損失=0.7022, 準確率=83.58%
   批次 100/391: 損失=0.7025, 準確率=83.55%
   批次 150/391: 損失=0.7049, 準確率=83.42%
   批次 200/391: 損失=0.7073, 準確率=83.34%
   批次 250/391: 損失=0.7066, 準確率=83.44%
   批次 300/391: 損失=0.7062, 準確率=83.39%
   批次 350/391: 損失=0.7078, 準確率=83.28%
   批次 391/391: 損失=0.7082, 準確率=83.22%
Epoch 30 完成: 訓練=83.22%, 驗證=77.43%, 時間=86.1s
   📊 訓練-驗證差異: 5.79%

Epoch 31/75, LR: 0.001967
   批次  50/391: 損失=0.6900, 準確率=84.41%
   批次 100/391: 損失=0.6916, 準確率=84.35%
   批次 150/391: 損失=0.6993, 準確率=84.15%
   批次 200/391: 損失=0.6999, 準確率=84.05%
   批次 250/391: 損失=0.7005, 準確率=83.88%
   批次 300/391: 損失=0.7026, 準確率=83.80%
   批次 350/391: 損失=0.7018, 準確率=83.81%
   批次 391/391: 損失=0.7040, 準確率=83.70%
Epoch 31 完成: 訓練=83.70%, 驗證=77.67%, 時間=84.9s
   📊 訓練-驗證差異: 6.03%

Epoch 32/75, LR: 0.001907
   批次  50/391: 損失=0.6777, 準確率=84.70%
   批次 100/391: 損失=0.6857, 準確率=84.33%
   批次 150/391: 損失=0.6879, 準確率=84.30%
   批次 200/391: 損失=0.6895, 準確率=84.23%
   批次 250/391: 損失=0.6925, 準確率=84.05%
   批次 300/391: 損失=0.6931, 準確率=84.05%
   批次 350/391: 損失=0.6938, 準確率=84.02%
   批次 391/391: 損失=0.6964, 準確率=83.89%
Epoch 32 完成: 訓練=83.89%, 驗證=78.06%, 時間=83.8s
   📊 訓練-驗證差異: 5.83%
   💾 新最佳模型已保存: 驗證準確率 78.06%

Epoch 33/75, LR: 0.001846
   批次  50/391: 損失=0.6804, 準確率=84.53%
   批次 100/391: 損失=0.6744, 準確率=85.11%
   批次 150/391: 損失=0.6777, 準確率=84.79%
   批次 200/391: 損失=0.6805, 準確率=84.57%
   批次 250/391: 損失=0.6850, 準確率=84.34%
   批次 300/391: 損失=0.6855, 準確率=84.28%
   批次 350/391: 損失=0.6866, 準確率=84.19%
   批次 391/391: 損失=0.6881, 準確率=84.13%
Epoch 33 完成: 訓練=84.13%, 驗證=78.41%, 時間=84.9s
   📊 訓練-驗證差異: 5.72%
   💾 新最佳模型已保存: 驗證準確率 78.41%

Epoch 34/75, LR: 0.001785
   批次  50/391: 損失=0.6627, 準確率=85.38%
   批次 100/391: 損失=0.6637, 準確率=85.20%
   批次 150/391: 損失=0.6689, 準確率=85.07%
   批次 200/391: 損失=0.6732, 準確率=84.85%
   批次 250/391: 損失=0.6763, 準確率=84.68%
   批次 300/391: 損失=0.6737, 準確率=84.80%
   批次 350/391: 損失=0.6757, 準確率=84.73%
   批次 391/391: 損失=0.6762, 準確率=84.67%
Epoch 34 完成: 訓練=84.67%, 驗證=78.68%, 時間=83.3s
   📊 訓練-驗證差異: 5.99%
   💾 新最佳模型已保存: 驗證準確率 78.68%

Epoch 35/75, LR: 0.001723
   批次  50/391: 損失=0.6473, 準確率=85.86%
   批次 100/391: 損失=0.6580, 準確率=85.41%
   批次 150/391: 損失=0.6581, 準確率=85.51%
   批次 200/391: 損失=0.6650, 準確率=85.09%
   批次 250/391: 損失=0.6669, 準確率=84.98%
   批次 300/391: 損失=0.6688, 準確率=84.93%
   批次 350/391: 損失=0.6711, 準確率=84.82%
   批次 391/391: 損失=0.6728, 準確率=84.78%
Epoch 35 完成: 訓練=84.78%, 驗證=78.30%, 時間=83.2s
   📊 訓練-驗證差異: 6.48%

Epoch 36/75, LR: 0.001661
   批次  50/391: 損失=0.6795, 準確率=84.75%
   批次 100/391: 損失=0.6686, 準確率=85.21%
   批次 150/391: 損失=0.6663, 準確率=85.35%
   批次 200/391: 損失=0.6673, 準確率=85.19%
   批次 250/391: 損失=0.6636, 準確率=85.30%
   批次 300/391: 損失=0.6679, 準確率=85.12%
   批次 350/391: 損失=0.6683, 準確率=85.09%
   批次 391/391: 損失=0.6675, 準確率=85.14%
Epoch 36 完成: 訓練=85.14%, 驗證=78.47%, 時間=84.3s
   📊 訓練-驗證差異: 6.67%

Epoch 37/75, LR: 0.001599
   批次  50/391: 損失=0.6359, 準確率=86.20%
   批次 100/391: 損失=0.6441, 準確率=85.98%
   批次 150/391: 損失=0.6455, 準確率=85.90%
   批次 200/391: 損失=0.6470, 準確率=85.73%
   批次 250/391: 損失=0.6457, 準確率=85.78%
   批次 300/391: 損失=0.6504, 準確率=85.57%
   批次 350/391: 損失=0.6530, 準確率=85.40%
   批次 391/391: 損失=0.6550, 準確率=85.36%
Epoch 37 完成: 訓練=85.36%, 驗證=78.68%, 時間=86.3s
   📊 訓練-驗證差異: 6.68%

Epoch 38/75, LR: 0.001536
   批次  50/391: 損失=0.6325, 準確率=86.72%
   批次 100/391: 損失=0.6338, 準確率=86.54%
   批次 150/391: 損失=0.6333, 準確率=86.37%
   批次 200/391: 損失=0.6394, 準確率=86.22%
   批次 250/391: 損失=0.6427, 準確率=86.17%
   批次 300/391: 損失=0.6439, 準確率=86.08%
   批次 350/391: 損失=0.6466, 準確率=85.94%
   批次 391/391: 損失=0.6473, 準確率=85.94%
Epoch 38 完成: 訓練=85.94%, 驗證=78.39%, 時間=85.5s
   📊 訓練-驗證差異: 7.55%

Epoch 39/75, LR: 0.001474
   批次  50/391: 損失=0.6172, 準確率=87.22%
   批次 100/391: 損失=0.6344, 準確率=86.57%
   批次 150/391: 損失=0.6359, 準確率=86.51%
   批次 200/391: 損失=0.6366, 準確率=86.43%
   批次 250/391: 損失=0.6388, 準確率=86.35%
   批次 300/391: 損失=0.6401, 準確率=86.28%
   批次 350/391: 損失=0.6415, 準確率=86.19%
   批次 391/391: 損失=0.6411, 準確率=86.23%
Epoch 39 完成: 訓練=86.23%, 驗證=79.07%, 時間=83.2s
   📊 訓練-驗證差異: 7.16%
   💾 新最佳模型已保存: 驗證準確率 79.07%

Epoch 40/75, LR: 0.001411
   批次  50/391: 損失=0.6311, 準確率=86.98%
   批次 100/391: 損失=0.6293, 準確率=86.95%
   批次 150/391: 損失=0.6288, 準確率=86.84%
   批次 200/391: 損失=0.6296, 準確率=86.80%
   批次 250/391: 損失=0.6323, 準確率=86.66%
   批次 300/391: 損失=0.6341, 準確率=86.59%
   批次 350/391: 損失=0.6342, 準確率=86.57%
   批次 391/391: 損失=0.6356, 準確率=86.47%
Epoch 40 完成: 訓練=86.47%, 驗證=78.55%, 時間=83.2s
   📊 訓練-驗證差異: 7.92%

Epoch 41/75, LR: 0.001349
   批次  50/391: 損失=0.6106, 準確率=87.59%
   批次 100/391: 損失=0.6189, 準確率=87.29%
   批次 150/391: 損失=0.6198, 準確率=87.30%
   批次 200/391: 損失=0.6210, 準確率=87.20%
   批次 250/391: 損失=0.6239, 準確率=87.08%
   批次 300/391: 損失=0.6266, 準確率=86.90%
   批次 350/391: 損失=0.6264, 準確率=86.92%
   批次 391/391: 損失=0.6265, 準確率=86.94%
Epoch 41 完成: 訓練=86.94%, 驗證=79.21%, 時間=83.4s
   📊 訓練-驗證差異: 7.73%
   💾 新最佳模型已保存: 驗證準確率 79.21%

Epoch 42/75, LR: 0.001287
   批次  50/391: 損失=0.6012, 準確率=87.67%
   批次 100/391: 損失=0.6114, 準確率=87.01%
   批次 150/391: 損失=0.6172, 準確率=86.83%
   批次 200/391: 損失=0.6204, 準確率=86.80%
   批次 250/391: 損失=0.6218, 準確率=86.73%
   批次 300/391: 損失=0.6231, 準確率=86.72%
   批次 350/391: 損失=0.6225, 準確率=86.75%
   批次 391/391: 損失=0.6224, 準確率=86.80%
Epoch 42 完成: 訓練=86.80%, 驗證=78.69%, 時間=85.3s
   ⚠️  過擬合警告: 差異 8.11% > 閾值 8.0% (1/6)
   📊 訓練-驗證差異: 8.11%

Epoch 43/75, LR: 0.001225
   批次  50/391: 損失=0.6015, 準確率=87.83%
   批次 100/391: 損失=0.6023, 準確率=87.81%
   批次 150/391: 損失=0.6033, 準確率=87.66%
   批次 200/391: 損失=0.6069, 準確率=87.43%
   批次 250/391: 損失=0.6093, 準確率=87.42%
   批次 300/391: 損失=0.6132, 準確率=87.28%
   批次 350/391: 損失=0.6126, 準確率=87.29%
   批次 391/391: 損失=0.6149, 準確率=87.26%
Epoch 43 完成: 訓練=87.26%, 驗證=79.14%, 時間=84.7s
   ⚠️  過擬合警告: 差異 8.12% > 閾值 8.0% (2/6)
   📊 訓練-驗證差異: 8.12%

Epoch 44/75, LR: 0.001164
   批次  50/391: 損失=0.5959, 準確率=88.22%
   批次 100/391: 損失=0.5992, 準確率=88.15%
   批次 150/391: 損失=0.5987, 準確率=88.05%
   批次 200/391: 損失=0.6005, 準確率=87.86%
   批次 250/391: 損失=0.6017, 準確率=87.80%
   批次 300/391: 損失=0.6048, 準確率=87.69%
   批次 350/391: 損失=0.6051, 準確率=87.68%
   批次 391/391: 損失=0.6073, 準確率=87.53%
Epoch 44 完成: 訓練=87.53%, 驗證=78.76%, 時間=84.6s
   ⚠️  過擬合警告: 差異 8.77% > 閾值 8.0% (3/6)
   📊 訓練-驗證差異: 8.77%

Epoch 45/75, LR: 0.001103
   批次  50/391: 損失=0.5936, 準確率=87.95%
   批次 100/391: 損失=0.5963, 準確率=88.02%
   批次 150/391: 損失=0.5956, 準確率=88.02%
   批次 200/391: 損失=0.5980, 準確率=87.95%
   批次 250/391: 損失=0.5964, 準確率=88.11%
   批次 300/391: 損失=0.5986, 準確率=88.05%
   批次 350/391: 損失=0.6008, 準確率=87.98%
   批次 391/391: 損失=0.6018, 準確率=87.88%
Epoch 45 完成: 訓練=87.88%, 驗證=78.99%, 時間=86.2s
   ⚠️  過擬合警告: 差異 8.89% > 閾值 8.0% (4/6)
   📊 訓練-驗證差異: 8.89%

Epoch 46/75, LR: 0.001043
   批次  50/391: 損失=0.5840, 準確率=88.52%
   批次 100/391: 損失=0.5895, 準確率=88.28%
   批次 150/391: 損失=0.5874, 準確率=88.39%
   批次 200/391: 損失=0.5894, 準確率=88.24%
   批次 250/391: 損失=0.5917, 準確率=88.16%
   批次 300/391: 損失=0.5927, 準確率=88.10%
   批次 350/391: 損失=0.5946, 準確率=88.02%
   批次 391/391: 損失=0.5949, 準確率=88.01%
Epoch 46 完成: 訓練=88.01%, 驗證=79.45%, 時間=82.7s
   ⚠️  過擬合警告: 差異 8.56% > 閾值 8.0% (5/6)
   📊 訓練-驗證差異: 8.56%
   💾 新最佳模型已保存: 驗證準確率 79.45%

Epoch 47/75, LR: 0.000984
   批次  50/391: 損失=0.5637, 準確率=89.61%
   批次 100/391: 損失=0.5742, 準確率=89.09%
   批次 150/391: 損失=0.5775, 準確率=88.80%
   批次 200/391: 損失=0.5822, 準確率=88.56%
   批次 250/391: 損失=0.5837, 準確率=88.57%
   批次 300/391: 損失=0.5890, 準確率=88.41%
   批次 350/391: 損失=0.5903, 準確率=88.35%
   批次 391/391: 損失=0.5920, 準確率=88.26%
Epoch 47 完成: 訓練=88.26%, 驗證=78.66%, 時間=84.1s
   ⚠️  過擬合警告: 差異 9.60% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3955.1s (65.9min)
   • 實際訓練epochs: 47 / 75
   • 平均每epoch: 84.1s
   • 最佳驗證準確率: 79.45%
   • 已載入最佳模型權重

📈 繪製超快速訓練歷史...

📊 評估超縮小版模型...
   ✓ 整體準確率: 79.45%

🎉 訓練完成總結:
   • 選擇模型: Nano
   • 最終準確率: 79.45%
   • 總訓練時間: 65.9 分鐘
   • 平均每epoch: 84.1 秒
   • 實際訓練輪數: 47/75
   • 早停狀態: 啟用
