🚀 超縮小版 gMLP 圖像分類訓練開始
============================================================

📋 超縮小版 gMLP 模型架構比較:
=====================================================================================
模型       深度     維度       FFN倍數    參數(M)      過擬合風險       
-------------------------------------------------------------------------------------
Nano     6      64       2        0.3        很低
XS       8      80       3        0.8        低
S        12     128      3        2.0        中等
M        16     160      4        4.5        較高
L        30     128      6        5.9        很高
-------------------------------------------------------------------------------------
🎯 建議（針對10K訓練樣本）:
   • Nano: 極速原型開發，最低過擬合風險 (<1分鐘訓練)
   • XS: 快速實驗，低過擬合風險 (~2分鐘訓練) ⭐推薦
   • S: 平衡性能與速度，中等過擬合風險 (~5分鐘訓練)
   • M: 較好性能但過擬合風險較高 (~10分鐘訓練)
   • L: 最大模型，很高過擬合風險，不建議用於小數據集
📦 加載超快速 CIFAR-10 數據集...
   🚀 超快速模式：小規模數據集訓練
   ✓ 訓練樣本: 50000
   ✓ 測試樣本: 10000
   ✓ Batch大小: 64

🏗️ 創建超縮小版 gMLP-Nano 模型...
   ⚡ CPU模式：已設置4個線程
   ✓ 超縮小版 gMLP-Nano 模型創建完成
   ✓ 設備: cpu
   ✓ 參數數量: 105,290 (0.11M)
   ✓ 目標參數: 0.3M
   ✓ 模型大小: 0.4 MB
   ✓ 架構: depth=6, dim=64, ff_mult=2

🏋️ 開始超快速訓練 (50 個 epochs)...
   🛡️  啟用過擬合早停保護

Epoch 1/50, LR: 0.003000
   批次  50/782: 損失=2.0273, 準確率=26.03%
   批次 100/782: 損失=1.9259, 準確率=30.12%
   批次 150/782: 損失=1.8555, 準確率=33.36%
   批次 200/782: 損失=1.8059, 準確率=35.59%
   批次 250/782: 損失=1.7658, 準確率=37.41%
   批次 300/782: 損失=1.7368, 準確率=38.48%
   批次 350/782: 損失=1.7182, 準確率=39.33%
   批次 400/782: 損失=1.6938, 準確率=40.42%
   批次 450/782: 損失=1.6721, 準確率=41.39%
   批次 500/782: 損失=1.6581, 準確率=42.05%
   批次 550/782: 損失=1.6446, 準確率=42.73%
   批次 600/782: 損失=1.6338, 準確率=43.29%
   批次 650/782: 損失=1.6208, 準確率=43.92%
   批次 700/782: 損失=1.6083, 準確率=44.56%
   批次 750/782: 損失=1.5983, 準確率=45.02%
   批次 782/782: 損失=1.5918, 準確率=45.28%
Epoch 1 完成: 訓練=45.28%, 驗證=54.78%, 時間=94.7s
   💾 新最佳模型已保存: 驗證準確率 54.78%

Epoch 2/50, LR: 0.002997
   批次  50/782: 損失=1.4130, 準確率=53.53%
   批次 100/782: 損失=1.4048, 準確率=53.73%
   批次 150/782: 損失=1.3926, 準確率=54.10%
   批次 200/782: 損失=1.3967, 準確率=54.07%
   批次 250/782: 損失=1.3938, 準確率=54.18%
   批次 300/782: 損失=1.3863, 準確率=54.54%
   批次 350/782: 損失=1.3789, 準確率=54.78%
   批次 400/782: 損失=1.3736, 準確率=55.07%
   批次 450/782: 損失=1.3706, 準確率=55.23%
   批次 500/782: 損失=1.3638, 準確率=55.53%
   批次 550/782: 損失=1.3576, 準確率=55.87%
   批次 600/782: 損失=1.3528, 準確率=56.17%
   批次 650/782: 損失=1.3485, 準確率=56.31%
   批次 700/782: 損失=1.3440, 準確率=56.51%
   批次 750/782: 損失=1.3384, 準確率=56.79%
   批次 782/782: 損失=1.3358, 準確率=56.89%
Epoch 2 完成: 訓練=56.89%, 驗證=60.22%, 時間=90.8s
   💾 新最佳模型已保存: 驗證準確率 60.22%

Epoch 3/50, LR: 0.002988
   批次  50/782: 損失=1.2876, 準確率=59.41%
   批次 100/782: 損失=1.2785, 準確率=59.00%
   批次 150/782: 損失=1.2564, 準確率=59.99%
   批次 200/782: 損失=1.2495, 準確率=60.36%
   批次 250/782: 損失=1.2524, 準確率=60.31%
   批次 300/782: 損失=1.2498, 準確率=60.51%
   批次 350/782: 損失=1.2444, 準確率=60.67%
   批次 400/782: 損失=1.2410, 準確率=60.90%
   批次 450/782: 損失=1.2376, 準確率=61.10%
   批次 500/782: 損失=1.2339, 準確率=61.22%
   批次 550/782: 損失=1.2326, 準確率=61.29%
   批次 600/782: 損失=1.2276, 準確率=61.44%
   批次 650/782: 損失=1.2260, 準確率=61.48%
   批次 700/782: 損失=1.2250, 準確率=61.53%
   批次 750/782: 損失=1.2237, 準確率=61.57%
   批次 782/782: 損失=1.2227, 準確率=61.63%
Epoch 3 完成: 訓練=61.63%, 驗證=63.91%, 時間=90.7s
   💾 新最佳模型已保存: 驗證準確率 63.91%

Epoch 4/50, LR: 0.002974
   批次  50/782: 損失=1.1468, 準確率=65.03%
   批次 100/782: 損失=1.1543, 準確率=64.31%
   批次 150/782: 損失=1.1526, 準確率=64.05%
   批次 200/782: 損失=1.1606, 準確率=64.07%
   批次 250/782: 損失=1.1599, 準確率=64.16%
   批次 300/782: 損失=1.1597, 準確率=64.33%
   批次 350/782: 損失=1.1596, 準確率=64.50%
   批次 400/782: 損失=1.1599, 準確率=64.57%
   批次 450/782: 損失=1.1574, 準確率=64.65%
   批次 500/782: 損失=1.1531, 準確率=64.76%
   批次 550/782: 損失=1.1516, 準確率=64.76%
   批次 600/782: 損失=1.1499, 準確率=64.81%
   批次 650/782: 損失=1.1484, 準確率=64.87%
   批次 700/782: 損失=1.1493, 準確率=64.85%
   批次 750/782: 損失=1.1501, 準確率=64.81%
   批次 782/782: 損失=1.1510, 準確率=64.79%
Epoch 4 完成: 訓練=64.79%, 驗證=65.19%, 時間=91.2s
   💾 新最佳模型已保存: 驗證準確率 65.19%

Epoch 5/50, LR: 0.002953
   批次  50/782: 損失=1.1263, 準確率=66.00%
   批次 100/782: 損失=1.1123, 準確率=66.36%
   批次 150/782: 損失=1.1029, 準確率=66.72%
   批次 200/782: 損失=1.1051, 準確率=66.59%
   批次 250/782: 損失=1.1086, 準確率=66.51%
   批次 300/782: 損失=1.1081, 準確率=66.66%
   批次 350/782: 損失=1.1091, 準確率=66.54%
   批次 400/782: 損失=1.1081, 準確率=66.59%
   批次 450/782: 損失=1.1077, 準確率=66.62%
   批次 500/782: 損失=1.1080, 準確率=66.62%
   批次 550/782: 損失=1.1071, 準確率=66.62%
   批次 600/782: 損失=1.1068, 準確率=66.66%
   批次 650/782: 損失=1.1062, 準確率=66.70%
   批次 700/782: 損失=1.1042, 準確率=66.83%
   批次 750/782: 損失=1.1028, 準確率=66.93%
   批次 782/782: 損失=1.1029, 準確率=66.94%
Epoch 5 完成: 訓練=66.94%, 驗證=67.41%, 時間=92.2s
   💾 新最佳模型已保存: 驗證準確率 67.41%

Epoch 6/50, LR: 0.002927
   批次  50/782: 損失=1.0449, 準確率=68.78%
   批次 100/782: 損失=1.0474, 準確率=68.69%
   批次 150/782: 損失=1.0564, 準確率=68.73%
   批次 200/782: 損失=1.0602, 準確率=68.71%
   批次 250/782: 損失=1.0572, 準確率=68.85%
   批次 300/782: 損失=1.0592, 準確率=68.81%
   批次 350/782: 損失=1.0606, 準確率=68.70%
   批次 400/782: 損失=1.0610, 準確率=68.69%
   批次 450/782: 損失=1.0619, 準確率=68.64%
   批次 500/782: 損失=1.0630, 準確率=68.65%
   批次 550/782: 損失=1.0652, 準確率=68.57%
   批次 600/782: 損失=1.0659, 準確率=68.53%
   批次 650/782: 損失=1.0671, 準確率=68.42%
   批次 700/782: 損失=1.0664, 準確率=68.46%
   批次 750/782: 損失=1.0652, 準確率=68.53%
   批次 782/782: 損失=1.0641, 準確率=68.55%
Epoch 6 完成: 訓練=68.55%, 驗證=68.90%, 時間=89.4s
   💾 新最佳模型已保存: 驗證準確率 68.90%

Epoch 7/50, LR: 0.002895
   批次  50/782: 損失=1.0186, 準確率=71.06%
   批次 100/782: 損失=1.0325, 準確率=70.27%
   批次 150/782: 損失=1.0430, 準確率=69.69%
   批次 200/782: 損失=1.0423, 準確率=69.50%
   批次 250/782: 損失=1.0402, 準確率=69.68%
   批次 300/782: 損失=1.0343, 準確率=69.89%
   批次 350/782: 損失=1.0361, 準確率=69.92%
   批次 400/782: 損失=1.0323, 準確率=70.12%
   批次 450/782: 損失=1.0346, 準確率=69.95%
   批次 500/782: 損失=1.0331, 準確率=70.02%
   批次 550/782: 損失=1.0377, 準確率=69.80%
   批次 600/782: 損失=1.0378, 準確率=69.76%
   批次 650/782: 損失=1.0363, 準確率=69.80%
   批次 700/782: 損失=1.0361, 準確率=69.80%
   批次 750/782: 損失=1.0358, 準確率=69.82%
   批次 782/782: 損失=1.0334, 準確率=69.94%
Epoch 7 完成: 訓練=69.94%, 驗證=69.43%, 時間=90.8s
   💾 新最佳模型已保存: 驗證準確率 69.43%

Epoch 8/50, LR: 0.002858
   批次  50/782: 損失=0.9857, 準確率=71.91%
   批次 100/782: 損失=0.9891, 準確率=71.91%
   批次 150/782: 損失=0.9934, 準確率=71.57%
   批次 200/782: 損失=0.9935, 準確率=71.40%
   批次 250/782: 損失=0.9939, 準確率=71.43%
   批次 300/782: 損失=0.9972, 準確率=71.33%
   批次 350/782: 損失=0.9944, 準確率=71.46%
   批次 400/782: 損失=0.9953, 準確率=71.45%
   批次 450/782: 損失=0.9977, 準確率=71.31%
   批次 500/782: 損失=0.9998, 準確率=71.28%
   批次 550/782: 損失=1.0011, 準確率=71.30%
   批次 600/782: 損失=1.0009, 準確率=71.35%
   批次 650/782: 損失=1.0010, 準確率=71.34%
   批次 700/782: 損失=1.0028, 準確率=71.29%
   批次 750/782: 損失=1.0030, 準確率=71.18%
   批次 782/782: 損失=1.0034, 準確率=71.19%
Epoch 8 完成: 訓練=71.19%, 驗證=70.92%, 時間=89.6s
   💾 新最佳模型已保存: 驗證準確率 70.92%

Epoch 9/50, LR: 0.002815
   批次  50/782: 損失=0.9807, 準確率=72.28%
   批次 100/782: 損失=0.9771, 準確率=72.17%
   批次 150/782: 損失=0.9810, 準確率=72.09%
   批次 200/782: 損失=0.9830, 準確率=72.08%
   批次 250/782: 損失=0.9859, 準確率=71.83%
   批次 300/782: 損失=0.9857, 準確率=71.80%
   批次 350/782: 損失=0.9858, 準確率=71.80%
   批次 400/782: 損失=0.9860, 準確率=71.85%
   批次 450/782: 損失=0.9826, 準確率=72.06%
   批次 500/782: 損失=0.9833, 準確率=72.09%
   批次 550/782: 損失=0.9847, 準確率=72.06%
   批次 600/782: 損失=0.9818, 準確率=72.20%
   批次 650/782: 損失=0.9821, 準確率=72.25%
   批次 700/782: 損失=0.9840, 準確率=72.15%
   批次 750/782: 損失=0.9834, 準確率=72.18%
   批次 782/782: 損失=0.9824, 準確率=72.16%
Epoch 9 完成: 訓練=72.16%, 驗證=71.23%, 時間=89.2s
   💾 新最佳模型已保存: 驗證準確率 71.23%

Epoch 10/50, LR: 0.002767
   批次  50/782: 損失=0.9567, 準確率=72.97%
   批次 100/782: 損失=0.9671, 準確率=72.72%
   批次 150/782: 損失=0.9707, 準確率=72.66%
   批次 200/782: 損失=0.9667, 準確率=72.81%
   批次 250/782: 損失=0.9668, 準確率=72.86%
   批次 300/782: 損失=0.9662, 準確率=72.82%
   批次 350/782: 損失=0.9617, 準確率=73.04%
   批次 400/782: 損失=0.9635, 準確率=72.97%
   批次 450/782: 損失=0.9622, 準確率=73.08%
   批次 500/782: 損失=0.9627, 準確率=73.07%
   批次 550/782: 損失=0.9632, 準確率=72.95%
   批次 600/782: 損失=0.9642, 準確率=72.85%
   批次 650/782: 損失=0.9614, 準確率=72.94%
   批次 700/782: 損失=0.9627, 準確率=72.95%
   批次 750/782: 損失=0.9609, 準確率=73.04%
   批次 782/782: 損失=0.9605, 準確率=73.06%
Epoch 10 完成: 訓練=73.06%, 驗證=71.63%, 時間=89.7s
   💾 新最佳模型已保存: 驗證準確率 71.63%

Epoch 11/50, LR: 0.002714
   批次  50/782: 損失=0.9400, 準確率=73.50%
   批次 100/782: 損失=0.9340, 準確率=73.77%
   批次 150/782: 損失=0.9341, 準確率=73.97%
   批次 200/782: 損失=0.9314, 準確率=73.96%
   批次 250/782: 損失=0.9297, 準確率=73.96%
   批次 300/782: 損失=0.9291, 準確率=74.00%
   批次 350/782: 損失=0.9311, 準確率=73.96%
   批次 400/782: 損失=0.9350, 準確率=73.75%
   批次 450/782: 損失=0.9349, 準確率=73.86%
   批次 500/782: 損失=0.9359, 準確率=73.87%
   批次 550/782: 損失=0.9350, 準確率=73.94%
   批次 600/782: 損失=0.9337, 準確率=74.00%
   批次 650/782: 損失=0.9355, 準確率=73.90%
   批次 700/782: 損失=0.9351, 準確率=73.98%
   批次 750/782: 損失=0.9342, 準確率=74.02%
   批次 782/782: 損失=0.9342, 準確率=74.03%
Epoch 11 完成: 訓練=74.03%, 驗證=72.14%, 時間=90.3s
   💾 新最佳模型已保存: 驗證準確率 72.14%

Epoch 12/50, LR: 0.002657
   批次  50/782: 損失=0.8912, 準確率=75.25%
   批次 100/782: 損失=0.8964, 準確率=75.25%
   批次 150/782: 損失=0.9031, 準確率=74.90%
   批次 200/782: 損失=0.9015, 準確率=75.15%
   批次 250/782: 損失=0.9061, 準確率=74.95%
   批次 300/782: 損失=0.9070, 準確率=75.00%
   批次 350/782: 損失=0.9052, 準確率=75.06%
   批次 400/782: 損失=0.9055, 準確率=75.02%
   批次 450/782: 損失=0.9055, 準確率=75.12%
   批次 500/782: 損失=0.9055, 準確率=75.13%
   批次 550/782: 損失=0.9070, 準確率=75.17%
   批次 600/782: 損失=0.9084, 準確率=75.12%
   批次 650/782: 損失=0.9085, 準確率=75.12%
   批次 700/782: 損失=0.9093, 準確率=75.06%
   批次 750/782: 損失=0.9084, 準確率=75.06%
   批次 782/782: 損失=0.9089, 準確率=75.05%
Epoch 12 完成: 訓練=75.05%, 驗證=73.71%, 時間=88.1s
   💾 新最佳模型已保存: 驗證準確率 73.71%

Epoch 13/50, LR: 0.002595
   批次  50/782: 損失=0.8931, 準確率=75.84%
   批次 100/782: 損失=0.8913, 準確率=76.16%
   批次 150/782: 損失=0.8846, 準確率=76.40%
   批次 200/782: 損失=0.8835, 準確率=76.52%
   批次 250/782: 損失=0.8852, 準確率=76.49%
   批次 300/782: 損失=0.8840, 準確率=76.26%
   批次 350/782: 損失=0.8848, 準確率=76.25%
   批次 400/782: 損失=0.8858, 準確率=76.16%
   批次 450/782: 損失=0.8883, 準確率=75.93%
   批次 500/782: 損失=0.8892, 準確率=75.93%
   批次 550/782: 損失=0.8895, 準確率=75.95%
   批次 600/782: 損失=0.8896, 準確率=75.90%
   批次 650/782: 損失=0.8913, 準確率=75.87%
   批次 700/782: 損失=0.8915, 準確率=75.90%
   批次 750/782: 損失=0.8894, 準確率=76.00%
   批次 782/782: 損失=0.8880, 準確率=76.06%
Epoch 13 完成: 訓練=76.06%, 驗證=74.63%, 時間=91.5s
   💾 新最佳模型已保存: 驗證準確率 74.63%

Epoch 14/50, LR: 0.002528
   批次  50/782: 損失=0.8579, 準確率=76.56%
   批次 100/782: 損失=0.8643, 準確率=76.44%
   批次 150/782: 損失=0.8672, 準確率=76.41%
   批次 200/782: 損失=0.8625, 準確率=76.94%
   批次 250/782: 損失=0.8606, 準確率=76.83%
   批次 300/782: 損失=0.8618, 準確率=76.88%
   批次 350/782: 損失=0.8638, 準確率=76.89%
   批次 400/782: 損失=0.8674, 準確率=76.75%
   批次 450/782: 損失=0.8668, 準確率=76.87%
   批次 500/782: 損失=0.8709, 準確率=76.69%
   批次 550/782: 損失=0.8727, 準確率=76.64%
   批次 600/782: 損失=0.8732, 準確率=76.61%
   批次 650/782: 損失=0.8748, 準確率=76.53%
   批次 700/782: 損失=0.8760, 準確率=76.48%
   批次 750/782: 損失=0.8754, 準確率=76.45%
   批次 782/782: 損失=0.8744, 準確率=76.49%
Epoch 14 完成: 訓練=76.49%, 驗證=74.25%, 時間=90.4s

Epoch 15/50, LR: 0.002458
   批次  50/782: 損失=0.8536, 準確率=77.56%
   批次 100/782: 損失=0.8661, 準確率=76.66%
   批次 150/782: 損失=0.8572, 準確率=77.04%
   批次 200/782: 損失=0.8595, 準確率=76.94%
   批次 250/782: 損失=0.8578, 準確率=77.14%
   批次 300/782: 損失=0.8550, 準確率=77.32%
   批次 350/782: 損失=0.8526, 準確率=77.44%
   批次 400/782: 損失=0.8542, 準確率=77.42%
   批次 450/782: 損失=0.8580, 準確率=77.20%
   批次 500/782: 損失=0.8551, 準確率=77.29%
   批次 550/782: 損失=0.8557, 準確率=77.27%
   批次 600/782: 損失=0.8562, 準確率=77.24%
   批次 650/782: 損失=0.8568, 準確率=77.23%
   批次 700/782: 損失=0.8576, 準確率=77.24%
   批次 750/782: 損失=0.8590, 準確率=77.13%
   批次 782/782: 損失=0.8570, 準確率=77.23%
Epoch 15 完成: 訓練=77.23%, 驗證=75.62%, 時間=91.1s
   💾 新最佳模型已保存: 驗證準確率 75.62%

Epoch 16/50, LR: 0.002384
   批次  50/782: 損失=0.8094, 準確率=79.41%
   批次 100/782: 損失=0.8273, 準確率=78.47%
   批次 150/782: 損失=0.8273, 準確率=78.61%
   批次 200/782: 損失=0.8329, 準確率=78.22%
   批次 250/782: 損失=0.8381, 準確率=78.06%
   批次 300/782: 損失=0.8358, 準確率=78.23%
   批次 350/782: 損失=0.8291, 準確率=78.40%
   批次 400/782: 損失=0.8277, 準確率=78.48%
   批次 450/782: 損失=0.8290, 準確率=78.35%
   批次 500/782: 損失=0.8305, 準確率=78.25%
   批次 550/782: 損失=0.8350, 準確率=78.06%
   批次 600/782: 損失=0.8358, 準確率=78.02%
   批次 650/782: 損失=0.8350, 準確率=78.04%
   批次 700/782: 損失=0.8375, 準確率=77.94%
   批次 750/782: 損失=0.8373, 準確率=77.95%
   批次 782/782: 損失=0.8368, 準確率=77.96%
Epoch 16 完成: 訓練=77.96%, 驗證=74.88%, 時間=91.1s

Epoch 17/50, LR: 0.002306
   批次  50/782: 損失=0.8168, 準確率=79.03%
   批次 100/782: 損失=0.8203, 準確率=78.95%
   批次 150/782: 損失=0.8193, 準確率=78.96%
   批次 200/782: 損失=0.8227, 準確率=78.90%
   批次 250/782: 損失=0.8224, 準確率=78.75%
   批次 300/782: 損失=0.8197, 準確率=78.68%
   批次 350/782: 損失=0.8209, 準確率=78.67%
   批次 400/782: 損失=0.8215, 準確率=78.65%
   批次 450/782: 損失=0.8183, 準確率=78.78%
   批次 500/782: 損失=0.8160, 準確率=78.89%
   批次 550/782: 損失=0.8192, 準確率=78.74%
   批次 600/782: 損失=0.8193, 準確率=78.75%
   批次 650/782: 損失=0.8207, 準確率=78.76%
   批次 700/782: 損失=0.8212, 準確率=78.76%
   批次 750/782: 損失=0.8231, 準確率=78.66%
   批次 782/782: 損失=0.8242, 準確率=78.61%
Epoch 17 完成: 訓練=78.61%, 驗證=74.98%, 時間=93.0s

Epoch 18/50, LR: 0.002225
   批次  50/782: 損失=0.8181, 準確率=78.94%
   批次 100/782: 損失=0.8210, 準確率=78.88%
   批次 150/782: 損失=0.8175, 準確率=79.17%
   批次 200/782: 損失=0.8090, 準確率=79.57%
   批次 250/782: 損失=0.8045, 準確率=79.74%
   批次 300/782: 損失=0.8044, 準確率=79.72%
   批次 350/782: 損失=0.8062, 準確率=79.59%
   批次 400/782: 損失=0.8041, 準確率=79.72%
   批次 450/782: 損失=0.8056, 準確率=79.54%
   批次 500/782: 損失=0.8059, 準確率=79.49%
   批次 550/782: 損失=0.8081, 準確率=79.36%
   批次 600/782: 損失=0.8081, 準確率=79.32%
   批次 650/782: 損失=0.8095, 準確率=79.21%
   批次 700/782: 損失=0.8104, 準確率=79.16%
   批次 750/782: 損失=0.8130, 準確率=79.09%
   批次 782/782: 損失=0.8141, 準確率=79.05%
Epoch 18 完成: 訓練=79.05%, 驗證=76.16%, 時間=88.9s
   💾 新最佳模型已保存: 驗證準確率 76.16%

Epoch 19/50, LR: 0.002142
   批次  50/782: 損失=0.8034, 準確率=79.78%
   批次 100/782: 損失=0.8027, 準確率=79.53%
   批次 150/782: 損失=0.7887, 準確率=79.93%
   批次 200/782: 損失=0.7925, 準確率=79.85%
   批次 250/782: 損失=0.7949, 準確率=79.74%
   批次 300/782: 損失=0.7969, 準確率=79.49%
   批次 350/782: 損失=0.7978, 準確率=79.52%
   批次 400/782: 損失=0.7969, 準確率=79.57%
   批次 450/782: 損失=0.7998, 準確率=79.48%
   批次 500/782: 損失=0.7995, 準確率=79.55%
   批次 550/782: 損失=0.8014, 準確率=79.48%
   批次 600/782: 損失=0.7997, 準確率=79.55%
   批次 650/782: 損失=0.8000, 準確率=79.51%
   批次 700/782: 損失=0.8002, 準確率=79.52%
   批次 750/782: 損失=0.8009, 準確率=79.47%
   批次 782/782: 損失=0.8011, 準確率=79.50%
Epoch 19 完成: 訓練=79.50%, 驗證=76.66%, 時間=91.4s
   💾 新最佳模型已保存: 驗證準確率 76.66%

Epoch 20/50, LR: 0.002055
   批次  50/782: 損失=0.7636, 準確率=81.47%
   批次 100/782: 損失=0.7679, 準確率=81.00%
   批次 150/782: 損失=0.7741, 準確率=80.65%
   批次 200/782: 損失=0.7723, 準確率=80.84%
   批次 250/782: 損失=0.7763, 準確率=80.66%
   批次 300/782: 損失=0.7809, 準確率=80.55%
   批次 350/782: 損失=0.7822, 準確率=80.38%
   批次 400/782: 損失=0.7849, 準確率=80.25%
   批次 450/782: 損失=0.7858, 準確率=80.32%
   批次 500/782: 損失=0.7874, 準確率=80.39%
   批次 550/782: 損失=0.7894, 準確率=80.25%
   批次 600/782: 損失=0.7899, 準確率=80.23%
   批次 650/782: 損失=0.7908, 準確率=80.21%
   批次 700/782: 損失=0.7894, 準確率=80.26%
   批次 750/782: 損失=0.7890, 準確率=80.26%
   批次 782/782: 損失=0.7905, 準確率=80.24%
Epoch 20 完成: 訓練=80.24%, 驗證=76.98%, 時間=91.0s
   💾 新最佳模型已保存: 驗證準確率 76.98%

Epoch 21/50, LR: 0.001967
   批次  50/782: 損失=0.7406, 準確率=81.94%
   批次 100/782: 損失=0.7607, 準確率=80.80%
   批次 150/782: 損失=0.7607, 準確率=81.14%
   批次 200/782: 損失=0.7577, 準確率=81.36%
   批次 250/782: 損失=0.7620, 準確率=81.28%
   批次 300/782: 損失=0.7668, 準確率=80.97%
   批次 350/782: 損失=0.7685, 準確率=80.95%
   批次 400/782: 損失=0.7686, 準確率=80.93%
   批次 450/782: 損失=0.7692, 準確率=80.90%
   批次 500/782: 損失=0.7701, 準確率=80.86%
   批次 550/782: 損失=0.7724, 準確率=80.72%
   批次 600/782: 損失=0.7724, 準確率=80.70%
   批次 650/782: 損失=0.7739, 準確率=80.65%
   批次 700/782: 損失=0.7744, 準確率=80.64%
   批次 750/782: 損失=0.7743, 準確率=80.64%
   批次 782/782: 損失=0.7752, 準確率=80.56%
Epoch 21 完成: 訓練=80.56%, 驗證=76.89%, 時間=93.3s

Epoch 22/50, LR: 0.001877
   批次  50/782: 損失=0.7453, 準確率=82.44%
   批次 100/782: 損失=0.7466, 準確率=81.98%
   批次 150/782: 損失=0.7488, 準確率=82.00%
   批次 200/782: 損失=0.7492, 準確率=81.84%
   批次 250/782: 損失=0.7587, 準確率=81.43%
   批次 300/782: 損失=0.7625, 準確率=81.25%
   批次 350/782: 損失=0.7622, 準確率=81.26%
   批次 400/782: 損失=0.7665, 準確率=81.14%
   批次 450/782: 損失=0.7685, 準確率=81.02%
   批次 500/782: 損失=0.7689, 準確率=81.01%
   批次 550/782: 損失=0.7708, 準確率=80.90%
   批次 600/782: 損失=0.7670, 準確率=81.06%
   批次 650/782: 損失=0.7686, 準確率=81.00%
   批次 700/782: 損失=0.7682, 準確率=80.98%
   批次 750/782: 損失=0.7676, 準確率=80.99%
   批次 782/782: 損失=0.7668, 準確率=81.02%
Epoch 22 完成: 訓練=81.02%, 驗證=77.08%, 時間=89.3s
   💾 新最佳模型已保存: 驗證準確率 77.08%

Epoch 23/50, LR: 0.001785
   批次  50/782: 損失=0.7468, 準確率=82.31%
   批次 100/782: 損失=0.7407, 準確率=82.36%
   批次 150/782: 損失=0.7462, 準確率=82.14%
   批次 200/782: 損失=0.7455, 準確率=81.92%
   批次 250/782: 損失=0.7436, 準確率=81.89%
   批次 300/782: 損失=0.7455, 準確率=81.88%
   批次 350/782: 損失=0.7472, 準確率=81.74%
   批次 400/782: 損失=0.7466, 準確率=81.79%
   批次 450/782: 損失=0.7434, 準確率=81.88%
   批次 500/782: 損失=0.7425, 準確率=81.86%
   批次 550/782: 損失=0.7451, 準確率=81.78%
   批次 600/782: 損失=0.7477, 準確率=81.67%
   批次 650/782: 損失=0.7501, 準確率=81.56%
   批次 700/782: 損失=0.7511, 準確率=81.54%
   批次 750/782: 損失=0.7502, 準確率=81.59%
   批次 782/782: 損失=0.7508, 準確率=81.56%
Epoch 23 完成: 訓練=81.56%, 驗證=77.27%, 時間=91.3s
   💾 新最佳模型已保存: 驗證準確率 77.27%

Epoch 24/50, LR: 0.001692
   批次  50/782: 損失=0.7275, 準確率=83.16%
   批次 100/782: 損失=0.7270, 準確率=83.12%
   批次 150/782: 損失=0.7378, 準確率=82.64%
   批次 200/782: 損失=0.7345, 準確率=82.56%
   批次 250/782: 損失=0.7345, 準確率=82.41%
   批次 300/782: 損失=0.7327, 準確率=82.38%
   批次 350/782: 損失=0.7362, 準確率=82.23%
   批次 400/782: 損失=0.7363, 準確率=82.18%
   批次 450/782: 損失=0.7398, 準確率=82.01%
   批次 500/782: 損失=0.7395, 準確率=82.08%
   批次 550/782: 損失=0.7389, 準確率=82.13%
   批次 600/782: 損失=0.7412, 準確率=82.08%
   批次 650/782: 損失=0.7410, 準確率=82.06%
   批次 700/782: 損失=0.7407, 準確率=82.05%
   批次 750/782: 損失=0.7403, 準確率=82.09%
   批次 782/782: 損失=0.7412, 準確率=82.07%
Epoch 24 完成: 訓練=82.07%, 驗證=77.32%, 時間=95.9s
   💾 新最佳模型已保存: 驗證準確率 77.32%

Epoch 25/50, LR: 0.001599
   批次  50/782: 損失=0.7291, 準確率=82.34%
   批次 100/782: 損失=0.7129, 準確率=83.06%
   批次 150/782: 損失=0.7119, 準確率=83.10%
   批次 200/782: 損失=0.7134, 準確率=83.20%
   批次 250/782: 損失=0.7242, 準確率=82.81%
   批次 300/782: 損失=0.7244, 準確率=82.77%
   批次 350/782: 損失=0.7266, 準確率=82.65%
   批次 400/782: 損失=0.7264, 準確率=82.63%
   批次 450/782: 損失=0.7259, 準確率=82.64%
   批次 500/782: 損失=0.7249, 準確率=82.70%
   批次 550/782: 損失=0.7250, 準確率=82.73%
   批次 600/782: 損失=0.7268, 準確率=82.60%
   批次 650/782: 損失=0.7274, 準確率=82.58%
   批次 700/782: 損失=0.7287, 準確率=82.52%
   批次 750/782: 損失=0.7288, 準確率=82.50%
   批次 782/782: 損失=0.7289, 準確率=82.49%
Epoch 25 完成: 訓練=82.49%, 驗證=77.97%, 時間=92.5s
   💾 新最佳模型已保存: 驗證準確率 77.97%

Epoch 26/50, LR: 0.001505
   批次  50/782: 損失=0.7070, 準確率=83.50%
   批次 100/782: 損失=0.7139, 準確率=83.11%
   批次 150/782: 損失=0.7113, 準確率=83.26%
   批次 200/782: 損失=0.7192, 準確率=83.08%
   批次 250/782: 損失=0.7223, 準確率=83.02%
   批次 300/782: 損失=0.7231, 準確率=82.81%
   批次 350/782: 損失=0.7256, 準確率=82.60%
   批次 400/782: 損失=0.7239, 準確率=82.70%
   批次 450/782: 損失=0.7206, 準確率=82.82%
   批次 500/782: 損失=0.7183, 準確率=82.89%
   批次 550/782: 損失=0.7180, 準確率=82.93%
   批次 600/782: 損失=0.7203, 準確率=82.85%
   批次 650/782: 損失=0.7202, 準確率=82.90%
   批次 700/782: 損失=0.7204, 準確率=82.86%
   批次 750/782: 損失=0.7207, 準確率=82.89%
   批次 782/782: 損失=0.7201, 準確率=82.88%
Epoch 26 完成: 訓練=82.88%, 驗證=78.23%, 時間=92.4s
   💾 新最佳模型已保存: 驗證準確率 78.23%

Epoch 27/50, LR: 0.001411
   批次  50/782: 損失=0.6757, 準確率=84.53%
   批次 100/782: 損失=0.6924, 準確率=84.02%
   批次 150/782: 損失=0.6977, 準確率=83.90%
   批次 200/782: 損失=0.6970, 準確率=83.79%
   批次 250/782: 損失=0.7037, 準確率=83.61%
   批次 300/782: 損失=0.7048, 準確率=83.56%
   批次 350/782: 損失=0.7042, 準確率=83.56%
   批次 400/782: 損失=0.7026, 準確率=83.71%
   批次 450/782: 損失=0.7024, 準確率=83.82%
   批次 500/782: 損失=0.7029, 準確率=83.76%
   批次 550/782: 損失=0.7016, 準確率=83.75%
   批次 600/782: 損失=0.7019, 準確率=83.69%
   批次 650/782: 損失=0.7024, 準確率=83.62%
   批次 700/782: 損失=0.7037, 準確率=83.61%
   批次 750/782: 損失=0.7049, 準確率=83.57%
   批次 782/782: 損失=0.7064, 準確率=83.51%
Epoch 27 完成: 訓練=83.51%, 驗證=77.93%, 時間=90.9s
   📊 訓練-驗證差異: 5.58%

Epoch 28/50, LR: 0.001318
   批次  50/782: 損失=0.6809, 準確率=85.12%
   批次 100/782: 損失=0.6966, 準確率=84.02%
   批次 150/782: 損失=0.6937, 準確率=84.12%
   批次 200/782: 損失=0.6947, 準確率=84.08%
   批次 250/782: 損失=0.6927, 準確率=84.13%
   批次 300/782: 損失=0.6938, 準確率=84.11%
   批次 350/782: 損失=0.6930, 準確率=84.07%
   批次 400/782: 損失=0.6926, 準確率=84.07%
   批次 450/782: 損失=0.6942, 準確率=83.98%
   批次 500/782: 損失=0.6931, 準確率=84.08%
   批次 550/782: 損失=0.6939, 準確率=83.99%
   批次 600/782: 損失=0.6964, 準確率=83.83%
   批次 650/782: 損失=0.6975, 準確率=83.79%
   批次 700/782: 損失=0.6982, 準確率=83.77%
   批次 750/782: 損失=0.6997, 準確率=83.67%
   批次 782/782: 損失=0.7000, 準確率=83.69%
Epoch 28 完成: 訓練=83.69%, 驗證=78.72%, 時間=91.1s
   💾 新最佳模型已保存: 驗證準確率 78.72%

Epoch 29/50, LR: 0.001225
   批次  50/782: 損失=0.6781, 準確率=84.88%
   批次 100/782: 損失=0.6816, 準確率=84.56%
   批次 150/782: 損失=0.6830, 準確率=84.32%
   批次 200/782: 損失=0.6847, 準確率=84.22%
   批次 250/782: 損失=0.6837, 準確率=84.21%
   批次 300/782: 損失=0.6842, 準確率=84.18%
   批次 350/782: 損失=0.6824, 準確率=84.31%
   批次 400/782: 損失=0.6817, 準確率=84.37%
   批次 450/782: 損失=0.6810, 準確率=84.42%
   批次 500/782: 損失=0.6817, 準確率=84.42%
   批次 550/782: 損失=0.6845, 準確率=84.30%
   批次 600/782: 損失=0.6856, 準確率=84.27%
   批次 650/782: 損失=0.6878, 準確率=84.16%
   批次 700/782: 損失=0.6885, 準確率=84.13%
   批次 750/782: 損失=0.6883, 準確率=84.15%
   批次 782/782: 損失=0.6876, 準確率=84.19%
Epoch 29 完成: 訓練=84.19%, 驗證=78.42%, 時間=92.8s
   📊 訓練-驗證差異: 5.77%

Epoch 30/50, LR: 0.001133
   批次  50/782: 損失=0.6508, 準確率=85.78%
   批次 100/782: 損失=0.6612, 準確率=85.03%
   批次 150/782: 損失=0.6687, 準確率=84.67%
   批次 200/782: 損失=0.6702, 準確率=84.73%
   批次 250/782: 損失=0.6703, 準確率=84.74%
   批次 300/782: 損失=0.6704, 準確率=84.72%
   批次 350/782: 損失=0.6699, 準確率=84.87%
   批次 400/782: 損失=0.6697, 準確率=84.84%
   批次 450/782: 損失=0.6709, 準確率=84.79%
   批次 500/782: 損失=0.6701, 準確率=84.84%
   批次 550/782: 損失=0.6710, 準確率=84.80%
   批次 600/782: 損失=0.6707, 準確率=84.84%
   批次 650/782: 損失=0.6729, 準確率=84.73%
   批次 700/782: 損失=0.6743, 準確率=84.69%
   批次 750/782: 損失=0.6751, 準確率=84.70%
   批次 782/782: 損失=0.6756, 準確率=84.69%
Epoch 30 完成: 訓練=84.69%, 驗證=78.66%, 時間=88.2s
   📊 訓練-驗證差異: 6.03%

Epoch 31/50, LR: 0.001043
   批次  50/782: 損失=0.6583, 準確率=85.34%
   批次 100/782: 損失=0.6518, 準確率=85.97%
   批次 150/782: 損失=0.6567, 準確率=85.52%
   批次 200/782: 損失=0.6530, 準確率=85.68%
   批次 250/782: 損失=0.6519, 準確率=85.83%
   批次 300/782: 損失=0.6524, 準確率=85.89%
   批次 350/782: 損失=0.6549, 準確率=85.76%
   批次 400/782: 損失=0.6559, 準確率=85.69%
   批次 450/782: 損失=0.6569, 準確率=85.67%
   批次 500/782: 損失=0.6597, 準確率=85.54%
   批次 550/782: 損失=0.6599, 準確率=85.49%
   批次 600/782: 損失=0.6613, 準確率=85.43%
   批次 650/782: 損失=0.6623, 準確率=85.38%
   批次 700/782: 損失=0.6643, 準確率=85.28%
   批次 750/782: 損失=0.6661, 準確率=85.19%
   批次 782/782: 損失=0.6666, 準確率=85.19%
Epoch 31 完成: 訓練=85.19%, 驗證=78.80%, 時間=89.1s
   📊 訓練-驗證差異: 6.39%
   💾 新最佳模型已保存: 驗證準確率 78.80%

Epoch 32/50, LR: 0.000955
   批次  50/782: 損失=0.6452, 準確率=86.66%
   批次 100/782: 損失=0.6522, 準確率=85.91%
   批次 150/782: 損失=0.6519, 準確率=85.91%
   批次 200/782: 損失=0.6522, 準確率=85.98%
   批次 250/782: 損失=0.6501, 準確率=86.05%
   批次 300/782: 損失=0.6513, 準確率=85.93%
   批次 350/782: 損失=0.6511, 準確率=85.92%
   批次 400/782: 損失=0.6517, 準確率=85.91%
   批次 450/782: 損失=0.6512, 準確率=85.95%
   批次 500/782: 損失=0.6520, 準確率=85.85%
   批次 550/782: 損失=0.6527, 準確率=85.82%
   批次 600/782: 損失=0.6533, 準確率=85.77%
   批次 650/782: 損失=0.6533, 準確率=85.77%
   批次 700/782: 損失=0.6542, 準確率=85.73%
   批次 750/782: 損失=0.6539, 準確率=85.75%
   批次 782/782: 損失=0.6552, 準確率=85.69%
Epoch 32 完成: 訓練=85.69%, 驗證=78.54%, 時間=90.4s
   📊 訓練-驗證差異: 7.15%

Epoch 33/50, LR: 0.000868
   批次  50/782: 損失=0.6237, 準確率=86.69%
   批次 100/782: 損失=0.6332, 準確率=86.55%
   批次 150/782: 損失=0.6358, 準確率=86.12%
   批次 200/782: 損失=0.6428, 準確率=85.79%
   批次 250/782: 損失=0.6450, 準確率=85.83%
   批次 300/782: 損失=0.6471, 準確率=85.80%
   批次 350/782: 損失=0.6491, 準確率=85.70%
   批次 400/782: 損失=0.6472, 準確率=85.80%
   批次 450/782: 損失=0.6449, 準確率=85.89%
   批次 500/782: 損失=0.6453, 準確率=85.86%
   批次 550/782: 損失=0.6469, 準確率=85.80%
   批次 600/782: 損失=0.6476, 準確率=85.74%
   批次 650/782: 損失=0.6456, 準確率=85.83%
   批次 700/782: 損失=0.6461, 準確率=85.87%
   批次 750/782: 損失=0.6465, 準確率=85.85%
   批次 782/782: 損失=0.6456, 準確率=85.87%
Epoch 33 完成: 訓練=85.87%, 驗證=79.21%, 時間=89.1s
   📊 訓練-驗證差異: 6.66%
   💾 新最佳模型已保存: 驗證準確率 79.21%

Epoch 34/50, LR: 0.000785
   批次  50/782: 損失=0.6073, 準確率=87.59%
   批次 100/782: 損失=0.6167, 準確率=87.02%
   批次 150/782: 損失=0.6188, 準確率=87.14%
   批次 200/782: 損失=0.6235, 準確率=86.87%
   批次 250/782: 損失=0.6256, 準確率=86.88%
   批次 300/782: 損失=0.6313, 準確率=86.58%
   批次 350/782: 損失=0.6309, 準確率=86.62%
   批次 400/782: 損失=0.6317, 準確率=86.55%
   批次 450/782: 損失=0.6316, 準確率=86.50%
   批次 500/782: 損失=0.6330, 準確率=86.35%
   批次 550/782: 損失=0.6330, 準確率=86.35%
   批次 600/782: 損失=0.6346, 準確率=86.34%
   批次 650/782: 損失=0.6343, 準確率=86.34%
   批次 700/782: 損失=0.6346, 準確率=86.34%
   批次 750/782: 損失=0.6353, 準確率=86.37%
   批次 782/782: 損失=0.6357, 準確率=86.36%
Epoch 34 完成: 訓練=86.36%, 驗證=78.43%, 時間=91.1s
   📊 訓練-驗證差異: 7.93%

Epoch 35/50, LR: 0.000704
   批次  50/782: 損失=0.6236, 準確率=86.69%
   批次 100/782: 損失=0.6262, 準確率=86.69%
   批次 150/782: 損失=0.6229, 準確率=86.93%
   批次 200/782: 損失=0.6192, 準確率=86.93%
   批次 250/782: 損失=0.6170, 準確率=87.12%
   批次 300/782: 損失=0.6161, 準確率=87.12%
   批次 350/782: 損失=0.6204, 準確率=86.90%
   批次 400/782: 損失=0.6231, 準確率=86.86%
   批次 450/782: 損失=0.6228, 準確率=86.90%
   批次 500/782: 損失=0.6247, 準確率=86.79%
   批次 550/782: 損失=0.6251, 準確率=86.76%
   批次 600/782: 損失=0.6252, 準確率=86.78%
   批次 650/782: 損失=0.6257, 準確率=86.79%
   批次 700/782: 損失=0.6276, 準確率=86.72%
   批次 750/782: 損失=0.6281, 準確率=86.71%
   批次 782/782: 損失=0.6286, 準確率=86.67%
Epoch 35 完成: 訓練=86.67%, 驗證=79.15%, 時間=89.0s
   📊 訓練-驗證差異: 7.52%

Epoch 36/50, LR: 0.000626
   批次  50/782: 損失=0.5885, 準確率=88.97%
   批次 100/782: 損失=0.6033, 準確率=87.94%
   批次 150/782: 損失=0.6142, 準確率=87.50%
   批次 200/782: 損失=0.6157, 準確率=87.41%
   批次 250/782: 損失=0.6154, 準確率=87.38%
   批次 300/782: 損失=0.6182, 準確率=87.37%
   批次 350/782: 損失=0.6167, 準確率=87.38%
   批次 400/782: 損失=0.6153, 準確率=87.39%
   批次 450/782: 損失=0.6151, 準確率=87.39%
   批次 500/782: 損失=0.6173, 準確率=87.28%
   批次 550/782: 損失=0.6167, 準確率=87.28%
   批次 600/782: 損失=0.6160, 準確率=87.30%
   批次 650/782: 損失=0.6171, 準確率=87.26%
   批次 700/782: 損失=0.6171, 準確率=87.29%
   批次 750/782: 損失=0.6182, 準確率=87.23%
   批次 782/782: 損失=0.6186, 準確率=87.24%
Epoch 36 完成: 訓練=87.24%, 驗證=79.00%, 時間=91.9s
   ⚠️  過擬合警告: 差異 8.24% > 閾值 8.0% (1/6)
   📊 訓練-驗證差異: 8.24%

Epoch 37/50, LR: 0.000552
   批次  50/782: 損失=0.5933, 準確率=88.16%
   批次 100/782: 損失=0.5928, 準確率=88.31%
   批次 150/782: 損失=0.5962, 準確率=88.16%
   批次 200/782: 損失=0.5986, 準確率=88.20%
   批次 250/782: 損失=0.5997, 準確率=88.13%
   批次 300/782: 損失=0.6031, 準確率=87.98%
   批次 350/782: 損失=0.6084, 準確率=87.72%
   批次 400/782: 損失=0.6113, 準確率=87.66%
   批次 450/782: 損失=0.6102, 準確率=87.62%
   批次 500/782: 損失=0.6081, 準確率=87.76%
   批次 550/782: 損失=0.6081, 準確率=87.73%
   批次 600/782: 損失=0.6063, 準確率=87.82%
   批次 650/782: 損失=0.6074, 準確率=87.74%
   批次 700/782: 損失=0.6089, 準確率=87.65%
   批次 750/782: 損失=0.6097, 準確率=87.61%
   批次 782/782: 損失=0.6101, 準確率=87.58%
Epoch 37 完成: 訓練=87.58%, 驗證=78.73%, 時間=88.2s
   ⚠️  過擬合警告: 差異 8.85% > 閾值 8.0% (2/6)
   📊 訓練-驗證差異: 8.85%

Epoch 38/50, LR: 0.000482
   批次  50/782: 損失=0.5752, 準確率=88.91%
   批次 100/782: 損失=0.5845, 準確率=88.92%
   批次 150/782: 損失=0.5892, 準確率=88.48%
   批次 200/782: 損失=0.5978, 準確率=87.95%
   批次 250/782: 損失=0.6016, 準確率=87.73%
   批次 300/782: 損失=0.6007, 準確率=87.85%
   批次 350/782: 損失=0.6001, 準確率=87.88%
   批次 400/782: 損失=0.6027, 準確率=87.70%
   批次 450/782: 損失=0.6023, 準確率=87.77%
   批次 500/782: 損失=0.6030, 準確率=87.74%
   批次 550/782: 損失=0.6032, 準確率=87.68%
   批次 600/782: 損失=0.6047, 準確率=87.64%
   批次 650/782: 損失=0.6046, 準確率=87.65%
   批次 700/782: 損失=0.6074, 準確率=87.52%
   批次 750/782: 損失=0.6065, 準確率=87.57%
   批次 782/782: 損失=0.6067, 準確率=87.58%
Epoch 38 完成: 訓練=87.58%, 驗證=79.07%, 時間=91.4s
   ⚠️  過擬合警告: 差異 8.51% > 閾值 8.0% (3/6)
   📊 訓練-驗證差異: 8.51%

Epoch 39/50, LR: 0.000415
   批次  50/782: 損失=0.5950, 準確率=88.62%
   批次 100/782: 損失=0.5833, 準確率=88.77%
   批次 150/782: 損失=0.5843, 準確率=88.68%
   批次 200/782: 損失=0.5920, 準確率=88.43%
   批次 250/782: 損失=0.5926, 準確率=88.34%
   批次 300/782: 損失=0.5944, 準確率=88.31%
   批次 350/782: 損失=0.5951, 準確率=88.35%
   批次 400/782: 損失=0.5956, 準確率=88.36%
   批次 450/782: 損失=0.5943, 準確率=88.38%
   批次 500/782: 損失=0.5943, 準確率=88.35%
   批次 550/782: 損失=0.5950, 準確率=88.29%
   批次 600/782: 損失=0.5950, 準確率=88.30%
   批次 650/782: 損失=0.5938, 準確率=88.36%
   批次 700/782: 損失=0.5945, 準確率=88.29%
   批次 750/782: 損失=0.5942, 準確率=88.29%
   批次 782/782: 損失=0.5946, 準確率=88.27%
Epoch 39 完成: 訓練=88.27%, 驗證=79.01%, 時間=88.4s
   ⚠️  過擬合警告: 差異 9.26% > 閾值 8.0% (4/6)
   📊 訓練-驗證差異: 9.26%

Epoch 40/50, LR: 0.000353
   批次  50/782: 損失=0.5882, 準確率=88.16%
   批次 100/782: 損失=0.5837, 準確率=88.45%
   批次 150/782: 損失=0.5858, 準確率=88.46%
   批次 200/782: 損失=0.5902, 準確率=88.40%
   批次 250/782: 損失=0.5920, 準確率=88.23%
   批次 300/782: 損失=0.5919, 準確率=88.28%
   批次 350/782: 損失=0.5919, 準確率=88.37%
   批次 400/782: 損失=0.5906, 準確率=88.46%
   批次 450/782: 損失=0.5902, 準確率=88.47%
   批次 500/782: 損失=0.5906, 準確率=88.42%
   批次 550/782: 損失=0.5898, 準確率=88.43%
   批次 600/782: 損失=0.5888, 準確率=88.54%
   批次 650/782: 損失=0.5890, 準確率=88.52%
   批次 700/782: 損失=0.5898, 準確率=88.48%
   批次 750/782: 損失=0.5889, 準確率=88.49%
   批次 782/782: 損失=0.5886, 準確率=88.52%
Epoch 40 完成: 訓練=88.52%, 驗證=78.84%, 時間=90.9s
   ⚠️  過擬合警告: 差異 9.68% > 閾值 8.0% (5/6)
   📊 訓練-驗證差異: 9.68%

Epoch 41/50, LR: 0.000296
   批次  50/782: 損失=0.5603, 準確率=89.75%
   批次 100/782: 損失=0.5635, 準確率=89.84%
   批次 150/782: 損失=0.5710, 準確率=89.52%
   批次 200/782: 損失=0.5725, 準確率=89.34%
   批次 250/782: 損失=0.5751, 準確率=89.29%
   批次 300/782: 損失=0.5771, 準確率=89.21%
   批次 350/782: 損失=0.5779, 準確率=89.19%
   批次 400/782: 損失=0.5798, 準確率=89.15%
   批次 450/782: 損失=0.5789, 準確率=89.18%
   批次 500/782: 損失=0.5805, 準確率=89.08%
   批次 550/782: 損失=0.5813, 準確率=89.03%
   批次 600/782: 損失=0.5816, 準確率=88.99%
   批次 650/782: 損失=0.5828, 準確率=88.96%
   批次 700/782: 損失=0.5833, 準確率=88.92%
   批次 750/782: 損失=0.5839, 準確率=88.86%
   批次 782/782: 損失=0.5836, 準確率=88.87%
Epoch 41 完成: 訓練=88.87%, 驗證=79.02%, 時間=90.1s
   ⚠️  過擬合警告: 差異 9.85% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
   批次 750/782: 損失=0.5839, 準確率=88.86%
   批次 782/782: 損失=0.5836, 準確率=88.87%
Epoch 41 完成: 訓練=88.87%, 驗證=79.02%, 時間=90.1s
   ⚠️  過擬合警告: 差異 9.85% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
   批次 782/782: 損失=0.5836, 準確率=88.87%
Epoch 41 完成: 訓練=88.87%, 驗證=79.02%, 時間=90.1s
   ⚠️  過擬合警告: 差異 9.85% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
   ⚠️  過擬合警告: 差異 9.85% > 閾值 8.0% (6/6)
   🛑 過擬合早停: 連續 6 epochs 訓練-驗證差異超過 8.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
⏱️ 超快速訓練時間統計:
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
   • 總訓練時間: 3722.7s (62.0min)
   • 實際訓練epochs: 41 / 50
   • 實際訓練epochs: 41 / 50
   • 平均每epoch: 90.8s
   • 最佳驗證準確率: 79.21%
   • 最佳驗證準確率: 79.21%
   • 早停原因: 過擬合檢測 (差異: 9.85%)
   • 已載入最佳模型權重

📈 繪製超快速訓練歷史...

📊 評估超縮小版模型...
   ✓ 整體準確率: 79.21%

🎉 超快速訓練完成!
   • 模型大小: Nano
   • 最終準確率: 79.21%
   • 總訓練時間: 62.0 分鐘
   • 平均每epoch: 90.8 秒