🚀 超縮小版 gMLP 圖像分類訓練開始
============================================================

📋 超縮小版 gMLP 模型架構比較:
======================================================================
模型       深度     維度       FFN倍數    參數(M)     
----------------------------------------------------------------------
Nano     6      64       2        0.3       
XS       8      80       3        0.8       
S        12     128      3        2.0       
M        16     160      4        4.5       
----------------------------------------------------------------------
🎯 建議:
   • Nano: 極速原型開發 (<1分鐘訓練)
   • XS: 快速實驗 (~2分鐘訓練)
   • S: 平衡性能與速度 (~5分鐘訓練)
   • M: 較好性能但稍慢 (~10分鐘訓練)
📦 加載超快速 CIFAR-10 數據集...
   🚀 超快速模式：小規模數據集訓練
   ✓ 訓練樣本: 8000
   ✓ 測試樣本: 2000
   ✓ Batch大小: 64

🏗️ 創建超縮小版 gMLP-XS 模型...
   ⚡ CPU模式：已設置4個線程
   ✓ 超縮小版 gMLP-XS 模型創建完成
   ✓ 設備: cpu
   ✓ 參數數量: 274,330 (0.27M)
   ✓ 目標參數: 0.8M
   ✓ 模型大小: 1.0 MB
   ✓ 架構: depth=8, dim=80, ff_mult=3

🏋️ 開始超快速訓練 (30 個 epochs)...
   🛡️  啟用過擬合早停保護

Epoch 1/30, LR: 0.003000
   批次 20/125: 損失=2.1548, 準確率=19.77%
   批次 40/125: 損失=2.0876, 準確率=21.68%
   批次 60/125: 損失=2.0236, 準確率=24.58%
   批次 80/125: 損失=1.9679, 準確率=27.48%
   批次 100/125: 損失=1.9329, 準確率=28.89%
   批次 120/125: 損失=1.9068, 準確率=30.18%
Epoch 1 完成: 訓練=30.55%, 驗證=38.30%, 時間=30.4s
   💾 新最佳模型已保存: 驗證準確率 38.30%

Epoch 2/30, LR: 0.002992
   批次 20/125: 損失=1.6444, 準確率=42.97%
   批次 40/125: 損失=1.6701, 準確率=41.72%
   批次 60/125: 損失=1.6668, 準確率=41.90%
   批次 80/125: 損失=1.6660, 準確率=41.91%
   批次 100/125: 損失=1.6529, 準確率=42.50%
   批次 120/125: 損失=1.6435, 準確率=42.92%
Epoch 2 完成: 訓練=42.76%, 驗證=45.00%, 時間=29.8s
   💾 新最佳模型已保存: 驗證準確率 45.00%

Epoch 3/30, LR: 0.002967
   批次 20/125: 損失=1.4766, 準確率=49.69%
   批次 40/125: 損失=1.5203, 準確率=47.81%
   批次 60/125: 損失=1.5414, 準確率=47.03%
   批次 80/125: 損失=1.5375, 準確率=47.30%
   批次 100/125: 損失=1.5421, 準確率=47.20%
   批次 120/125: 損失=1.5367, 準確率=47.38%
Epoch 3 完成: 訓練=47.46%, 驗證=48.15%, 時間=29.2s
   💾 新最佳模型已保存: 驗證準確率 48.15%

Epoch 4/30, LR: 0.002927
   批次 20/125: 損失=1.4812, 準確率=48.83%
   批次 40/125: 損失=1.4679, 準確率=49.30%
   批次 60/125: 損失=1.4632, 準確率=49.84%
   批次 80/125: 損失=1.4721, 準確率=49.88%
   批次 100/125: 損失=1.4755, 準確率=49.92%
   批次 120/125: 損失=1.4729, 準確率=50.01%
Epoch 4 完成: 訓練=50.09%, 驗證=51.95%, 時間=32.1s
   💾 新最佳模型已保存: 驗證準確率 51.95%

Epoch 5/30, LR: 0.002871
   批次 20/125: 損失=1.4429, 準確率=51.09%
   批次 40/125: 損失=1.4202, 準確率=51.91%
   批次 60/125: 損失=1.4175, 準確率=52.58%
   批次 80/125: 損失=1.4133, 準確率=52.99%
   批次 100/125: 損失=1.3986, 準確率=53.81%
   批次 120/125: 損失=1.4085, 準確率=53.65%
Epoch 5 完成: 訓練=53.79%, 驗證=53.20%, 時間=31.8s
   💾 新最佳模型已保存: 驗證準確率 53.20%

Epoch 6/30, LR: 0.002800
   批次 20/125: 損失=1.3137, 準確率=56.88%
   批次 40/125: 損失=1.3119, 準確率=57.15%
   批次 60/125: 損失=1.3188, 準確率=56.61%
   批次 80/125: 損失=1.3274, 準確率=56.84%
   批次 100/125: 損失=1.3309, 準確率=56.78%
   批次 120/125: 損失=1.3242, 準確率=57.23%
Epoch 6 完成: 訓練=57.10%, 驗證=56.90%, 時間=37.8s
   💾 新最佳模型已保存: 驗證準確率 56.90%

Epoch 7/30, LR: 0.002714
   批次 20/125: 損失=1.2253, 準確率=60.94%
   批次 40/125: 損失=1.2544, 準確率=59.61%
   批次 60/125: 損失=1.2712, 準確率=59.17%
   批次 80/125: 損失=1.2716, 準確率=59.30%
   批次 100/125: 損失=1.2638, 準確率=59.62%
   批次 120/125: 損失=1.2645, 準確率=59.51%
Epoch 7 完成: 訓練=59.56%, 驗證=58.95%, 時間=30.1s
   💾 新最佳模型已保存: 驗證準確率 58.95%

Epoch 8/30, LR: 0.002616
   批次 20/125: 損失=1.2075, 準確率=63.59%
   批次 40/125: 損失=1.2084, 準確率=62.77%
   批次 60/125: 損失=1.2025, 準確率=63.28%
   批次 80/125: 損失=1.2056, 準確率=63.03%
   批次 100/125: 損失=1.2052, 準確率=62.67%
   批次 120/125: 損失=1.2096, 準確率=62.25%
Epoch 8 完成: 訓練=62.27%, 驗證=58.20%, 時間=28.8s

Epoch 9/30, LR: 0.002505
   批次 20/125: 損失=1.1510, 準確率=63.91%
   批次 40/125: 損失=1.1549, 準確率=64.14%
   批次 60/125: 損失=1.1574, 準確率=63.96%
   批次 80/125: 損失=1.1708, 準確率=63.36%
   批次 100/125: 損失=1.1727, 準確率=63.33%
   批次 120/125: 損失=1.1683, 準確率=63.45%
Epoch 9 完成: 訓練=63.44%, 驗證=57.65%, 時間=29.5s
   📊 訓練-驗證差異: 5.79%

Epoch 10/30, LR: 0.002384
   批次 20/125: 損失=1.1389, 準確率=62.66%
   批次 40/125: 損失=1.1383, 準確率=63.71%
   批次 60/125: 損失=1.1205, 準確率=64.32%
   批次 80/125: 損失=1.1085, 準確率=64.86%
   批次 100/125: 損失=1.1122, 準確率=64.98%
   批次 120/125: 損失=1.1138, 準確率=65.17%
Epoch 10 完成: 訓練=65.25%, 驗證=59.05%, 時間=29.4s
   📊 訓練-驗證差異: 6.20%
   💾 新最佳模型已保存: 驗證準確率 59.05%

Epoch 11/30, LR: 0.002252
   批次 20/125: 損失=1.0626, 準確率=67.11%
   批次 40/125: 損失=1.0802, 準確率=67.19%
   批次 60/125: 損失=1.0711, 準確率=68.07%
   批次 80/125: 損失=1.0727, 準確率=68.20%
   批次 100/125: 損失=1.0814, 準確率=68.05%
   批次 120/125: 損失=1.0811, 準確率=68.03%
Epoch 11 完成: 訓練=68.14%, 驗證=60.30%, 時間=29.7s
   📊 訓練-驗證差異: 7.84%
   💾 新最佳模型已保存: 驗證準確率 60.30%

Epoch 12/30, LR: 0.002113
   批次 20/125: 損失=1.0364, 準確率=70.00%
   批次 40/125: 損失=1.0327, 準確率=69.88%
   批次 60/125: 損失=1.0255, 準確率=70.42%
   批次 80/125: 損失=1.0225, 準確率=70.39%
   批次 100/125: 損失=1.0367, 準確率=69.78%
   批次 120/125: 損失=1.0356, 準確率=69.91%
Epoch 12 完成: 訓練=70.05%, 驗證=61.45%, 時間=28.7s
   📊 訓練-驗證差異: 8.60%
   💾 新最佳模型已保存: 驗證準確率 61.45%

Epoch 13/30, LR: 0.001967
   批次 20/125: 損失=0.9407, 準確率=74.06%
   批次 40/125: 損失=0.9590, 準確率=73.16%
   批次 60/125: 損失=0.9628, 準確率=73.15%
   批次 80/125: 損失=0.9790, 準確率=72.27%
   批次 100/125: 損失=0.9794, 準確率=72.05%
   批次 120/125: 損失=0.9741, 準確率=72.29%
Epoch 13 完成: 訓練=72.30%, 驗證=61.20%, 時間=28.8s
   ⚠️  過擬合警告: 差異 11.10% > 閾值 10.0% (1/8)
   📊 訓練-驗證差異: 11.10%

Epoch 14/30, LR: 0.001816
   批次 20/125: 損失=0.9254, 準確率=74.53%
   批次 40/125: 損失=0.9406, 準確率=74.22%
   批次 60/125: 損失=0.9333, 準確率=74.32%
   批次 80/125: 損失=0.9251, 準確率=74.61%
   批次 100/125: 損失=0.9329, 準確率=74.00%
   批次 120/125: 損失=0.9316, 準確率=74.10%
Epoch 14 完成: 訓練=74.24%, 驗證=61.70%, 時間=27.9s
   ⚠️  過擬合警告: 差異 12.54% > 閾值 10.0% (2/8)
   📊 訓練-驗證差異: 12.54%
   💾 新最佳模型已保存: 驗證準確率 61.70%

Epoch 15/30, LR: 0.001661
   批次 20/125: 損失=0.8754, 準確率=77.27%
   批次 40/125: 損失=0.8740, 準確率=77.03%
   批次 60/125: 損失=0.8842, 準確率=76.77%
   批次 80/125: 損失=0.8891, 準確率=76.60%
   批次 100/125: 損失=0.8839, 準確率=76.92%
   批次 120/125: 損失=0.8912, 準確率=76.60%
Epoch 15 完成: 訓練=76.41%, 驗證=60.75%, 時間=29.0s
   ⚠️  過擬合警告: 差異 15.66% > 閾值 10.0% (3/8)
   📊 訓練-驗證差異: 15.66%

Epoch 16/30, LR: 0.001505
   批次 20/125: 損失=0.8444, 準確率=79.06%
   批次 40/125: 損失=0.8226, 準確率=79.10%
   批次 60/125: 損失=0.8349, 準確率=78.26%
   批次 80/125: 損失=0.8390, 準確率=77.85%
   批次 100/125: 損失=0.8344, 準確率=78.33%
   批次 120/125: 損失=0.8374, 準確率=78.18%
Epoch 16 完成: 訓練=78.05%, 驗證=61.60%, 時間=28.8s
   ⚠️  過擬合警告: 差異 16.45% > 閾值 10.0% (4/8)
   📊 訓練-驗證差異: 16.45%

Epoch 17/30, LR: 0.001349
   批次 20/125: 損失=0.8109, 準確率=80.00%
   批次 40/125: 損失=0.7901, 準確率=80.98%
   批次 60/125: 損失=0.7951, 準確率=80.42%
   批次 80/125: 損失=0.8005, 準確率=79.86%
   批次 100/125: 損失=0.7961, 準確率=80.16%
   批次 120/125: 損失=0.7999, 準確率=79.80%
Epoch 17 完成: 訓練=79.78%, 驗證=61.75%, 時間=29.8s
   ⚠️  過擬合警告: 差異 18.03% > 閾值 10.0% (5/8)
   📊 訓練-驗證差異: 18.03%
   💾 新最佳模型已保存: 驗證準確率 61.75%

Epoch 18/30, LR: 0.001194
   批次 20/125: 損失=0.7540, 準確率=80.62%
   批次 40/125: 損失=0.7297, 準確率=82.73%
   批次 60/125: 損失=0.7344, 準確率=82.53%
   批次 80/125: 損失=0.7367, 準確率=82.66%
   批次 100/125: 損失=0.7407, 準確率=82.67%
   批次 120/125: 損失=0.7489, 準確率=82.23%
Epoch 18 完成: 訓練=82.17%, 驗證=61.75%, 時間=31.7s
   ⚠️  過擬合警告: 差異 20.42% > 閾值 10.0% (6/8)
   📊 訓練-驗證差異: 20.42%

Epoch 19/30, LR: 0.001043
   批次 20/125: 損失=0.7122, 準確率=84.69%
   批次 40/125: 損失=0.7041, 準確率=84.88%
   批次 60/125: 損失=0.7047, 準確率=84.79%
   批次 80/125: 損失=0.7050, 準確率=84.84%
   批次 100/125: 損失=0.7091, 準確率=84.50%
   批次 120/125: 損失=0.7101, 準確率=84.38%
Epoch 19 完成: 訓練=84.29%, 驗證=61.95%, 時間=29.7s
   ⚠️  過擬合警告: 差異 22.34% > 閾值 10.0% (7/8)
   📊 訓練-驗證差異: 22.34%
   💾 新最佳模型已保存: 驗證準確率 61.95%

Epoch 20/30, LR: 0.000897
   批次 20/125: 損失=0.6493, 準確率=86.80%
   批次 40/125: 損失=0.6649, 準確率=86.25%
   批次 60/125: 損失=0.6641, 準確率=86.59%
   批次 80/125: 損失=0.6721, 準確率=86.31%
   批次 100/125: 損失=0.6751, 準確率=85.98%
   批次 120/125: 損失=0.6751, 準確率=86.03%
Epoch 20 完成: 訓練=86.03%, 驗證=62.10%, 時間=31.0s
   ⚠️  過擬合警告: 差異 23.93% > 閾值 10.0% (8/8)
   🛑 過擬合早停: 連續 8 epochs 訓練-驗證差異超過 10.0%

⏱️ 超快速訓練時間統計:
   • 總訓練時間: 604.4s (10.1min)
   • 實際訓練epochs: 20 / 30
   • 平均每epoch: 30.2s
   • 最佳驗證準確率: 61.95%
   • 早停原因: 過擬合檢測 (差異: 23.93%)
   • 已載入最佳模型權重

📈 繪製超快速訓練歷史...

📊 評估超縮小版模型...
   ✓ 整體準確率: 61.95%

🎉 超快速訓練完成!
   • 模型大小: XS
   • 最終準確率: 61.95%
   • 總訓練時間: 10.1 分鐘
   • 平均每epoch: 30.2 秒