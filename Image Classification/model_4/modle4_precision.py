<<<<<<< HEAD
"""
è¶…ç²¾æº–ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦
åŒ…å«æ··åˆç²¾åº¦è¨“ç·´ã€EMAã€é«˜ç´šæ•¸æ“šå¢å¼·å’Œè©³ç´°ç›£æ§
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset, RandomSampler
from torch.cuda.amp import GradScaler, autocast
from g_mlp_pytorch import gMLPVision
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
import random
from collections import defaultdict
import warnings

warnings.filterwarnings("ignore")


class EMA:
    """æŒ‡æ•¸ç§»å‹•å¹³å‡ (Exponential Moving Average)"""

    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}

        # åˆå§‹åŒ–shadowåƒæ•¸
        for name, param in model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (
                    1.0 - self.decay
                ) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}


class CutMix:
    """CutMix æ•¸æ“šå¢å¼·"""

    def __init__(self, alpha=1.0):
        self.alpha = alpha

    def __call__(self, batch):
        images, labels = batch
        batch_size = images.size(0)

        # ç”Ÿæˆéš¨æ©Ÿç´¢å¼•
        indices = torch.randperm(batch_size)
        shuffled_images = images[indices]
        shuffled_labels = labels[indices]

        # ç”Ÿæˆ lambda
        lam = np.random.beta(self.alpha, self.alpha)

        # ç”Ÿæˆéš¨æ©Ÿè£å‰ªå€åŸŸ
        W, H = images.size(2), images.size(3)
        cut_rat = np.sqrt(1.0 - lam)
        cut_w = int(W * cut_rat)
        cut_h = int(H * cut_rat)

        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)

        # æ‡‰ç”¨ CutMix
        images[:, :, bbx1:bbx2, bby1:bby2] = shuffled_images[:, :, bbx1:bbx2, bby1:bby2]

        # èª¿æ•´ lambda
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))

        return images, labels, shuffled_labels, lam


def set_seed(seed=42):
    """è¨­å®šéš¨æ©Ÿç¨®å­ç¢ºä¿çµæœå¯é‡ç¾"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def load_cifar10_data_precision():
    """åŠ è¼‰è¶…ç²¾æº–çš„ CIFAR-10 æ•¸æ“šé›†"""
    print("ğŸ“¦ åŠ è¼‰è¶…ç²¾æº–çš„ CIFAR-10 æ•¸æ“šé›†...")

    # æ›´ç²¾ç´°çš„æ•¸æ“šå¢å¼·ç­–ç•¥
    transform_train = transforms.Compose(
        [
            transforms.RandomCrop(32, padding=4, padding_mode="reflect"),  # åå°„å¡«å……
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=15, fill=0),
            transforms.ColorJitter(
                brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1
            ),
            transforms.RandomApply(
                [transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.3
            ),
            transforms.RandomApply(
                [transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))], p=0.3
            ),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
            transforms.RandomErasing(p=0.25, scale=(0.02, 0.20), ratio=(0.3, 3.3)),
        ]
    )

    # æ¸¬è©¦æ™‚å¢å¼· (TTAæº–å‚™)
    transform_test = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    # è¼‰å…¥å®Œæ•´æ•¸æ“šé›†
    trainset = torchvision.datasets.CIFAR10(
        root="./data", train=True, download=True, transform=transform_train
    )
    testset = torchvision.datasets.CIFAR10(
        root="./data", train=False, download=True, transform=transform_test
    )

    # ä½¿ç”¨æ›´å¤šè¨“ç·´æ•¸æ“šä»¥æé«˜ç²¾åº¦
    train_size = 40000  # ä½¿ç”¨80%çš„è¨“ç·´æ•¸æ“š
    val_size = 10000  # ä½¿ç”¨20%ä½œç‚ºé©—è­‰é›†

    # åˆ†å±¤æ¡æ¨£ç¢ºä¿é¡åˆ¥å¹³è¡¡
    train_indices = []
    val_indices = []

    class_counts = defaultdict(list)
    for idx, (_, label) in enumerate(trainset):
        class_counts[label].append(idx)

    for class_idx, indices in class_counts.items():
        np.random.shuffle(indices)
        train_split = int(0.8 * len(indices))
        train_indices.extend(indices[:train_split])
        val_indices.extend(indices[train_split:])

    trainset = Subset(trainset, train_indices)
    valset = Subset(
        torchvision.datasets.CIFAR10(
            root="./data", train=True, download=False, transform=transform_test
        ),
        val_indices,
    )

    # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
    trainloader = DataLoader(
        trainset,
        batch_size=128,
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True,
    )
    valloader = DataLoader(
        valset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True
    )
    testloader = DataLoader(
        testset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True
    )

    classes = [
        "Airplane",
        "Automobile",
        "Bird",
        "Cat",
        "Deer",
        "Dog",
        "Frog",
        "Horse",
        "Ship",
        "Truck",
    ]

    print(f"   âœ“ è¨“ç·´æ¨£æœ¬: {len(trainset):,}")
    print(f"   âœ“ é©—è­‰æ¨£æœ¬: {len(valset):,}")
    print(f"   âœ“ æ¸¬è©¦æ¨£æœ¬: {len(testset):,}")
    print(f"   âœ“ é¡åˆ¥æ•¸: {len(classes)}")

    return trainloader, valloader, testloader, classes


def create_precision_gmlp_model():
    """å‰µå»ºè¶…ç²¾æº–çš„ gMLP æ¨¡å‹"""
    print("\nğŸ—ï¸ å‰µå»ºè¶…ç²¾æº–çš„ gMLP æ¨¡å‹...")

    model = gMLPVision(
        # === æ ¸å¿ƒæ¶æ§‹åƒæ•¸ ===
        image_size=32,  # åœ–åƒå°ºå¯¸
        patch_size=4,  # è£œä¸å¤§å°ï¼šæ›´å°çš„patchæé«˜ç´°ç¯€æ•æ‰
        num_classes=10,  # åˆ†é¡æ•¸é‡
        dim=512,  # å¢åŠ ç‰¹å¾µç¶­åº¦ä»¥æé«˜è¡¨é”èƒ½åŠ›
        depth=12,  # å¢åŠ æ·±åº¦ä»¥æé«˜æ¨¡å‹å®¹é‡
        # === ç¶²çµ¡çµæ§‹åƒæ•¸ ===
        ff_mult=4,  # å‰é¥‹å€æ•¸
        channels=3,  # è¼¸å…¥é€šé“
        attn_dim=None,  # æ³¨æ„åŠ›ç¶­åº¦
        # === æ­£å‰‡åŒ–åƒæ•¸ ===
        dropout=0.15,  # é©åº¦å¢åŠ dropout
        prob_survival=0.85,  # éš¨æ©Ÿæ·±åº¦ï¼šæ›´aggressiveçš„stochastic depth
        # === ç‰¹æ®ŠåŠŸèƒ½åƒæ•¸ ===
        causal=False,  # å› æœé®ç½©
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # æ¬Šé‡åˆå§‹åŒ–
    def init_weights(m):
        if isinstance(m, nn.Linear):
            torch.nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                torch.nn.init.zeros_(m.bias)
        elif isinstance(m, nn.LayerNorm):
            torch.nn.init.ones_(m.weight)
            torch.nn.init.zeros_(m.bias)

    model.apply(init_weights)

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"   âœ“ è¶…ç²¾æº–æ¨¡å‹å‰µå»ºå®Œæˆ")
    print(f"   âœ“ è¨­å‚™: {device}")
    print(f"   âœ“ ç¸½åƒæ•¸æ•¸é‡: {total_params:,}")
    print(f"   âœ“ å¯è¨“ç·´åƒæ•¸: {trainable_params:,}")
    print(f"   âœ“ æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.1f} MB")

    return model, device


def train_precision_model(model, trainloader, valloader, device, epochs=50):
    """è¶…ç²¾æº–è¨“ç·´æµç¨‹"""
    print(f"\nğŸ‹ï¸ é–‹å§‹è¶…ç²¾æº–è¨“ç·´ ({epochs} å€‹ epochs)...")

    # è¨­å®šæ··åˆç²¾åº¦è¨“ç·´
    scaler = GradScaler()

    # æå¤±å‡½æ•¸ï¼šä½¿ç”¨æ¨™ç±¤å¹³æ»‘
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # å„ªåŒ–å™¨ï¼šä½¿ç”¨AdamW + æ¬Šé‡è¡°æ¸›
    optimizer = optim.AdamW(
        model.parameters(), lr=0.001, weight_decay=0.05, betas=(0.9, 0.999), eps=1e-8
    )

    # å­¸ç¿’ç‡èª¿åº¦å™¨ï¼šé¤˜å¼¦é€€ç« + é ç†±
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=10,  # ç¬¬ä¸€æ¬¡é‡å•Ÿçš„é€±æœŸ
        T_mult=2,  # æ¯æ¬¡é‡å•Ÿå¾Œé€±æœŸçš„å€æ•¸
        eta_min=1e-6,  # æœ€å°å­¸ç¿’ç‡
    )

    # EMA
    ema = EMA(model, decay=0.9999)

    # CutMix
    cutmix = CutMix(alpha=1.0)

    # è¨“ç·´è¨˜éŒ„
    train_losses, train_accs = [], []
    val_losses, val_accs = [], []
    learning_rates = []
    epoch_times = []

    # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
    best_val_acc = 0
    patience = 15
    patience_counter = 0

    total_start_time = time.time()

    for epoch in range(epochs):
        epoch_start_time = time.time()
        current_lr = optimizer.param_groups[0]["lr"]
        learning_rates.append(current_lr)

        print(f"\nEpoch {epoch + 1}/{epochs}")
        print(f"Learning Rate: {current_lr:.8f}")

        # =============== è¨“ç·´éšæ®µ ===============
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for batch_idx, (inputs, targets) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)

            # éš¨æ©Ÿæ‡‰ç”¨ CutMix
            if np.random.rand() < 0.5:
                inputs, targets_a, targets_b, lam = cutmix((inputs, targets))
                cutmix_flag = True
            else:
                cutmix_flag = False

            optimizer.zero_grad()

            # æ··åˆç²¾åº¦å‰å‘å‚³æ’­
            with autocast():
                outputs = model(inputs)
                if cutmix_flag:
                    loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(
                        outputs, targets_b
                    )
                else:
                    loss = criterion(outputs, targets)

            # æ··åˆç²¾åº¦åå‘å‚³æ’­
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()

            # æ›´æ–° EMA
            ema.update()

            # çµ±è¨ˆ
            train_loss += loss.item()
            if not cutmix_flag:
                _, predicted = outputs.max(1)
                train_total += targets.size(0)
                train_correct += predicted.eq(targets).sum().item()

            if (batch_idx + 1) % 50 == 0:
                print(f"   Batch {batch_idx + 1:3d}: Loss = {loss.item():.4f}")

        # æ›´æ–°å­¸ç¿’ç‡
        scheduler.step()

        # è¨ˆç®—è¨“ç·´æŒ‡æ¨™
        avg_train_loss = train_loss / len(trainloader)
        train_acc = 100.0 * train_correct / train_total if train_total > 0 else 0

        train_losses.append(avg_train_loss)
        train_accs.append(train_acc)

        # =============== é©—è­‰éšæ®µ ===============
        val_loss, val_acc = validate_model(model, valloader, criterion, device)
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        # ä½¿ç”¨ EMA é€²è¡Œé©—è­‰
        ema.apply_shadow()
        ema_val_loss, ema_val_acc = validate_model(model, valloader, criterion, device)
        ema.restore()

        epoch_end_time = time.time()
        epoch_duration = epoch_end_time - epoch_start_time
        epoch_times.append(epoch_duration)

        print(f"Epoch {epoch + 1} Results:")
        print(f"   Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        print(f"   EMA Val Loss: {ema_val_loss:.4f}, EMA Val Acc: {ema_val_acc:.2f}%")
        print(f"   Time: {epoch_duration:.2f}s")

        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜ (ä½¿ç”¨EMAçµæœ)
        if ema_val_acc > best_val_acc:
            best_val_acc = ema_val_acc
            patience_counter = 0

            # ä¿å­˜æœ€ä½³æ¨¡å‹ (EMAç‰ˆæœ¬)
            ema.apply_shadow()
            torch.save(
                {
                    "epoch": epoch,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": optimizer.state_dict(),
                    "scheduler_state_dict": scheduler.state_dict(),
                    "best_val_acc": best_val_acc,
                    "ema_state_dict": ema.shadow,
                },
                "best_precision_model.pth",
            )
            ema.restore()

            print(f"   ğŸ’¾ New best model saved! EMA Val Acc: {best_val_acc:.2f}%")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"\nâ¹ï¸ Early stopping: No improvement for {patience} epochs")
                break

    total_end_time = time.time()
    total_training_time = total_end_time - total_start_time

    print(f"\nâ±ï¸ è¨“ç·´å®Œæˆçµ±è¨ˆ:")
    print(
        f"   â€¢ ç¸½è¨“ç·´æ™‚é–“: {total_training_time:.2f}s ({total_training_time/60:.2f}min)"
    )
    print(f"   â€¢ å¹³å‡æ¯epochæ™‚é–“: {np.mean(epoch_times):.2f}s")
    print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")

    # è¼‰å…¥æœ€ä½³æ¨¡å‹
    checkpoint = torch.load("best_precision_model.pth")
    model.load_state_dict(checkpoint["model_state_dict"])
    print("   â€¢ å·²è¼‰å…¥æœ€ä½³æ¨¡å‹æ¬Šé‡")

    return (
        train_losses,
        train_accs,
        val_losses,
        val_accs,
        learning_rates,
        epoch_times,
        total_training_time,
    )


def validate_model(model, dataloader, criterion, device):
    """é©—è­‰æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)

            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)

            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    avg_loss = total_loss / len(dataloader)
    accuracy = 100.0 * correct / total

    return avg_loss, accuracy


def test_time_augmentation(model, testloader, device, num_crops=5):
    """æ¸¬è©¦æ™‚å¢å¼· (TTA)"""
    print(f"\nğŸ”¬ åŸ·è¡Œæ¸¬è©¦æ™‚å¢å¼· (TTA) with {num_crops} crops...")

    model.eval()
    all_predictions = []
    all_labels = []

    # TTA transforms
    tta_transforms = transforms.Compose(
        [
            transforms.ToPILImage(),
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    with torch.no_grad():
        for inputs, targets in testloader:
            inputs, targets = inputs.to(device), targets.to(device)
            batch_size = inputs.size(0)

            # æ”¶é›†æ‰€æœ‰å¢å¼·é æ¸¬
            batch_predictions = []

            # åŸå§‹åœ–åƒ
            with autocast():
                outputs = model(inputs)
                batch_predictions.append(torch.softmax(outputs, dim=1))

            # TTAå¢å¼·
            for _ in range(num_crops):
                # å°æ¯å€‹æ¨£æœ¬æ‡‰ç”¨éš¨æ©Ÿå¢å¼·
                augmented_batch = []
                for i in range(batch_size):
                    # åæ¨™æº–åŒ–
                    img = inputs[i].cpu()
                    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)
                    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)
                    img = img * std + mean
                    img = torch.clamp(img, 0, 1)

                    # æ‡‰ç”¨TTAè®Šæ›
                    aug_img = tta_transforms(img)
                    augmented_batch.append(aug_img)

                augmented_batch = torch.stack(augmented_batch).to(device)

                with autocast():
                    outputs = model(augmented_batch)
                    batch_predictions.append(torch.softmax(outputs, dim=1))

            # å¹³å‡æ‰€æœ‰é æ¸¬
            avg_predictions = torch.stack(batch_predictions).mean(dim=0)
            _, predicted = avg_predictions.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(targets.cpu().numpy())

    accuracy = (
        100.0
        * np.sum(np.array(all_predictions) == np.array(all_labels))
        / len(all_labels)
    )
    print(f"   âœ“ TTA Accuracy: {accuracy:.2f}%")

    return accuracy, all_predictions, all_labels


def plot_precision_training_history(
    train_losses, train_accs, val_losses, val_accs, learning_rates, epoch_times
):
    """ç¹ªè£½è¶…ç²¾æº–è¨“ç·´æ­·å²"""
    print("\nğŸ“ˆ ç¹ªè£½è¶…ç²¾æº–è¨“ç·´æ­·å²...")

    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle("Precision gMLP Training History", fontsize=16, fontweight="bold")

    epochs = range(1, len(train_losses) + 1)

    # æå¤±æ›²ç·š
    axes[0, 0].plot(epochs, train_losses, "b-", linewidth=2, label="Training Loss")
    axes[0, 0].plot(epochs, val_losses, "r-", linewidth=2, label="Validation Loss")
    axes[0, 0].set_title("Loss Curves", fontweight="bold")
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Loss")
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # æº–ç¢ºç‡æ›²ç·š
    axes[0, 1].plot(epochs, train_accs, "g-", linewidth=2, label="Training Accuracy")
    axes[0, 1].plot(
        epochs, val_accs, "orange", linewidth=2, label="Validation Accuracy"
    )
    axes[0, 1].set_title("Accuracy Curves", fontweight="bold")
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Accuracy (%)")
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # å­¸ç¿’ç‡æ›²ç·š
    axes[0, 2].plot(epochs, learning_rates, "purple", linewidth=2)
    axes[0, 2].set_title("Learning Rate Schedule", fontweight="bold")
    axes[0, 2].set_xlabel("Epoch")
    axes[0, 2].set_ylabel("Learning Rate")
    axes[0, 2].set_yscale("log")
    axes[0, 2].grid(True, alpha=0.3)

    # éæ“¬åˆç›£æ§
    if len(train_accs) > 0 and len(val_accs) > 0:
        overfitting = np.array(train_accs) - np.array(val_accs)
        axes[1, 0].plot(epochs, overfitting, "red", linewidth=2)
        axes[1, 0].axhline(y=0, color="black", linestyle="--", alpha=0.5)
        axes[1, 0].set_title("Overfitting Monitor", fontweight="bold")
        axes[1, 0].set_xlabel("Epoch")
        axes[1, 0].set_ylabel("Train - Val Accuracy (%)")
        axes[1, 0].grid(True, alpha=0.3)

    # æ¯epochæ™‚é–“
    axes[1, 1].plot(epochs, epoch_times, "brown", linewidth=2, marker="o", markersize=4)
    axes[1, 1].set_title("Training Time per Epoch", fontweight="bold")
    axes[1, 1].set_xlabel("Epoch")
    axes[1, 1].set_ylabel("Time (seconds)")
    axes[1, 1].grid(True, alpha=0.3)

    # è¨“ç·´ç©©å®šæ€§åˆ†æ
    if len(val_accs) >= 10:
        window_size = min(5, len(val_accs) // 2)
        val_acc_smooth = np.convolve(
            val_accs, np.ones(window_size) / window_size, mode="valid"
        )
        smooth_epochs = range(window_size, len(val_accs) + 1)
        axes[1, 2].plot(epochs, val_accs, "lightblue", alpha=0.7, label="Raw")
        axes[1, 2].plot(
            smooth_epochs, val_acc_smooth, "darkblue", linewidth=2, label="Smoothed"
        )
        axes[1, 2].set_title("Validation Accuracy Stability", fontweight="bold")
        axes[1, 2].set_xlabel("Epoch")
        axes[1, 2].set_ylabel("Validation Accuracy (%)")
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("precision_gmlp_training_history.png", dpi=300, bbox_inches="tight")
    plt.show()


def evaluate_precision_model(model, testloader, device, classes):
    """è¶…ç²¾æº–æ¨¡å‹è©•ä¼°"""
    print("\nğŸ“Š åŸ·è¡Œè¶…ç²¾æº–æ¨¡å‹è©•ä¼°...")

    model.eval()
    all_predictions = []
    all_labels = []
    all_probabilities = []
    correct = 0
    total = 0
    class_correct = [0] * len(classes)
    class_total = [0] * len(classes)

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)

            with autocast():
                outputs = model(inputs)
                probabilities = torch.softmax(outputs, dim=1)

            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())

            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            # æ¯é¡åˆ¥çµ±è¨ˆ
            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += (predicted[i] == label).item()
                class_total[label] += 1

    overall_acc = 100.0 * correct / total

    # TTAè©•ä¼°
    tta_acc, tta_predictions, _ = test_time_augmentation(
        model, testloader, device, num_crops=3
    )

    print(f"\nğŸ“ˆ è©•ä¼°çµæœ:")
    print(f"   â€¢ æ¨™æº–æ¸¬è©¦æº–ç¢ºç‡: {overall_acc:.3f}%")
    print(f"   â€¢ TTAæ¸¬è©¦æº–ç¢ºç‡: {tta_acc:.3f}%")
    print(f"   â€¢ TTAæå‡: {tta_acc - overall_acc:.3f}%")

    # è©³ç´°å¯è¦–åŒ–
    plot_precision_evaluation(
        all_labels,
        all_predictions,
        tta_predictions,
        all_probabilities,
        classes,
        overall_acc,
        tta_acc,
    )

    return overall_acc, tta_acc


def plot_precision_evaluation(
    labels, predictions, tta_predictions, probabilities, classes, standard_acc, tta_acc
):
    """è¶…ç²¾æº–è©•ä¼°å¯è¦–åŒ–"""
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle("Precision gMLP Evaluation Results", fontsize=16, fontweight="bold")

    # 1. é¡åˆ¥æº–ç¢ºç‡æ¯”è¼ƒ
    class_accs_std = []
    class_accs_tta = []

    for i in range(len(classes)):
        class_mask = np.array(labels) == i
        if np.sum(class_mask) > 0:
            std_acc = (
                100.0
                * np.sum(np.array(predictions)[class_mask] == i)
                / np.sum(class_mask)
            )
            tta_acc_class = (
                100.0
                * np.sum(np.array(tta_predictions)[class_mask] == i)
                / np.sum(class_mask)
            )
            class_accs_std.append(std_acc)
            class_accs_tta.append(tta_acc_class)
        else:
            class_accs_std.append(0)
            class_accs_tta.append(0)

    x = np.arange(len(classes))
    width = 0.35

    axes[0, 0].bar(x - width / 2, class_accs_std, width, label="Standard", alpha=0.8)
    axes[0, 0].bar(x + width / 2, class_accs_tta, width, label="TTA", alpha=0.8)
    axes[0, 0].set_title("Class-wise Accuracy Comparison")
    axes[0, 0].set_ylabel("Accuracy (%)")
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(classes, rotation=45)
    axes[0, 0].legend()
    axes[0, 0].grid(axis="y", alpha=0.3)

    # 2. æ··æ·†çŸ©é™£ (æ¨™æº–)
    cm_std = confusion_matrix(labels, predictions)
    sns.heatmap(
        cm_std,
        annot=True,
        fmt="d",
        cmap="Blues",
        xticklabels=classes,
        yticklabels=classes,
        ax=axes[0, 1],
    )
    axes[0, 1].set_title(f"Standard Confusion Matrix (Acc: {standard_acc:.2f}%)")
    axes[0, 1].set_xlabel("Predicted")
    axes[0, 1].set_ylabel("True")

    # 3. æ··æ·†çŸ©é™£ (TTA)
    cm_tta = confusion_matrix(labels, tta_predictions)
    sns.heatmap(
        cm_tta,
        annot=True,
        fmt="d",
        cmap="Greens",
        xticklabels=classes,
        yticklabels=classes,
        ax=axes[0, 2],
    )
    axes[0, 2].set_title(f"TTA Confusion Matrix (Acc: {tta_acc:.2f}%)")
    axes[0, 2].set_xlabel("Predicted")
    axes[0, 2].set_ylabel("True")

    # 4. é æ¸¬ä¿¡å¿ƒåº¦åˆ†ä½ˆ
    max_probs = np.max(probabilities, axis=1)
    correct_mask = np.array(predictions) == np.array(labels)

    axes[1, 0].hist(
        max_probs[correct_mask], bins=50, alpha=0.7, label="Correct", density=True
    )
    axes[1, 0].hist(
        max_probs[~correct_mask], bins=50, alpha=0.7, label="Incorrect", density=True
    )
    axes[1, 0].set_title("Prediction Confidence Distribution")
    axes[1, 0].set_xlabel("Max Probability")
    axes[1, 0].set_ylabel("Density")
    axes[1, 0].legend()
    axes[1, 0].grid(alpha=0.3)

    # 5. æº–ç¢ºç‡ vs ä¿¡å¿ƒåº¦
    confidence_bins = np.linspace(0, 1, 21)
    bin_accs = []
    bin_counts = []

    for i in range(len(confidence_bins) - 1):
        mask = (max_probs >= confidence_bins[i]) & (max_probs < confidence_bins[i + 1])
        if np.sum(mask) > 0:
            bin_acc = np.mean(correct_mask[mask])
            bin_accs.append(bin_acc)
            bin_counts.append(np.sum(mask))
        else:
            bin_accs.append(0)
            bin_counts.append(0)

    bin_centers = (confidence_bins[:-1] + confidence_bins[1:]) / 2
    axes[1, 1].plot(bin_centers, bin_accs, "o-", linewidth=2, markersize=6)
    axes[1, 1].plot([0, 1], [0, 1], "r--", alpha=0.5, label="Perfect Calibration")
    axes[1, 1].set_title("Reliability Diagram")
    axes[1, 1].set_xlabel("Confidence")
    axes[1, 1].set_ylabel("Accuracy")
    axes[1, 1].legend()
    axes[1, 1].grid(alpha=0.3)

    # 6. æ”¹é€²åˆ†æ
    improvement = np.array(tta_predictions) == np.array(labels)
    standard_result = np.array(predictions) == np.array(labels)

    tta_better = improvement & (~standard_result)  # TTAå°ä½†æ¨™æº–éŒ¯
    tta_worse = (~improvement) & standard_result  # TTAéŒ¯ä½†æ¨™æº–å°
    both_correct = improvement & standard_result  # éƒ½å°
    both_wrong = (~improvement) & (~standard_result)  # éƒ½éŒ¯

    categories = ["Both Correct", "TTA Better", "TTA Worse", "Both Wrong"]
    counts = [
        np.sum(both_correct),
        np.sum(tta_better),
        np.sum(tta_worse),
        np.sum(both_wrong),
    ]
    colors = ["green", "blue", "orange", "red"]

    axes[1, 2].pie(counts, labels=categories, colors=colors, autopct="%1.1f%%")
    axes[1, 2].set_title("TTA vs Standard Comparison")

    plt.tight_layout()
    plt.savefig("precision_gmlp_evaluation.png", dpi=300, bbox_inches="tight")
    plt.show()


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ è¶…ç²¾æº– gMLP åœ–åƒåˆ†é¡æ¸¬è©¦")
    print("=" * 60)

    # è¨­å®šéš¨æ©Ÿç¨®å­
    set_seed(42)

    try:
        # 1. è¼‰å…¥è¶…ç²¾æº–æ•¸æ“š
        trainloader, valloader, testloader, classes = load_cifar10_data_precision()

        # 2. å‰µå»ºè¶…ç²¾æº–æ¨¡å‹
        model, device = create_precision_gmlp_model()

        # 3. è¶…ç²¾æº–è¨“ç·´
        (
            train_losses,
            train_accs,
            val_losses,
            val_accs,
            learning_rates,
            epoch_times,
            total_training_time,
        ) = train_precision_model(model, trainloader, valloader, device, epochs=50)

        # 4. ç¹ªè£½è¨“ç·´æ­·å²
        plot_precision_training_history(
            train_losses, train_accs, val_losses, val_accs, learning_rates, epoch_times
        )

        # 5. è¶…ç²¾æº–è©•ä¼°
        standard_acc, tta_acc = evaluate_precision_model(
            model, testloader, device, classes
        )

        # 6. æœ€çµ‚å ±å‘Š
        print(f"\nğŸŠ è¶…ç²¾æº–æ¸¬è©¦å®Œæˆï¼")
        print(f"=" * 60)
        print(f"ğŸ“Š æœ€çµ‚çµæœ:")
        print(f"   â€¢ æ¨™æº–æ¸¬è©¦æº–ç¢ºç‡: {standard_acc:.3f}%")
        print(f"   â€¢ TTAæ¸¬è©¦æº–ç¢ºç‡: {tta_acc:.3f}%")
        print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(val_accs):.3f}%")
        print(f"   â€¢ ç¸½è¨“ç·´æ™‚é–“: {total_training_time/60:.2f} åˆ†é˜")
        print(f"   â€¢ å¹³å‡æ¯epochæ™‚é–“: {np.mean(epoch_times):.2f} ç§’")

        # æ€§èƒ½è©•ç´š
        if tta_acc >= 90:
            grade = "ğŸ† å„ªç§€"
            comment = "æ¨¡å‹è¡¨ç¾å„ªç•°ï¼Œå¯ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒï¼"
        elif tta_acc >= 85:
            grade = "ğŸ¥‡ å„ªè‰¯"
            comment = "æ¨¡å‹è¡¨ç¾å¾ˆå¥½ï¼Œæ¥è¿‘SOTAæ°´æº–ï¼"
        elif tta_acc >= 80:
            grade = "ğŸ¥ˆ è‰¯å¥½"
            comment = "æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼Œé”åˆ°é æœŸç›®æ¨™ï¼"
        elif tta_acc >= 75:
            grade = "ğŸ¥‰ åŠæ ¼"
            comment = "æ¨¡å‹è¡¨ç¾å°šå¯ï¼Œé‚„æœ‰æ”¹é€²ç©ºé–“ã€‚"
        else:
            grade = "âŒ éœ€æ”¹é€²"
            comment = "æ¨¡å‹è¡¨ç¾ä¸ä½³ï¼Œéœ€è¦é‡æ–°èª¿æ•´ã€‚"

        print(f"\nğŸ¯ æ€§èƒ½è©•ç´š: {grade}")
        print(f"ğŸ’¬ è©•èª: {comment}")

        # æŠ€è¡“å»ºè­°
        print(f"\nğŸ”§ æŠ€è¡“åˆ†æ:")
        overfitting = train_accs[-1] - val_accs[-1] if train_accs and val_accs else 0
        if overfitting > 10:
            print(f"   âš ï¸  æª¢æ¸¬åˆ°éæ“¬åˆ (å·®ç•°: {overfitting:.2f}%)")
            print(f"      å»ºè­°: å¢åŠ æ­£å‰‡åŒ–æˆ–æ¸›å°‘æ¨¡å‹è¤‡é›œåº¦")
        elif overfitting > 5:
            print(f"   ğŸ”¶ è¼•å¾®éæ“¬åˆ (å·®ç•°: {overfitting:.2f}%)")
            print(f"      å»ºè­°: å¾®èª¿æ­£å‰‡åŒ–åƒæ•¸")
        else:
            print(f"   âœ… æ¨¡å‹æ³›åŒ–è‰¯å¥½ (å·®ç•°: {overfitting:.2f}%)")

        if tta_acc - standard_acc > 1:
            print(f"   ğŸ“ˆ TTAæ•ˆæœé¡¯è‘— (+{tta_acc - standard_acc:.2f}%)")
            print(f"      å»ºè­°: åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ä½¿ç”¨TTA")
        else:
            print(f"   ğŸ“Š TTAæ•ˆæœæœ‰é™ (+{tta_acc - standard_acc:.2f}%)")
            print(f"      å»ºè­°: è€ƒæ…®å…¶ä»–å¢å¼·ç­–ç•¥")

    except Exception as e:
        print(f"âŒ è¶…ç²¾æº–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
=======
"""
è¶…ç²¾æº–ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦
åŒ…å«æ··åˆç²¾åº¦è¨“ç·´ã€EMAã€é«˜ç´šæ•¸æ“šå¢å¼·å’Œè©³ç´°ç›£æ§
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset, RandomSampler
from torch.cuda.amp import GradScaler, autocast
from g_mlp_pytorch import gMLPVision
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
import random
from collections import defaultdict
import warnings

warnings.filterwarnings("ignore")


class EMA:
    """æŒ‡æ•¸ç§»å‹•å¹³å‡ (Exponential Moving Average)"""

    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}

        # åˆå§‹åŒ–shadowåƒæ•¸
        for name, param in model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (
                    1.0 - self.decay
                ) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}


class CutMix:
    """CutMix æ•¸æ“šå¢å¼·"""

    def __init__(self, alpha=1.0):
        self.alpha = alpha

    def __call__(self, batch):
        images, labels = batch
        batch_size = images.size(0)

        # ç”Ÿæˆéš¨æ©Ÿç´¢å¼•
        indices = torch.randperm(batch_size)
        shuffled_images = images[indices]
        shuffled_labels = labels[indices]

        # ç”Ÿæˆ lambda
        lam = np.random.beta(self.alpha, self.alpha)

        # ç”Ÿæˆéš¨æ©Ÿè£å‰ªå€åŸŸ
        W, H = images.size(2), images.size(3)
        cut_rat = np.sqrt(1.0 - lam)
        cut_w = int(W * cut_rat)
        cut_h = int(H * cut_rat)

        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)

        # æ‡‰ç”¨ CutMix
        images[:, :, bbx1:bbx2, bby1:bby2] = shuffled_images[:, :, bbx1:bbx2, bby1:bby2]

        # èª¿æ•´ lambda
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))

        return images, labels, shuffled_labels, lam


def set_seed(seed=42):
    """è¨­å®šéš¨æ©Ÿç¨®å­ç¢ºä¿çµæœå¯é‡ç¾"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def load_cifar10_data_precision():
    """åŠ è¼‰è¶…ç²¾æº–çš„ CIFAR-10 æ•¸æ“šé›†"""
    print("ğŸ“¦ åŠ è¼‰è¶…ç²¾æº–çš„ CIFAR-10 æ•¸æ“šé›†...")

    # æ›´ç²¾ç´°çš„æ•¸æ“šå¢å¼·ç­–ç•¥
    transform_train = transforms.Compose(
        [
            transforms.RandomCrop(32, padding=4, padding_mode="reflect"),  # åå°„å¡«å……
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=15, fill=0),
            transforms.ColorJitter(
                brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1
            ),
            transforms.RandomApply(
                [transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.3
            ),
            transforms.RandomApply(
                [transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))], p=0.3
            ),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
            transforms.RandomErasing(p=0.25, scale=(0.02, 0.20), ratio=(0.3, 3.3)),
        ]
    )

    # æ¸¬è©¦æ™‚å¢å¼· (TTAæº–å‚™)
    transform_test = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    # è¼‰å…¥å®Œæ•´æ•¸æ“šé›†
    trainset = torchvision.datasets.CIFAR10(
        root="./data", train=True, download=True, transform=transform_train
    )
    testset = torchvision.datasets.CIFAR10(
        root="./data", train=False, download=True, transform=transform_test
    )

    # ä½¿ç”¨æ›´å¤šè¨“ç·´æ•¸æ“šä»¥æé«˜ç²¾åº¦
    train_size = 40000  # ä½¿ç”¨80%çš„è¨“ç·´æ•¸æ“š
    val_size = 10000  # ä½¿ç”¨20%ä½œç‚ºé©—è­‰é›†

    # åˆ†å±¤æ¡æ¨£ç¢ºä¿é¡åˆ¥å¹³è¡¡
    train_indices = []
    val_indices = []

    class_counts = defaultdict(list)
    for idx, (_, label) in enumerate(trainset):
        class_counts[label].append(idx)

    for class_idx, indices in class_counts.items():
        np.random.shuffle(indices)
        train_split = int(0.8 * len(indices))
        train_indices.extend(indices[:train_split])
        val_indices.extend(indices[train_split:])

    trainset = Subset(trainset, train_indices)
    valset = Subset(
        torchvision.datasets.CIFAR10(
            root="./data", train=True, download=False, transform=transform_test
        ),
        val_indices,
    )

    # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
    trainloader = DataLoader(
        trainset,
        batch_size=128,
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True,
    )
    valloader = DataLoader(
        valset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True
    )
    testloader = DataLoader(
        testset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True
    )

    classes = [
        "Airplane",
        "Automobile",
        "Bird",
        "Cat",
        "Deer",
        "Dog",
        "Frog",
        "Horse",
        "Ship",
        "Truck",
    ]

    print(f"   âœ“ è¨“ç·´æ¨£æœ¬: {len(trainset):,}")
    print(f"   âœ“ é©—è­‰æ¨£æœ¬: {len(valset):,}")
    print(f"   âœ“ æ¸¬è©¦æ¨£æœ¬: {len(testset):,}")
    print(f"   âœ“ é¡åˆ¥æ•¸: {len(classes)}")

    return trainloader, valloader, testloader, classes


def create_precision_gmlp_model():
    """å‰µå»ºè¶…ç²¾æº–çš„ gMLP æ¨¡å‹"""
    print("\nğŸ—ï¸ å‰µå»ºè¶…ç²¾æº–çš„ gMLP æ¨¡å‹...")

    model = gMLPVision(
        # === æ ¸å¿ƒæ¶æ§‹åƒæ•¸ ===
        image_size=32,  # åœ–åƒå°ºå¯¸
        patch_size=4,  # è£œä¸å¤§å°ï¼šæ›´å°çš„patchæé«˜ç´°ç¯€æ•æ‰
        num_classes=10,  # åˆ†é¡æ•¸é‡
        dim=512,  # å¢åŠ ç‰¹å¾µç¶­åº¦ä»¥æé«˜è¡¨é”èƒ½åŠ›
        depth=12,  # å¢åŠ æ·±åº¦ä»¥æé«˜æ¨¡å‹å®¹é‡
        # === ç¶²çµ¡çµæ§‹åƒæ•¸ ===
        ff_mult=4,  # å‰é¥‹å€æ•¸
        channels=3,  # è¼¸å…¥é€šé“
        attn_dim=None,  # æ³¨æ„åŠ›ç¶­åº¦
        # === æ­£å‰‡åŒ–åƒæ•¸ ===
        dropout=0.15,  # é©åº¦å¢åŠ dropout
        prob_survival=0.85,  # éš¨æ©Ÿæ·±åº¦ï¼šæ›´aggressiveçš„stochastic depth
        # === ç‰¹æ®ŠåŠŸèƒ½åƒæ•¸ ===
        causal=False,  # å› æœé®ç½©
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # æ¬Šé‡åˆå§‹åŒ–
    def init_weights(m):
        if isinstance(m, nn.Linear):
            torch.nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                torch.nn.init.zeros_(m.bias)
        elif isinstance(m, nn.LayerNorm):
            torch.nn.init.ones_(m.weight)
            torch.nn.init.zeros_(m.bias)

    model.apply(init_weights)

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"   âœ“ è¶…ç²¾æº–æ¨¡å‹å‰µå»ºå®Œæˆ")
    print(f"   âœ“ è¨­å‚™: {device}")
    print(f"   âœ“ ç¸½åƒæ•¸æ•¸é‡: {total_params:,}")
    print(f"   âœ“ å¯è¨“ç·´åƒæ•¸: {trainable_params:,}")
    print(f"   âœ“ æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.1f} MB")

    return model, device


def train_precision_model(model, trainloader, valloader, device, epochs=50):
    """è¶…ç²¾æº–è¨“ç·´æµç¨‹"""
    print(f"\nğŸ‹ï¸ é–‹å§‹è¶…ç²¾æº–è¨“ç·´ ({epochs} å€‹ epochs)...")

    # è¨­å®šæ··åˆç²¾åº¦è¨“ç·´
    scaler = GradScaler()

    # æå¤±å‡½æ•¸ï¼šä½¿ç”¨æ¨™ç±¤å¹³æ»‘
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # å„ªåŒ–å™¨ï¼šä½¿ç”¨AdamW + æ¬Šé‡è¡°æ¸›
    optimizer = optim.AdamW(
        model.parameters(), lr=0.001, weight_decay=0.05, betas=(0.9, 0.999), eps=1e-8
    )

    # å­¸ç¿’ç‡èª¿åº¦å™¨ï¼šé¤˜å¼¦é€€ç« + é ç†±
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=10,  # ç¬¬ä¸€æ¬¡é‡å•Ÿçš„é€±æœŸ
        T_mult=2,  # æ¯æ¬¡é‡å•Ÿå¾Œé€±æœŸçš„å€æ•¸
        eta_min=1e-6,  # æœ€å°å­¸ç¿’ç‡
    )

    # EMA
    ema = EMA(model, decay=0.9999)

    # CutMix
    cutmix = CutMix(alpha=1.0)

    # è¨“ç·´è¨˜éŒ„
    train_losses, train_accs = [], []
    val_losses, val_accs = [], []
    learning_rates = []
    epoch_times = []

    # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
    best_val_acc = 0
    patience = 15
    patience_counter = 0

    total_start_time = time.time()

    for epoch in range(epochs):
        epoch_start_time = time.time()
        current_lr = optimizer.param_groups[0]["lr"]
        learning_rates.append(current_lr)

        print(f"\nEpoch {epoch + 1}/{epochs}")
        print(f"Learning Rate: {current_lr:.8f}")

        # =============== è¨“ç·´éšæ®µ ===============
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for batch_idx, (inputs, targets) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)

            # éš¨æ©Ÿæ‡‰ç”¨ CutMix
            if np.random.rand() < 0.5:
                inputs, targets_a, targets_b, lam = cutmix((inputs, targets))
                cutmix_flag = True
            else:
                cutmix_flag = False

            optimizer.zero_grad()

            # æ··åˆç²¾åº¦å‰å‘å‚³æ’­
            with autocast():
                outputs = model(inputs)
                if cutmix_flag:
                    loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(
                        outputs, targets_b
                    )
                else:
                    loss = criterion(outputs, targets)

            # æ··åˆç²¾åº¦åå‘å‚³æ’­
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()

            # æ›´æ–° EMA
            ema.update()

            # çµ±è¨ˆ
            train_loss += loss.item()
            if not cutmix_flag:
                _, predicted = outputs.max(1)
                train_total += targets.size(0)
                train_correct += predicted.eq(targets).sum().item()

            if (batch_idx + 1) % 50 == 0:
                print(f"   Batch {batch_idx + 1:3d}: Loss = {loss.item():.4f}")

        # æ›´æ–°å­¸ç¿’ç‡
        scheduler.step()

        # è¨ˆç®—è¨“ç·´æŒ‡æ¨™
        avg_train_loss = train_loss / len(trainloader)
        train_acc = 100.0 * train_correct / train_total if train_total > 0 else 0

        train_losses.append(avg_train_loss)
        train_accs.append(train_acc)

        # =============== é©—è­‰éšæ®µ ===============
        val_loss, val_acc = validate_model(model, valloader, criterion, device)
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        # ä½¿ç”¨ EMA é€²è¡Œé©—è­‰
        ema.apply_shadow()
        ema_val_loss, ema_val_acc = validate_model(model, valloader, criterion, device)
        ema.restore()

        epoch_end_time = time.time()
        epoch_duration = epoch_end_time - epoch_start_time
        epoch_times.append(epoch_duration)

        print(f"Epoch {epoch + 1} Results:")
        print(f"   Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        print(f"   EMA Val Loss: {ema_val_loss:.4f}, EMA Val Acc: {ema_val_acc:.2f}%")
        print(f"   Time: {epoch_duration:.2f}s")

        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜ (ä½¿ç”¨EMAçµæœ)
        if ema_val_acc > best_val_acc:
            best_val_acc = ema_val_acc
            patience_counter = 0

            # ä¿å­˜æœ€ä½³æ¨¡å‹ (EMAç‰ˆæœ¬)
            ema.apply_shadow()
            torch.save(
                {
                    "epoch": epoch,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": optimizer.state_dict(),
                    "scheduler_state_dict": scheduler.state_dict(),
                    "best_val_acc": best_val_acc,
                    "ema_state_dict": ema.shadow,
                },
                "best_precision_model.pth",
            )
            ema.restore()

            print(f"   ğŸ’¾ New best model saved! EMA Val Acc: {best_val_acc:.2f}%")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"\nâ¹ï¸ Early stopping: No improvement for {patience} epochs")
                break

    total_end_time = time.time()
    total_training_time = total_end_time - total_start_time

    print(f"\nâ±ï¸ è¨“ç·´å®Œæˆçµ±è¨ˆ:")
    print(
        f"   â€¢ ç¸½è¨“ç·´æ™‚é–“: {total_training_time:.2f}s ({total_training_time/60:.2f}min)"
    )
    print(f"   â€¢ å¹³å‡æ¯epochæ™‚é–“: {np.mean(epoch_times):.2f}s")
    print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")

    # è¼‰å…¥æœ€ä½³æ¨¡å‹
    checkpoint = torch.load("best_precision_model.pth")
    model.load_state_dict(checkpoint["model_state_dict"])
    print("   â€¢ å·²è¼‰å…¥æœ€ä½³æ¨¡å‹æ¬Šé‡")

    return (
        train_losses,
        train_accs,
        val_losses,
        val_accs,
        learning_rates,
        epoch_times,
        total_training_time,
    )


def validate_model(model, dataloader, criterion, device):
    """é©—è­‰æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)

            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)

            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    avg_loss = total_loss / len(dataloader)
    accuracy = 100.0 * correct / total

    return avg_loss, accuracy


def test_time_augmentation(model, testloader, device, num_crops=5):
    """æ¸¬è©¦æ™‚å¢å¼· (TTA)"""
    print(f"\nğŸ”¬ åŸ·è¡Œæ¸¬è©¦æ™‚å¢å¼· (TTA) with {num_crops} crops...")

    model.eval()
    all_predictions = []
    all_labels = []

    # TTA transforms
    tta_transforms = transforms.Compose(
        [
            transforms.ToPILImage(),
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    with torch.no_grad():
        for inputs, targets in testloader:
            inputs, targets = inputs.to(device), targets.to(device)
            batch_size = inputs.size(0)

            # æ”¶é›†æ‰€æœ‰å¢å¼·é æ¸¬
            batch_predictions = []

            # åŸå§‹åœ–åƒ
            with autocast():
                outputs = model(inputs)
                batch_predictions.append(torch.softmax(outputs, dim=1))

            # TTAå¢å¼·
            for _ in range(num_crops):
                # å°æ¯å€‹æ¨£æœ¬æ‡‰ç”¨éš¨æ©Ÿå¢å¼·
                augmented_batch = []
                for i in range(batch_size):
                    # åæ¨™æº–åŒ–
                    img = inputs[i].cpu()
                    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)
                    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)
                    img = img * std + mean
                    img = torch.clamp(img, 0, 1)

                    # æ‡‰ç”¨TTAè®Šæ›
                    aug_img = tta_transforms(img)
                    augmented_batch.append(aug_img)

                augmented_batch = torch.stack(augmented_batch).to(device)

                with autocast():
                    outputs = model(augmented_batch)
                    batch_predictions.append(torch.softmax(outputs, dim=1))

            # å¹³å‡æ‰€æœ‰é æ¸¬
            avg_predictions = torch.stack(batch_predictions).mean(dim=0)
            _, predicted = avg_predictions.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(targets.cpu().numpy())

    accuracy = (
        100.0
        * np.sum(np.array(all_predictions) == np.array(all_labels))
        / len(all_labels)
    )
    print(f"   âœ“ TTA Accuracy: {accuracy:.2f}%")

    return accuracy, all_predictions, all_labels


def plot_precision_training_history(
    train_losses, train_accs, val_losses, val_accs, learning_rates, epoch_times
):
    """ç¹ªè£½è¶…ç²¾æº–è¨“ç·´æ­·å²"""
    print("\nğŸ“ˆ ç¹ªè£½è¶…ç²¾æº–è¨“ç·´æ­·å²...")

    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle("Precision gMLP Training History", fontsize=16, fontweight="bold")

    epochs = range(1, len(train_losses) + 1)

    # æå¤±æ›²ç·š
    axes[0, 0].plot(epochs, train_losses, "b-", linewidth=2, label="Training Loss")
    axes[0, 0].plot(epochs, val_losses, "r-", linewidth=2, label="Validation Loss")
    axes[0, 0].set_title("Loss Curves", fontweight="bold")
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Loss")
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # æº–ç¢ºç‡æ›²ç·š
    axes[0, 1].plot(epochs, train_accs, "g-", linewidth=2, label="Training Accuracy")
    axes[0, 1].plot(
        epochs, val_accs, "orange", linewidth=2, label="Validation Accuracy"
    )
    axes[0, 1].set_title("Accuracy Curves", fontweight="bold")
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Accuracy (%)")
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # å­¸ç¿’ç‡æ›²ç·š
    axes[0, 2].plot(epochs, learning_rates, "purple", linewidth=2)
    axes[0, 2].set_title("Learning Rate Schedule", fontweight="bold")
    axes[0, 2].set_xlabel("Epoch")
    axes[0, 2].set_ylabel("Learning Rate")
    axes[0, 2].set_yscale("log")
    axes[0, 2].grid(True, alpha=0.3)

    # éæ“¬åˆç›£æ§
    if len(train_accs) > 0 and len(val_accs) > 0:
        overfitting = np.array(train_accs) - np.array(val_accs)
        axes[1, 0].plot(epochs, overfitting, "red", linewidth=2)
        axes[1, 0].axhline(y=0, color="black", linestyle="--", alpha=0.5)
        axes[1, 0].set_title("Overfitting Monitor", fontweight="bold")
        axes[1, 0].set_xlabel("Epoch")
        axes[1, 0].set_ylabel("Train - Val Accuracy (%)")
        axes[1, 0].grid(True, alpha=0.3)

    # æ¯epochæ™‚é–“
    axes[1, 1].plot(epochs, epoch_times, "brown", linewidth=2, marker="o", markersize=4)
    axes[1, 1].set_title("Training Time per Epoch", fontweight="bold")
    axes[1, 1].set_xlabel("Epoch")
    axes[1, 1].set_ylabel("Time (seconds)")
    axes[1, 1].grid(True, alpha=0.3)

    # è¨“ç·´ç©©å®šæ€§åˆ†æ
    if len(val_accs) >= 10:
        window_size = min(5, len(val_accs) // 2)
        val_acc_smooth = np.convolve(
            val_accs, np.ones(window_size) / window_size, mode="valid"
        )
        smooth_epochs = range(window_size, len(val_accs) + 1)
        axes[1, 2].plot(epochs, val_accs, "lightblue", alpha=0.7, label="Raw")
        axes[1, 2].plot(
            smooth_epochs, val_acc_smooth, "darkblue", linewidth=2, label="Smoothed"
        )
        axes[1, 2].set_title("Validation Accuracy Stability", fontweight="bold")
        axes[1, 2].set_xlabel("Epoch")
        axes[1, 2].set_ylabel("Validation Accuracy (%)")
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("precision_gmlp_training_history.png", dpi=300, bbox_inches="tight")
    plt.show()


def evaluate_precision_model(model, testloader, device, classes):
    """è¶…ç²¾æº–æ¨¡å‹è©•ä¼°"""
    print("\nğŸ“Š åŸ·è¡Œè¶…ç²¾æº–æ¨¡å‹è©•ä¼°...")

    model.eval()
    all_predictions = []
    all_labels = []
    all_probabilities = []
    correct = 0
    total = 0
    class_correct = [0] * len(classes)
    class_total = [0] * len(classes)

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)

            with autocast():
                outputs = model(inputs)
                probabilities = torch.softmax(outputs, dim=1)

            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())

            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            # æ¯é¡åˆ¥çµ±è¨ˆ
            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += (predicted[i] == label).item()
                class_total[label] += 1

    overall_acc = 100.0 * correct / total

    # TTAè©•ä¼°
    tta_acc, tta_predictions, _ = test_time_augmentation(
        model, testloader, device, num_crops=3
    )

    print(f"\nğŸ“ˆ è©•ä¼°çµæœ:")
    print(f"   â€¢ æ¨™æº–æ¸¬è©¦æº–ç¢ºç‡: {overall_acc:.3f}%")
    print(f"   â€¢ TTAæ¸¬è©¦æº–ç¢ºç‡: {tta_acc:.3f}%")
    print(f"   â€¢ TTAæå‡: {tta_acc - overall_acc:.3f}%")

    # è©³ç´°å¯è¦–åŒ–
    plot_precision_evaluation(
        all_labels,
        all_predictions,
        tta_predictions,
        all_probabilities,
        classes,
        overall_acc,
        tta_acc,
    )

    return overall_acc, tta_acc


def plot_precision_evaluation(
    labels, predictions, tta_predictions, probabilities, classes, standard_acc, tta_acc
):
    """è¶…ç²¾æº–è©•ä¼°å¯è¦–åŒ–"""
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle("Precision gMLP Evaluation Results", fontsize=16, fontweight="bold")

    # 1. é¡åˆ¥æº–ç¢ºç‡æ¯”è¼ƒ
    class_accs_std = []
    class_accs_tta = []

    for i in range(len(classes)):
        class_mask = np.array(labels) == i
        if np.sum(class_mask) > 0:
            std_acc = (
                100.0
                * np.sum(np.array(predictions)[class_mask] == i)
                / np.sum(class_mask)
            )
            tta_acc_class = (
                100.0
                * np.sum(np.array(tta_predictions)[class_mask] == i)
                / np.sum(class_mask)
            )
            class_accs_std.append(std_acc)
            class_accs_tta.append(tta_acc_class)
        else:
            class_accs_std.append(0)
            class_accs_tta.append(0)

    x = np.arange(len(classes))
    width = 0.35

    axes[0, 0].bar(x - width / 2, class_accs_std, width, label="Standard", alpha=0.8)
    axes[0, 0].bar(x + width / 2, class_accs_tta, width, label="TTA", alpha=0.8)
    axes[0, 0].set_title("Class-wise Accuracy Comparison")
    axes[0, 0].set_ylabel("Accuracy (%)")
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(classes, rotation=45)
    axes[0, 0].legend()
    axes[0, 0].grid(axis="y", alpha=0.3)

    # 2. æ··æ·†çŸ©é™£ (æ¨™æº–)
    cm_std = confusion_matrix(labels, predictions)
    sns.heatmap(
        cm_std,
        annot=True,
        fmt="d",
        cmap="Blues",
        xticklabels=classes,
        yticklabels=classes,
        ax=axes[0, 1],
    )
    axes[0, 1].set_title(f"Standard Confusion Matrix (Acc: {standard_acc:.2f}%)")
    axes[0, 1].set_xlabel("Predicted")
    axes[0, 1].set_ylabel("True")

    # 3. æ··æ·†çŸ©é™£ (TTA)
    cm_tta = confusion_matrix(labels, tta_predictions)
    sns.heatmap(
        cm_tta,
        annot=True,
        fmt="d",
        cmap="Greens",
        xticklabels=classes,
        yticklabels=classes,
        ax=axes[0, 2],
    )
    axes[0, 2].set_title(f"TTA Confusion Matrix (Acc: {tta_acc:.2f}%)")
    axes[0, 2].set_xlabel("Predicted")
    axes[0, 2].set_ylabel("True")

    # 4. é æ¸¬ä¿¡å¿ƒåº¦åˆ†ä½ˆ
    max_probs = np.max(probabilities, axis=1)
    correct_mask = np.array(predictions) == np.array(labels)

    axes[1, 0].hist(
        max_probs[correct_mask], bins=50, alpha=0.7, label="Correct", density=True
    )
    axes[1, 0].hist(
        max_probs[~correct_mask], bins=50, alpha=0.7, label="Incorrect", density=True
    )
    axes[1, 0].set_title("Prediction Confidence Distribution")
    axes[1, 0].set_xlabel("Max Probability")
    axes[1, 0].set_ylabel("Density")
    axes[1, 0].legend()
    axes[1, 0].grid(alpha=0.3)

    # 5. æº–ç¢ºç‡ vs ä¿¡å¿ƒåº¦
    confidence_bins = np.linspace(0, 1, 21)
    bin_accs = []
    bin_counts = []

    for i in range(len(confidence_bins) - 1):
        mask = (max_probs >= confidence_bins[i]) & (max_probs < confidence_bins[i + 1])
        if np.sum(mask) > 0:
            bin_acc = np.mean(correct_mask[mask])
            bin_accs.append(bin_acc)
            bin_counts.append(np.sum(mask))
        else:
            bin_accs.append(0)
            bin_counts.append(0)

    bin_centers = (confidence_bins[:-1] + confidence_bins[1:]) / 2
    axes[1, 1].plot(bin_centers, bin_accs, "o-", linewidth=2, markersize=6)
    axes[1, 1].plot([0, 1], [0, 1], "r--", alpha=0.5, label="Perfect Calibration")
    axes[1, 1].set_title("Reliability Diagram")
    axes[1, 1].set_xlabel("Confidence")
    axes[1, 1].set_ylabel("Accuracy")
    axes[1, 1].legend()
    axes[1, 1].grid(alpha=0.3)

    # 6. æ”¹é€²åˆ†æ
    improvement = np.array(tta_predictions) == np.array(labels)
    standard_result = np.array(predictions) == np.array(labels)

    tta_better = improvement & (~standard_result)  # TTAå°ä½†æ¨™æº–éŒ¯
    tta_worse = (~improvement) & standard_result  # TTAéŒ¯ä½†æ¨™æº–å°
    both_correct = improvement & standard_result  # éƒ½å°
    both_wrong = (~improvement) & (~standard_result)  # éƒ½éŒ¯

    categories = ["Both Correct", "TTA Better", "TTA Worse", "Both Wrong"]
    counts = [
        np.sum(both_correct),
        np.sum(tta_better),
        np.sum(tta_worse),
        np.sum(both_wrong),
    ]
    colors = ["green", "blue", "orange", "red"]

    axes[1, 2].pie(counts, labels=categories, colors=colors, autopct="%1.1f%%")
    axes[1, 2].set_title("TTA vs Standard Comparison")

    plt.tight_layout()
    plt.savefig("precision_gmlp_evaluation.png", dpi=300, bbox_inches="tight")
    plt.show()


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ è¶…ç²¾æº– gMLP åœ–åƒåˆ†é¡æ¸¬è©¦")
    print("=" * 60)

    # è¨­å®šéš¨æ©Ÿç¨®å­
    set_seed(42)

    try:
        # 1. è¼‰å…¥è¶…ç²¾æº–æ•¸æ“š
        trainloader, valloader, testloader, classes = load_cifar10_data_precision()

        # 2. å‰µå»ºè¶…ç²¾æº–æ¨¡å‹
        model, device = create_precision_gmlp_model()

        # 3. è¶…ç²¾æº–è¨“ç·´
        (
            train_losses,
            train_accs,
            val_losses,
            val_accs,
            learning_rates,
            epoch_times,
            total_training_time,
        ) = train_precision_model(model, trainloader, valloader, device, epochs=50)

        # 4. ç¹ªè£½è¨“ç·´æ­·å²
        plot_precision_training_history(
            train_losses, train_accs, val_losses, val_accs, learning_rates, epoch_times
        )

        # 5. è¶…ç²¾æº–è©•ä¼°
        standard_acc, tta_acc = evaluate_precision_model(
            model, testloader, device, classes
        )

        # 6. æœ€çµ‚å ±å‘Š
        print(f"\nğŸŠ è¶…ç²¾æº–æ¸¬è©¦å®Œæˆï¼")
        print(f"=" * 60)
        print(f"ğŸ“Š æœ€çµ‚çµæœ:")
        print(f"   â€¢ æ¨™æº–æ¸¬è©¦æº–ç¢ºç‡: {standard_acc:.3f}%")
        print(f"   â€¢ TTAæ¸¬è©¦æº–ç¢ºç‡: {tta_acc:.3f}%")
        print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(val_accs):.3f}%")
        print(f"   â€¢ ç¸½è¨“ç·´æ™‚é–“: {total_training_time/60:.2f} åˆ†é˜")
        print(f"   â€¢ å¹³å‡æ¯epochæ™‚é–“: {np.mean(epoch_times):.2f} ç§’")

        # æ€§èƒ½è©•ç´š
        if tta_acc >= 90:
            grade = "ğŸ† å„ªç§€"
            comment = "æ¨¡å‹è¡¨ç¾å„ªç•°ï¼Œå¯ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒï¼"
        elif tta_acc >= 85:
            grade = "ğŸ¥‡ å„ªè‰¯"
            comment = "æ¨¡å‹è¡¨ç¾å¾ˆå¥½ï¼Œæ¥è¿‘SOTAæ°´æº–ï¼"
        elif tta_acc >= 80:
            grade = "ğŸ¥ˆ è‰¯å¥½"
            comment = "æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼Œé”åˆ°é æœŸç›®æ¨™ï¼"
        elif tta_acc >= 75:
            grade = "ğŸ¥‰ åŠæ ¼"
            comment = "æ¨¡å‹è¡¨ç¾å°šå¯ï¼Œé‚„æœ‰æ”¹é€²ç©ºé–“ã€‚"
        else:
            grade = "âŒ éœ€æ”¹é€²"
            comment = "æ¨¡å‹è¡¨ç¾ä¸ä½³ï¼Œéœ€è¦é‡æ–°èª¿æ•´ã€‚"

        print(f"\nğŸ¯ æ€§èƒ½è©•ç´š: {grade}")
        print(f"ğŸ’¬ è©•èª: {comment}")

        # æŠ€è¡“å»ºè­°
        print(f"\nğŸ”§ æŠ€è¡“åˆ†æ:")
        overfitting = train_accs[-1] - val_accs[-1] if train_accs and val_accs else 0
        if overfitting > 10:
            print(f"   âš ï¸  æª¢æ¸¬åˆ°éæ“¬åˆ (å·®ç•°: {overfitting:.2f}%)")
            print(f"      å»ºè­°: å¢åŠ æ­£å‰‡åŒ–æˆ–æ¸›å°‘æ¨¡å‹è¤‡é›œåº¦")
        elif overfitting > 5:
            print(f"   ğŸ”¶ è¼•å¾®éæ“¬åˆ (å·®ç•°: {overfitting:.2f}%)")
            print(f"      å»ºè­°: å¾®èª¿æ­£å‰‡åŒ–åƒæ•¸")
        else:
            print(f"   âœ… æ¨¡å‹æ³›åŒ–è‰¯å¥½ (å·®ç•°: {overfitting:.2f}%)")

        if tta_acc - standard_acc > 1:
            print(f"   ğŸ“ˆ TTAæ•ˆæœé¡¯è‘— (+{tta_acc - standard_acc:.2f}%)")
            print(f"      å»ºè­°: åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ä½¿ç”¨TTA")
        else:
            print(f"   ğŸ“Š TTAæ•ˆæœæœ‰é™ (+{tta_acc - standard_acc:.2f}%)")
            print(f"      å»ºè­°: è€ƒæ…®å…¶ä»–å¢å¼·ç­–ç•¥")

    except Exception as e:
        print(f"âŒ è¶…ç²¾æº–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
>>>>>>> 420764095488647da1ecd1309c810893dfec8ea4
