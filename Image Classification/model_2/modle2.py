<<<<<<< HEAD
"""
å¢å¼·ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦
åŒ…å«å¯è¦–åŒ–çµæœå’Œæº–ç¢ºç‡å„ªåŒ–æŠ€å·§
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset
from g_mlp_pytorch import gMLPVision
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns


def load_cifar10_data_enhanced(quick_test=True):
    """åŠ è¼‰å¢å¼·çš„ CIFAR-10 æ•¸æ“šé›†"""
    print("ğŸ“¦ åŠ è¼‰å¢å¼·çš„ CIFAR-10 æ•¸æ“šé›†...")

    # æ›´å¥½çš„æ•¸æ“šå¢å¼·
    transform_train = transforms.Compose(
        [
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(
                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1
            ),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    transform_test = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    trainset = torchvision.datasets.CIFAR10(
        root="./data", train=True, download=True, transform=transform_train
    )
    testset = torchvision.datasets.CIFAR10(
        root="./data", train=False, download=True, transform=transform_test
    )

    if quick_test:
        trainset = Subset(trainset, range(500))  # å¢åŠ åˆ°5000å€‹æ¨£æœ¬
        testset = Subset(testset, range(100))  # å¢åŠ åˆ°1000å€‹æ¨£æœ¬
        print("   âš¡ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼šä½¿ç”¨å¢å¼·çš„éƒ¨åˆ†æ•¸æ“š")

    trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)
    testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=0)

    classes = [
        "Airplane",
        "Automobile",
        "Bird",
        "Cat",
        "Deer",
        "Dog",
        "Frog",
        "Horse",
        "Ship",
        "Truck",
    ]

    print(f"   âœ“ è¨“ç·´æ¨£æœ¬: {len(trainset)}")
    print(f"   âœ“ æ¸¬è©¦æ¨£æœ¬: {len(testset)}")
    print(f"   âœ“ é¡åˆ¥æ•¸: {len(classes)}")

    return trainloader, testloader, classes


def create_optimized_gmlp_model():
    """å‰µå»ºå„ªåŒ–çš„ gMLP æ¨¡å‹"""
    print("\nğŸ—ï¸ å‰µå»ºå„ªåŒ–çš„ gMLP æ¨¡å‹...")

    model = gMLPVision(
        image_size=32,
        patch_size=8,  # æ›´å¤§çš„patchï¼Œæ¸›å°‘è¨ˆç®—é‡
        num_classes=10,
        dim=256,  # è¼ƒå°çš„ç¶­åº¦
        depth=6,  # è¼ƒæ·ºçš„ç¶²çµ¡
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"   âœ“ å„ªåŒ–æ¨¡å‹å‰µå»ºå®Œæˆ")
    print(f"   âœ“ è¨­å‚™: {device}")
    print(f"   âœ“ åƒæ•¸æ•¸é‡: {total_params:,}")
    print(f"   âœ“ æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.1f} MB")

    return model, device


def train_model_with_scheduler(model, trainloader, testloader, device, epochs=10):
    """ä½¿ç”¨å­¸ç¿’ç‡èª¿åº¦å™¨çš„å„ªåŒ–è¨“ç·´"""
    print(f"\nğŸ‹ï¸ é–‹å§‹å„ªåŒ–è¨“ç·´ ({epochs} å€‹ epochs)...")

    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # æ¨™ç±¤å¹³æ»‘
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    train_losses = []
    train_accs = []
    val_accs = []

    for epoch in range(epochs):
        # è¨“ç·´éšæ®µ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        print(f"\nEpoch {epoch + 1}/{epochs}, LR: {scheduler.get_last_lr()[0]:.6f}")

        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            if (i + 1) % 20 == 0:
                acc = 100.0 * correct / total
                print(
                    f"   æ‰¹æ¬¡ {i+1:3d}: æå¤± = {running_loss/(i+1):.4f}, æº–ç¢ºç‡ = {acc:.2f}%"
                )

        epoch_loss = running_loss / len(trainloader)
        epoch_acc = 100.0 * correct / total
        train_losses.append(epoch_loss)
        train_accs.append(epoch_acc)

        # é©—è­‰éšæ®µ
        val_acc = quick_validate(model, testloader, device)
        val_accs.append(val_acc)

        print(
            f"Epoch {epoch + 1} å®Œæˆ: è¨“ç·´æº–ç¢ºç‡ = {epoch_acc:.2f}%, é©—è­‰æº–ç¢ºç‡ = {val_acc:.2f}%"
        )
        scheduler.step()

    return train_losses, train_accs, val_accs


def quick_validate(model, testloader, device):
    """å¿«é€Ÿé©—è­‰"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    return 100.0 * correct / total


def evaluate_model_with_visualization(model, testloader, device, classes):
    """è©•ä¼°æ¨¡å‹ä¸¦ç”Ÿæˆå¯è¦–åŒ–çµæœ"""
    print("\nğŸ“Š è©•ä¼°æ¨¡å‹ä¸¦ç”Ÿæˆå¯è¦–åŒ–...")

    model.eval()
    all_predictions = []
    all_labels = []
    correct = 0
    total = 0
    class_correct = [0] * 10
    class_total = [0] * 10

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += (predicted[i] == label).item()
                class_total[label] += 1

    overall_acc = 100.0 * correct / total
    print(f"   âœ“ overall accuracy: {overall_acc:.2f}%")  # ç¸½é«”æº–ç¢ºç‡

    # 1. å„é¡åˆ¥æº–ç¢ºç‡æ¢å½¢åœ–
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    class_accs = []
    for i in range(10):
        if class_total[i] > 0:
            acc = 100.0 * class_correct[i] / class_total[i]
            class_accs.append(acc)
        else:
            class_accs.append(0)

    bars = plt.bar(classes, class_accs, color=plt.cm.tab10(np.arange(10)))
    plt.title("Accuracy of Each Category", fontsize=14, fontweight="bold")
    plt.ylabel("Accuracy (%)")
    plt.xticks(rotation=45)
    plt.grid(axis="y", alpha=0.3)

    # åœ¨æŸ±ç‹€åœ–ä¸Šæ·»åŠ æ•¸å€¼
    for bar, acc in zip(bars, class_accs):
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 1,
            f"{acc:.1f}%",
            ha="center",
            va="bottom",
            fontweight="bold",
        )

    # 2. æ··æ·†çŸ©é™£
    plt.subplot(2, 2, 2)
    cm = confusion_matrix(all_labels, all_predictions)
    sns.heatmap(
        cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes
    )
    plt.title("Confusion Matrix", fontsize=14, fontweight="bold")
    plt.xlabel("Predicted Category")
    plt.ylabel("True Category")

    # 3. æ¨™æº–åŒ–æ··æ·†çŸ©é™£
    plt.subplot(2, 2, 3)
    cm_normalized = confusion_matrix(all_labels, all_predictions, normalize="true")
    sns.heatmap(
        cm_normalized,
        annot=True,
        fmt=".2f",
        cmap="Blues",
        xticklabels=classes,
        yticklabels=classes,
    )
    plt.title("Normalized Confusion Matrix", fontsize=14, fontweight="bold")
    plt.xlabel("Predicted Category")
    plt.ylabel("True Category")

    # 4. é¡åˆ¥åˆ†ä½ˆ
    plt.subplot(2, 2, 4)
    unique, counts = np.unique(all_labels, return_counts=True)
    plt.pie(
        counts,
        labels=[classes[i] for i in unique],
        autopct="%1.1f%%",
        colors=plt.cm.tab10(np.arange(len(unique))),
    )
    plt.title("Test Set Category Distribution", fontsize=14, fontweight="bold")

    plt.tight_layout()
    plt.savefig("gmlp_evaluation_results.png", dpi=300, bbox_inches="tight")
    plt.show()

    # æ‰“å°è©³ç´°å ±å‘Š
    print(f"\nğŸ“‹ è©³ç´°åˆ†é¡å ±å‘Š:")
    target_names = [f"{i}_{classes[i]}" for i in range(10)]
    report = classification_report(
        all_labels, all_predictions, target_names=target_names, digits=3
    )
    print(report)

    return overall_acc


def plot_training_history(train_losses, train_accs, val_accs):
    """ç¹ªè£½è¨“ç·´æ­·å²"""
    print("\nğŸ“ˆ ç¹ªè£½è¨“ç·´æ­·å²...")

    plt.figure(figsize=(15, 5))

    # æå¤±æ›²ç·š
    plt.subplot(1, 3, 1)
    plt.plot(train_losses, "b-", linewidth=2, label="Training Loss")
    plt.title("Training Loss Curve", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True, alpha=0.3)
    plt.legend()

    # æº–ç¢ºç‡æ›²ç·š
    plt.subplot(1, 3, 2)
    plt.plot(train_accs, "g-", linewidth=2, label="Training Accuracy")
    plt.plot(val_accs, "r-", linewidth=2, label="Validation Accuracy")
    plt.title("Accuracy Curve", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.grid(True, alpha=0.3)
    plt.legend()

    # æº–ç¢ºç‡å·®ç•°
    plt.subplot(1, 3, 3)
    diff = np.array(train_accs) - np.array(val_accs)
    plt.plot(diff, "purple", linewidth=2, label="Train-Val Difference")
    plt.title("Overfitting Monitor", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy Difference (%)")
    plt.grid(True, alpha=0.3)
    plt.axhline(y=0, color="black", linestyle="--", alpha=0.5)
    plt.legend()

    plt.tight_layout()
    plt.savefig("gmlp_training_history.png", dpi=300, bbox_inches="tight")
    plt.show()


def visualize_sample_predictions(model, testloader, device, classes, num_samples=12):
    """å¯è¦–åŒ–æ¨£æœ¬é æ¸¬çµæœ"""
    print(f"\nğŸ” å¯è¦–åŒ– {num_samples} å€‹æ¨£æœ¬é æ¸¬...")

    model.eval()

    # ç²å–ä¸€æ‰¹æ•¸æ“š
    dataiter = iter(testloader)
    images, labels = next(dataiter)
    images, labels = images.to(device), labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        _, predictions = torch.max(outputs, 1)
        probabilities = torch.softmax(outputs, 1)

    # ç¹ªè£½çµæœ
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    fig.suptitle("gMLP Prediction Results", fontsize=16, fontweight="bold")

    for i in range(min(num_samples, len(images))):
        ax = axes[i // 4, i % 4]

        # åæ¨™æº–åŒ–åœ–åƒ
        img = images[i].cpu()
        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)
        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)
        img = img * std + mean
        img = torch.clamp(img, 0, 1)

        ax.imshow(img.permute(1, 2, 0))

        true_label = classes[labels[i]]
        pred_label = classes[predictions[i]]
        confidence = probabilities[i, predictions[i]].item()

        # è¨­ç½®é¡è‰²ï¼ˆæ­£ç¢º=ç¶ è‰²ï¼ŒéŒ¯èª¤=ç´…è‰²ï¼‰
        color = "green" if labels[i] == predictions[i] else "red"

        ax.set_title(
            f"True: {true_label}\nPred: {pred_label}\nConf: {confidence:.2f}",
            color=color,
            fontweight="bold",
        )
        ax.axis("off")

    plt.tight_layout()
    plt.savefig("gmlp_sample_predictions.png", dpi=300, bbox_inches="tight")
    plt.show()


def main():
    print("ğŸ–¼ï¸ å¢å¼·ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦")
    print("=" * 60)

    try:
        # 1. åŠ è¼‰å¢å¼·æ•¸æ“š
        trainloader, testloader, classes = load_cifar10_data_enhanced(quick_test=True)

        # 2. å‰µå»ºå„ªåŒ–æ¨¡å‹
        model, device = create_optimized_gmlp_model()

        # 3. å„ªåŒ–è¨“ç·´
        train_losses, train_accs, val_accs = train_model_with_scheduler(
            model, trainloader, testloader, device, epochs=3
        )

        # 4. ç¹ªè£½è¨“ç·´æ­·å²
        plot_training_history(train_losses, train_accs, val_accs)

        # 5. è©³ç´°è©•ä¼°èˆ‡å¯è¦–åŒ–
        accuracy = evaluate_model_with_visualization(model, testloader, device, classes)

        # 6. å¯è¦–åŒ–é æ¸¬æ¨£æœ¬
        visualize_sample_predictions(model, testloader, device, classes)

        # 7. ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), "gmlp_model.pth")
        print("\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜ç‚º 'gmlp_model.pth'")

        print("\n" + "=" * 60)
        print("âœ… å¢å¼·æ¸¬è©¦å®Œæˆï¼")
        print(f"\nğŸ“ˆ æœ€çµ‚çµæœ:")
        print(f"   â€¢ æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {accuracy:.2f}%")
        print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(val_accs):.2f}%")
        print(f"   â€¢ è¨“ç·´-é©—è­‰å·®ç•°: {train_accs[-1] - val_accs[-1]:.2f}%")

        print(f"\nğŸ¯ æ”¹é€²å»ºè­°:")
        if accuracy < 70:
            print(f"   â€¢ è€ƒæ…®å¢åŠ è¨“ç·´æ™‚é–“å’Œæ•¸æ“šé‡")
            print(f"   â€¢ å˜—è©¦æ›´å¼·çš„æ•¸æ“šå¢å¼·")
            print(f"   â€¢ èª¿æ•´å­¸ç¿’ç‡å’Œå„ªåŒ–å™¨åƒæ•¸")
        elif accuracy < 85:
            print(f"   â€¢ è¡¨ç¾è‰¯å¥½ï¼å¯å˜—è©¦æ›´æ·±çš„æ¨¡å‹")
            print(f"   â€¢ è€ƒæ…®ä½¿ç”¨å­¸ç¿’ç‡é ç†±")
            print(f"   â€¢ å¯¦é©—ä¸åŒçš„æ­£å‰‡åŒ–æŠ€å·§")
        else:
            print(f"   â€¢ å„ªç§€çš„è¡¨ç¾ï¼æ¨¡å‹å·²ç¶“å¾ˆå¥½")
            print(f"   â€¢ å¯ä»¥ç”¨æ–¼å¯¦éš›æ‡‰ç”¨")

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
=======
"""
å¢å¼·ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦
åŒ…å«å¯è¦–åŒ–çµæœå’Œæº–ç¢ºç‡å„ªåŒ–æŠ€å·§
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset
from g_mlp_pytorch import gMLPVision
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns


def load_cifar10_data_enhanced(quick_test=True):
    """åŠ è¼‰å¢å¼·çš„ CIFAR-10 æ•¸æ“šé›†"""
    print("ğŸ“¦ åŠ è¼‰å¢å¼·çš„ CIFAR-10 æ•¸æ“šé›†...")

    # æ›´å¥½çš„æ•¸æ“šå¢å¼·
    transform_train = transforms.Compose(
        [
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(
                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1
            ),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    transform_test = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ]
    )

    trainset = torchvision.datasets.CIFAR10(
        root="./data", train=True, download=True, transform=transform_train
    )
    testset = torchvision.datasets.CIFAR10(
        root="./data", train=False, download=True, transform=transform_test
    )

    if quick_test:
        trainset = Subset(trainset, range(500))  # å¢åŠ åˆ°5000å€‹æ¨£æœ¬
        testset = Subset(testset, range(100))  # å¢åŠ åˆ°1000å€‹æ¨£æœ¬
        print("   âš¡ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼šä½¿ç”¨å¢å¼·çš„éƒ¨åˆ†æ•¸æ“š")

    trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)
    testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=0)

    classes = [
        "Airplane",
        "Automobile",
        "Bird",
        "Cat",
        "Deer",
        "Dog",
        "Frog",
        "Horse",
        "Ship",
        "Truck",
    ]

    print(f"   âœ“ è¨“ç·´æ¨£æœ¬: {len(trainset)}")
    print(f"   âœ“ æ¸¬è©¦æ¨£æœ¬: {len(testset)}")
    print(f"   âœ“ é¡åˆ¥æ•¸: {len(classes)}")

    return trainloader, testloader, classes


def create_optimized_gmlp_model():
    """å‰µå»ºå„ªåŒ–çš„ gMLP æ¨¡å‹"""
    print("\nğŸ—ï¸ å‰µå»ºå„ªåŒ–çš„ gMLP æ¨¡å‹...")

    model = gMLPVision(
        image_size=32,
        patch_size=8,  # æ›´å¤§çš„patchï¼Œæ¸›å°‘è¨ˆç®—é‡
        num_classes=10,
        dim=256,  # è¼ƒå°çš„ç¶­åº¦
        depth=6,  # è¼ƒæ·ºçš„ç¶²çµ¡
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"   âœ“ å„ªåŒ–æ¨¡å‹å‰µå»ºå®Œæˆ")
    print(f"   âœ“ è¨­å‚™: {device}")
    print(f"   âœ“ åƒæ•¸æ•¸é‡: {total_params:,}")
    print(f"   âœ“ æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.1f} MB")

    return model, device


def train_model_with_scheduler(model, trainloader, testloader, device, epochs=10):
    """ä½¿ç”¨å­¸ç¿’ç‡èª¿åº¦å™¨çš„å„ªåŒ–è¨“ç·´"""
    print(f"\nğŸ‹ï¸ é–‹å§‹å„ªåŒ–è¨“ç·´ ({epochs} å€‹ epochs)...")

    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # æ¨™ç±¤å¹³æ»‘
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    train_losses = []
    train_accs = []
    val_accs = []

    for epoch in range(epochs):
        # è¨“ç·´éšæ®µ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        print(f"\nEpoch {epoch + 1}/{epochs}, LR: {scheduler.get_last_lr()[0]:.6f}")

        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            if (i + 1) % 20 == 0:
                acc = 100.0 * correct / total
                print(
                    f"   æ‰¹æ¬¡ {i+1:3d}: æå¤± = {running_loss/(i+1):.4f}, æº–ç¢ºç‡ = {acc:.2f}%"
                )

        epoch_loss = running_loss / len(trainloader)
        epoch_acc = 100.0 * correct / total
        train_losses.append(epoch_loss)
        train_accs.append(epoch_acc)

        # é©—è­‰éšæ®µ
        val_acc = quick_validate(model, testloader, device)
        val_accs.append(val_acc)

        print(
            f"Epoch {epoch + 1} å®Œæˆ: è¨“ç·´æº–ç¢ºç‡ = {epoch_acc:.2f}%, é©—è­‰æº–ç¢ºç‡ = {val_acc:.2f}%"
        )
        scheduler.step()

    return train_losses, train_accs, val_accs


def quick_validate(model, testloader, device):
    """å¿«é€Ÿé©—è­‰"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    return 100.0 * correct / total


def evaluate_model_with_visualization(model, testloader, device, classes):
    """è©•ä¼°æ¨¡å‹ä¸¦ç”Ÿæˆå¯è¦–åŒ–çµæœ"""
    print("\nğŸ“Š è©•ä¼°æ¨¡å‹ä¸¦ç”Ÿæˆå¯è¦–åŒ–...")

    model.eval()
    all_predictions = []
    all_labels = []
    correct = 0
    total = 0
    class_correct = [0] * 10
    class_total = [0] * 10

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += (predicted[i] == label).item()
                class_total[label] += 1

    overall_acc = 100.0 * correct / total
    print(f"   âœ“ overall accuracy: {overall_acc:.2f}%")  # ç¸½é«”æº–ç¢ºç‡

    # 1. å„é¡åˆ¥æº–ç¢ºç‡æ¢å½¢åœ–
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    class_accs = []
    for i in range(10):
        if class_total[i] > 0:
            acc = 100.0 * class_correct[i] / class_total[i]
            class_accs.append(acc)
        else:
            class_accs.append(0)

    bars = plt.bar(classes, class_accs, color=plt.cm.tab10(np.arange(10)))
    plt.title("Accuracy of Each Category", fontsize=14, fontweight="bold")
    plt.ylabel("Accuracy (%)")
    plt.xticks(rotation=45)
    plt.grid(axis="y", alpha=0.3)

    # åœ¨æŸ±ç‹€åœ–ä¸Šæ·»åŠ æ•¸å€¼
    for bar, acc in zip(bars, class_accs):
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 1,
            f"{acc:.1f}%",
            ha="center",
            va="bottom",
            fontweight="bold",
        )

    # 2. æ··æ·†çŸ©é™£
    plt.subplot(2, 2, 2)
    cm = confusion_matrix(all_labels, all_predictions)
    sns.heatmap(
        cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes
    )
    plt.title("Confusion Matrix", fontsize=14, fontweight="bold")
    plt.xlabel("Predicted Category")
    plt.ylabel("True Category")

    # 3. æ¨™æº–åŒ–æ··æ·†çŸ©é™£
    plt.subplot(2, 2, 3)
    cm_normalized = confusion_matrix(all_labels, all_predictions, normalize="true")
    sns.heatmap(
        cm_normalized,
        annot=True,
        fmt=".2f",
        cmap="Blues",
        xticklabels=classes,
        yticklabels=classes,
    )
    plt.title("Normalized Confusion Matrix", fontsize=14, fontweight="bold")
    plt.xlabel("Predicted Category")
    plt.ylabel("True Category")

    # 4. é¡åˆ¥åˆ†ä½ˆ
    plt.subplot(2, 2, 4)
    unique, counts = np.unique(all_labels, return_counts=True)
    plt.pie(
        counts,
        labels=[classes[i] for i in unique],
        autopct="%1.1f%%",
        colors=plt.cm.tab10(np.arange(len(unique))),
    )
    plt.title("Test Set Category Distribution", fontsize=14, fontweight="bold")

    plt.tight_layout()
    plt.savefig("gmlp_evaluation_results.png", dpi=300, bbox_inches="tight")
    plt.show()

    # æ‰“å°è©³ç´°å ±å‘Š
    print(f"\nğŸ“‹ è©³ç´°åˆ†é¡å ±å‘Š:")
    target_names = [f"{i}_{classes[i]}" for i in range(10)]
    report = classification_report(
        all_labels, all_predictions, target_names=target_names, digits=3
    )
    print(report)

    return overall_acc


def plot_training_history(train_losses, train_accs, val_accs):
    """ç¹ªè£½è¨“ç·´æ­·å²"""
    print("\nğŸ“ˆ ç¹ªè£½è¨“ç·´æ­·å²...")

    plt.figure(figsize=(15, 5))

    # æå¤±æ›²ç·š
    plt.subplot(1, 3, 1)
    plt.plot(train_losses, "b-", linewidth=2, label="Training Loss")
    plt.title("Training Loss Curve", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True, alpha=0.3)
    plt.legend()

    # æº–ç¢ºç‡æ›²ç·š
    plt.subplot(1, 3, 2)
    plt.plot(train_accs, "g-", linewidth=2, label="Training Accuracy")
    plt.plot(val_accs, "r-", linewidth=2, label="Validation Accuracy")
    plt.title("Accuracy Curve", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.grid(True, alpha=0.3)
    plt.legend()

    # æº–ç¢ºç‡å·®ç•°
    plt.subplot(1, 3, 3)
    diff = np.array(train_accs) - np.array(val_accs)
    plt.plot(diff, "purple", linewidth=2, label="Train-Val Difference")
    plt.title("Overfitting Monitor", fontsize=14, fontweight="bold")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy Difference (%)")
    plt.grid(True, alpha=0.3)
    plt.axhline(y=0, color="black", linestyle="--", alpha=0.5)
    plt.legend()

    plt.tight_layout()
    plt.savefig("gmlp_training_history.png", dpi=300, bbox_inches="tight")
    plt.show()


def visualize_sample_predictions(model, testloader, device, classes, num_samples=12):
    """å¯è¦–åŒ–æ¨£æœ¬é æ¸¬çµæœ"""
    print(f"\nğŸ” å¯è¦–åŒ– {num_samples} å€‹æ¨£æœ¬é æ¸¬...")

    model.eval()

    # ç²å–ä¸€æ‰¹æ•¸æ“š
    dataiter = iter(testloader)
    images, labels = next(dataiter)
    images, labels = images.to(device), labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        _, predictions = torch.max(outputs, 1)
        probabilities = torch.softmax(outputs, 1)

    # ç¹ªè£½çµæœ
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    fig.suptitle("gMLP Prediction Results", fontsize=16, fontweight="bold")

    for i in range(min(num_samples, len(images))):
        ax = axes[i // 4, i % 4]

        # åæ¨™æº–åŒ–åœ–åƒ
        img = images[i].cpu()
        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)
        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)
        img = img * std + mean
        img = torch.clamp(img, 0, 1)

        ax.imshow(img.permute(1, 2, 0))

        true_label = classes[labels[i]]
        pred_label = classes[predictions[i]]
        confidence = probabilities[i, predictions[i]].item()

        # è¨­ç½®é¡è‰²ï¼ˆæ­£ç¢º=ç¶ è‰²ï¼ŒéŒ¯èª¤=ç´…è‰²ï¼‰
        color = "green" if labels[i] == predictions[i] else "red"

        ax.set_title(
            f"True: {true_label}\nPred: {pred_label}\nConf: {confidence:.2f}",
            color=color,
            fontweight="bold",
        )
        ax.axis("off")

    plt.tight_layout()
    plt.savefig("gmlp_sample_predictions.png", dpi=300, bbox_inches="tight")
    plt.show()


def main():
    print("ğŸ–¼ï¸ å¢å¼·ç‰ˆ gMLP åœ–åƒåˆ†é¡æ¸¬è©¦")
    print("=" * 60)

    try:
        # 1. åŠ è¼‰å¢å¼·æ•¸æ“š
        trainloader, testloader, classes = load_cifar10_data_enhanced(quick_test=True)

        # 2. å‰µå»ºå„ªåŒ–æ¨¡å‹
        model, device = create_optimized_gmlp_model()

        # 3. å„ªåŒ–è¨“ç·´
        train_losses, train_accs, val_accs = train_model_with_scheduler(
            model, trainloader, testloader, device, epochs=3
        )

        # 4. ç¹ªè£½è¨“ç·´æ­·å²
        plot_training_history(train_losses, train_accs, val_accs)

        # 5. è©³ç´°è©•ä¼°èˆ‡å¯è¦–åŒ–
        accuracy = evaluate_model_with_visualization(model, testloader, device, classes)

        # 6. å¯è¦–åŒ–é æ¸¬æ¨£æœ¬
        visualize_sample_predictions(model, testloader, device, classes)

        # 7. ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), "gmlp_model.pth")
        print("\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜ç‚º 'gmlp_model.pth'")

        print("\n" + "=" * 60)
        print("âœ… å¢å¼·æ¸¬è©¦å®Œæˆï¼")
        print(f"\nğŸ“ˆ æœ€çµ‚çµæœ:")
        print(f"   â€¢ æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {accuracy:.2f}%")
        print(f"   â€¢ æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(val_accs):.2f}%")
        print(f"   â€¢ è¨“ç·´-é©—è­‰å·®ç•°: {train_accs[-1] - val_accs[-1]:.2f}%")

        print(f"\nğŸ¯ æ”¹é€²å»ºè­°:")
        if accuracy < 70:
            print(f"   â€¢ è€ƒæ…®å¢åŠ è¨“ç·´æ™‚é–“å’Œæ•¸æ“šé‡")
            print(f"   â€¢ å˜—è©¦æ›´å¼·çš„æ•¸æ“šå¢å¼·")
            print(f"   â€¢ èª¿æ•´å­¸ç¿’ç‡å’Œå„ªåŒ–å™¨åƒæ•¸")
        elif accuracy < 85:
            print(f"   â€¢ è¡¨ç¾è‰¯å¥½ï¼å¯å˜—è©¦æ›´æ·±çš„æ¨¡å‹")
            print(f"   â€¢ è€ƒæ…®ä½¿ç”¨å­¸ç¿’ç‡é ç†±")
            print(f"   â€¢ å¯¦é©—ä¸åŒçš„æ­£å‰‡åŒ–æŠ€å·§")
        else:
            print(f"   â€¢ å„ªç§€çš„è¡¨ç¾ï¼æ¨¡å‹å·²ç¶“å¾ˆå¥½")
            print(f"   â€¢ å¯ä»¥ç”¨æ–¼å¯¦éš›æ‡‰ç”¨")

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
>>>>>>> 420764095488647da1ecd1309c810893dfec8ea4
